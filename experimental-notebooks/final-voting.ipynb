{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f11009ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d658a9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 1560</th>\n",
       "      <th>Feature 1561</th>\n",
       "      <th>Feature 1562</th>\n",
       "      <th>Feature 1563</th>\n",
       "      <th>Feature 1564</th>\n",
       "      <th>Feature 1565</th>\n",
       "      <th>Feature 1566</th>\n",
       "      <th>Feature 1567</th>\n",
       "      <th>Feature 1568</th>\n",
       "      <th>Unnamed: 1568</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.854928e-19</td>\n",
       "      <td>-1.329011e-20</td>\n",
       "      <td>4.204335e-21</td>\n",
       "      <td>4.428740e-21</td>\n",
       "      <td>4.461340e-23</td>\n",
       "      <td>2.376798e-24</td>\n",
       "      <td>-7.807106e-24</td>\n",
       "      <td>2.379322e-24</td>\n",
       "      <td>-5.582096e-26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.118652e-20</td>\n",
       "      <td>4.062297e-21</td>\n",
       "      <td>-7.743107e-21</td>\n",
       "      <td>8.638654e-22</td>\n",
       "      <td>-1.006311e-21</td>\n",
       "      <td>-2.267525e-22</td>\n",
       "      <td>-5.867730e-23</td>\n",
       "      <td>4.858047e-24</td>\n",
       "      <td>-4.595498e-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.619224e-20</td>\n",
       "      <td>-3.590984e-20</td>\n",
       "      <td>-2.717642e-20</td>\n",
       "      <td>1.923565e-20</td>\n",
       "      <td>-2.244442e-21</td>\n",
       "      <td>-4.244237e-24</td>\n",
       "      <td>-3.599564e-23</td>\n",
       "      <td>7.471194e-24</td>\n",
       "      <td>-3.815300e-24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.346105e-19</td>\n",
       "      <td>-6.278001e-19</td>\n",
       "      <td>-5.786255e-19</td>\n",
       "      <td>2.573141e-19</td>\n",
       "      <td>2.385063e-19</td>\n",
       "      <td>6.655487e-20</td>\n",
       "      <td>2.834975e-20</td>\n",
       "      <td>3.356577e-21</td>\n",
       "      <td>1.698628e-21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.494150e-20</td>\n",
       "      <td>-1.187973e-20</td>\n",
       "      <td>-1.450941e-21</td>\n",
       "      <td>8.954877e-22</td>\n",
       "      <td>-2.645088e-22</td>\n",
       "      <td>1.365356e-23</td>\n",
       "      <td>8.062470e-24</td>\n",
       "      <td>-1.235689e-24</td>\n",
       "      <td>1.890073e-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1569 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  Feature 6  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   Feature 7  Feature 8  Feature 9  Feature 10  ...  Feature 1560  \\\n",
       "0        0.0        0.0        0.0         0.0  ...  3.854928e-19   \n",
       "1        0.0        0.0        0.0         0.0  ... -7.118652e-20   \n",
       "2        0.0        0.0        0.0         0.0  ... -4.619224e-20   \n",
       "3        0.0        0.0        0.0         0.0  ... -5.346105e-19   \n",
       "4        0.0        0.0        0.0         0.0  ...  5.494150e-20   \n",
       "\n",
       "   Feature 1561  Feature 1562  Feature 1563  Feature 1564  Feature 1565  \\\n",
       "0 -1.329011e-20  4.204335e-21  4.428740e-21  4.461340e-23  2.376798e-24   \n",
       "1  4.062297e-21 -7.743107e-21  8.638654e-22 -1.006311e-21 -2.267525e-22   \n",
       "2 -3.590984e-20 -2.717642e-20  1.923565e-20 -2.244442e-21 -4.244237e-24   \n",
       "3 -6.278001e-19 -5.786255e-19  2.573141e-19  2.385063e-19  6.655487e-20   \n",
       "4 -1.187973e-20 -1.450941e-21  8.954877e-22 -2.645088e-22  1.365356e-23   \n",
       "\n",
       "   Feature 1566  Feature 1567  Feature 1568  Unnamed: 1568  \n",
       "0 -7.807106e-24  2.379322e-24 -5.582096e-26            NaN  \n",
       "1 -5.867730e-23  4.858047e-24 -4.595498e-25            NaN  \n",
       "2 -3.599564e-23  7.471194e-24 -3.815300e-24            NaN  \n",
       "3  2.834975e-20  3.356577e-21  1.698628e-21            NaN  \n",
       "4  8.062470e-24 -1.235689e-24  1.890073e-25            NaN  \n",
       "\n",
       "[5 rows x 1569 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb9653b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2336245f310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAEkCAYAAACPCFMiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAchElEQVR4nO3df3SV1b3n8c8hCYeAJ2fMxOQkNyGNCmoBWQrIj4IEf2TMtFTETv11O9CqgzUw5lLGW2TNMqt1iNWRwUql1ToURhE6t/zwDlRIiwl1IQoUhgx6bRgCxktiBkbOCREPhOz5w3LGmJCdkOfs5CTv11rPWp5nf3meL1sSPuzzZB+fMcYIAADAkUG93QAAABhYCB8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnEru7Qa+qrW1VcePH1cgEJDP5+vtdgAAQBcYY9TU1KScnBwNGtT52kafCx/Hjx9XXl5eb7cBAAAuQV1dnXJzczutiVv4ePHFF/Xss8+qvr5eo0aN0vLlyzVt2jTrrwsEApKkqfrXSlZKvNoDAAAeatE5va2tsb/HOxOX8LF+/XqVlpbqxRdf1De+8Q396le/UnFxsd5//30NHz6801974a2WZKUo2Uf4AAAgIfz1k+K68shEXB44XbZsmR588EE99NBDuu6667R8+XLl5eVp5cqV8bgdAABIIJ6Hj7Nnz2rfvn0qKipqc76oqEi7du1qVx+NRhWJRNocAACg//I8fJw4cULnz59XVlZWm/NZWVlqaGhoV19eXq5gMBg7eNgUAID+LW77fHz1PR9jTIfvAy1evFjhcDh21NXVxaslAADQB3j+wGlGRoaSkpLarXI0Nja2Ww2RJL/fL7/f73UbAACgj/J85WPw4MEaN26cKioq2pyvqKjQlClTvL4dAABIMHH5UduFCxfqe9/7nsaPH6/JkyfrpZde0kcffaRHHnkkHrcDAAAJJC7h45577tHJkyf1k5/8RPX19Ro9erS2bt2q/Pz8eNwOAAAkEJ8xxvR2E18WiUQUDAZVqDvZZAwAgATRYs6pUpsVDoeVlpbWaS2fagsAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnCJ8AAAApwgfAADAKcIHAABwivABAACcInwAAACnCB8AAMApwgcAAHCK8AEAAJwifAAAAKeSe7sBJK6kf5lurWn976nWmi3X/KMX7XRJkq/zvF2w7UHrNUZ+f59X7QAJ7S+rxllrQqFT1pqd1//WWvNe1GeteXjV/E7H8366y3oNuMHKBwAAcIrwAQAAnCJ8AAAApwgfAADAKcIHAABwivABAACcInwAAACnCB8AAMApnzHG9HYTXxaJRBQMBlWoO5XsS+ntdgaspKxMa039S/ZNxt4b/5oX7ThT2/K5tab01r+11pw/XOtFO0B7PvtmW5H7JnY6Pu7v9luvccNlx6w1E1KPWmuuS7F/H29Vq7XGC6NeX2CtuWrRbged9E8t5pwqtVnhcFhpaWmd1rLyAQAAnCJ8AAAApwgfAADAKcIHAABwivABAACcInwAAACnCB8AAMCp5N5uAH3T6TXDrDXvjU6sPTy6oiB5iLXmxn84bK3Zf+fXrDUtx+q60hLQbZXPvuDoTkmO7uON8+ktvd0C/oqVDwAA4JTn4aOsrEw+n6/NEQqFvL4NAABIUHF522XUqFH6wx/+EHudlJRYS3MAACB+4hI+kpOTWe0AAAAdisszHzU1NcrJyVFBQYHuvfdeHTly5KK10WhUkUikzQEAAPovz8PHxIkTtWbNGm3btk0vv/yyGhoaNGXKFJ08ebLD+vLycgWDwdiRl5fndUsAAKAP8Tx8FBcX6+6779aYMWN02223acuWLZKk1atXd1i/ePFihcPh2FFXx48fAgDQn8V9n49hw4ZpzJgxqqmp6XDc7/fL7/fHuw0AANBHxD18RKNRffDBB5o2bVq8bwUP/eqarmwgNjBD45NXHLDWzMy43n6hYz3vBQASkedvuyxatEhVVVWqra3Vu+++q+985zuKRCKaM2eO17cCAAAJyPOVj48//lj33XefTpw4oSuuuEKTJk3S7t27lZ+f7/WtAABAAvI8fKxbt87rSwIAgH6Ez3YBAABOET4AAIBThA8AAOAU4QMAADhF+AAAAE7FfZMxwOajljPWmjebr7PWjBty1F7jaF+0I4vsX1oF9zloBIij7x8tstYkDzpvrXl5+B+9aAcJhJUPAADgFOEDAAA4RfgAAABOET4AAIBThA8AAOAU4QMAADhF+AAAAE4RPgAAgFNsMoYO3fnOD601v530krXmnldLrTVpR+z9pK96x1rzD3fcYa15/pcvdDp+XUqKvZkumPS1WmvNJ57cCWjv2/90l5P7nFqdZ615vmyFg066ZmjN4N5uAX/FygcAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnCJ8AAAApwgfAADAKTYZQ4eunPtP1ponLiu21nztpH1zMK8MfnOPtebIuYxOx69LCXvVDhAfxthrbv04/n1IOr14uLVmnN9+nVYPepGk6/44r9PxEeW7PLoTeoqVDwAA4BThAwAAOEX4AAAAThE+AACAU4QPAADgFOEDAAA4RfgAAABOET4AAIBTbDKGDplo1Fpzvgs1LjXOn2Ktmeh/21KR6k0zwADw2Yizzu71bjTFWnPVS15tV4Z4Y+UDAAA41e3wsXPnTs2cOVM5OTny+XzatGlTm3FjjMrKypSTk6PU1FQVFhbq0KFDXvULAAASXLfDR3Nzs8aOHasVK1Z0OP7MM89o2bJlWrFihfbs2aNQKKTbb79dTU1NPW4WAAAkvm4/81FcXKzi4o4/UMwYo+XLl2vJkiWaPXu2JGn16tXKysrS2rVrNW9e+w/9iUajin7p2YFIJNLdlgAAQALx9JmP2tpaNTQ0qKioKHbO7/dr+vTp2rWr408TLC8vVzAYjB15eXletgQAAPoYT8NHQ0ODJCkrK6vN+aysrNjYVy1evFjhcDh21NXVedkSAADoY+Lyo7Y+n6/Na2NMu3MX+P1++f3+eLQBAAD6IE9XPkKhkCS1W+VobGxstxoCAAAGJk9XPgoKChQKhVRRUaEbbrhBknT27FlVVVXpZz/7mZe3AtppyjfWmowkN5uI7dk22lozXB0/BwX0BccX2Tft+8u/esFak+JLstacs3/pqiYastYMevuA/ULoE7odPk6fPq3Dhw/HXtfW1urAgQNKT0/X8OHDVVpaqqVLl2rEiBEaMWKEli5dqqFDh+r+++/3tHEAAJCYuh0+9u7dqxkzZsReL1y4UJI0Z84c/eY3v9Hjjz+uM2fO6NFHH9Wnn36qiRMnavv27QoEAt51DQAAEla3w0dhYaGMufgamc/nU1lZmcrKynrSFwAA6Kf4bBcAAOAU4QMAADhF+AAAAE4RPgAAgFOEDwAA4FRctlcHvHb6u5OsNRXffbYLV3KzyVj+P4atNV3YVwmIizOzbrLWvLHgGWtNq+wfjdGVDcTmHL3NWnP0hWusNQHttt8MfQIrHwAAwCnCBwAAcIrwAQAAnCJ8AAAApwgfAADAKcIHAABwivABAACcInwAAACn2GQMvW7QsGHWmitKaq01ucluNhD7uOWMtcZ37ry1hk3GEC9JWZmdjl/22MfWa+Qk2zcQezeaYq156N051pqr59m/vgMRNhDrT1j5AAAAThE+AACAU4QPAADgFOEDAAA4RfgAAABOET4AAIBThA8AAOAU+3z0Qw2lU6w1zX/T810mBkd81pq8n+6y1tS8PMJa88HVr3Spp546cd6+h8cDf7/IWhM4yJ4EiBOf/esuY9PnnY6/PPyPnrTyyH991FpT8JT9e4B9Vxz0N6x8AAAApwgfAADAKcIHAABwivABAACcInwAAACnCB8AAMApwgcAAHCK8AEAAJxik7G+5KYx1pLD9w6z1rzzb5611lw+aEiXWurMZ+asteatf3uFtea21K5syJXShZqeu/0Xj1tr/madfdMk4FJ8OneytebaeYesNa8Mf8tSYf935wfnzllrMqpbrDVAR1j5AAAATnU7fOzcuVMzZ85UTk6OfD6fNm3a1GZ87ty58vl8bY5JkyZ51S8AAEhw3Q4fzc3NGjt2rFasWHHRmjvuuEP19fWxY+vWrT1qEgAA9B/dfuajuLhYxcXFndb4/X6FQqFLbgoAAPRfcXnmo7KyUpmZmRo5cqQefvhhNTY2XrQ2Go0qEom0OQAAQP/lefgoLi7Wa6+9ph07dui5557Tnj17dMsttygajXZYX15ermAwGDvy8vK8bgkAAPQhnv+o7T333BP779GjR2v8+PHKz8/Xli1bNHv27Hb1ixcv1sKFC2OvI5EIAQQAgH4s7vt8ZGdnKz8/XzU1NR2O+/1++f3+eLcBAAD6iLiHj5MnT6qurk7Z2dnxvlWfljTqGmvNd9dss9Y8EKjvwt16voFYVwz1DbbWfHNouAtXcrOBmCQtPdH5Rm7DN35ivcZ5r5rBgJKcl2utmf7v7RvuPZX1nrWm1TL+btT+NffjJ0qsNYHNXdkgEGiv2+Hj9OnTOnz4cOx1bW2tDhw4oPT0dKWnp6usrEx33323srOzdfToUT3xxBPKyMjQXXfd5WnjAAAgMXU7fOzdu1czZsyIvb7wvMacOXO0cuVKVVdXa82aNTp16pSys7M1Y8YMrV+/XoFAwLuuAQBAwup2+CgsLJQx5qLj27bZ3zoAAAADF5/tAgAAnCJ8AAAApwgfAADAKcIHAABwivABAACcivsmY/jC4QfSrTVd20AMPZGV0vmmZ61pqY46QX/y6dzJ1hqvNhDzwn+q/Za1JrCODcQQP6x8AAAApwgfAADAKcIHAABwivABAACcInwAAACnCB8AAMApwgcAAHCK8AEAAJxikzEPnJhn32Co6m+f7cKV2OAq3h4MftTp+NBX37Re49d/P9urdqz+udD+74OMP/usNf/iv73jRTu4iGvnHbLWuNpAzKWTD9u/952cctZaM/QvfmtNbvmuLvXU3/zv/zzJWnPVb5s7L3iv2qNuvMPKBwAAcIrwAQAAnCJ8AAAApwgfAADAKcIHAABwivABAACcInwAAACnCB8AAMApnzHG9HYTXxaJRBQMBlWoO5XsS+ntdrrk+ONTrDV/fuwFB51gIPoPDROtNR+Ma3HQycC17fgBa805cz7+jfRBKb4ka42ruelLvUju+hm7coG1Ju+pnm/i1mLOqVKbFQ6HlZaW1mktKx8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnCJ8AAAAp5J7uwH0b3933L4B25b/NdpaUz5lg7Xm7stOdKknwGvL/u+V1pqSyz900Enfc64L21i2qjX+jahv9SL1vX5c6tbKR3l5uSZMmKBAIKDMzEzNmjVLH37Y9gvKGKOysjLl5OQoNTVVhYWFOnTokKdNAwCAxNWt8FFVVaWSkhLt3r1bFRUVamlpUVFRkZqbm2M1zzzzjJYtW6YVK1Zoz549CoVCuv3229XU1OR58wAAIPF0622XN998s83rVatWKTMzU/v27dPNN98sY4yWL1+uJUuWaPbs2ZKk1atXKysrS2vXrtW8efO86xwAACSkHj1wGg6HJUnp6emSpNraWjU0NKioqChW4/f7NX36dO3a1fGH1kSjUUUikTYHAADovy45fBhjtHDhQk2dOlWjR3/xwGBDQ4MkKSsrq01tVlZWbOyrysvLFQwGY0deXt6ltgQAABLAJYeP+fPn6+DBg3r99dfbjfl8vjavjTHtzl2wePFihcPh2FFXV3epLQEAgARwST9qu2DBAr3xxhvauXOncnNzY+dDoZCkL1ZAsrOzY+cbGxvbrYZc4Pf75ff7L6UNAACQgLq18mGM0fz587Vhwwbt2LFDBQUFbcYLCgoUCoVUUVERO3f27FlVVVVpyhT7fg8AAKD/69bKR0lJidauXavNmzcrEAjEnuMIBoNKTU2Vz+dTaWmpli5dqhEjRmjEiBFaunSphg4dqvvvvz8uv4G+YMj/se8U83HLGWtNbnKqF+144tq3HrLWXLXS/vtO+fiktWbksX3WmjWjiqw1//F76daa0m//j07H/13wqPUaXjlnzltrnvjEHtr//NMbrTWpeq9LPeHSrH75DmvN0HlRB5184fsO/xy7Em49a63Z0DSy0/ExQ+xv6493uBA/aucPPLlOxubO/+742kH7Boz270be6lb4WLlypSSpsLCwzflVq1Zp7ty5kqTHH39cZ86c0aOPPqpPP/1UEydO1Pbt2xUIBDxpGAAAJLZuhQ9j7P/S9fl8KisrU1lZ2aX2BAAA+jE+WA4AADhF+AAAAE4RPgAAgFOEDwAA4BThAwAAOEX4AAAATvlMV35+1qFIJKJgMKhC3alkX0pvt+OZuiX2zaL+56MvOOjkC1P239fpeMZ3PrJeo/Xzz71qx5mkkVd1Ol737Y4/BiAeBnVhV5/Qf+n406AxgF3kc7K+rG7J5B7f5qF737TWvH50vLWmeXdGj3uRpMFhe03WC51/vbROu8F6jX+e7m6zx7yn+tfXd4s5p0ptVjgcVlpaWqe1rHwAAACnCB8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnGKTMQAA0GNsMgYAAPoswgcAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnCJ8AAAApwgfAADAKcIHAABwivABAACcInwAAACnCB8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwKluhY/y8nJNmDBBgUBAmZmZmjVrlj788MM2NXPnzpXP52tzTJo0ydOmAQBA4upW+KiqqlJJSYl2796tiooKtbS0qKioSM3NzW3q7rjjDtXX18eOrVu3eto0AABIXMndKX7zzTfbvF61apUyMzO1b98+3XzzzbHzfr9foVDImw4BAEC/0qNnPsLhsCQpPT29zfnKykplZmZq5MiRevjhh9XY2HjRa0SjUUUikTYHAADovy45fBhjtHDhQk2dOlWjR4+OnS8uLtZrr72mHTt26LnnntOePXt0yy23KBqNdnid8vJyBYPB2JGXl3epLQEAgATgM8aYS/mFJSUl2rJli95++23l5uZetK6+vl75+flat26dZs+e3W48Go22CSaRSER5eXkq1J1K9qVcSmsAAMCxFnNOldqscDistLS0Tmu79czHBQsWLNAbb7yhnTt3dho8JCk7O1v5+fmqqanpcNzv98vv919KGwAAIAF1K3wYY7RgwQJt3LhRlZWVKigosP6akydPqq6uTtnZ2ZfcJAAA6D+69cxHSUmJXn31Va1du1aBQEANDQ1qaGjQmTNnJEmnT5/WokWL9M477+jo0aOqrKzUzJkzlZGRobvuuisuvwEAAJBYurXysXLlSklSYWFhm/OrVq3S3LlzlZSUpOrqaq1Zs0anTp1Sdna2ZsyYofXr1ysQCHjWNAAASFzdftulM6mpqdq2bVuPGgIAAP0bn+0CAACcInwAAACnCB8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnCJ8AAAApwgfAADAKcIHAABwivABAACcInwAAACnknu7ga8yxkiSWnROMr3cDAAA6JIWnZP0//8e70yfCx9NTU2SpLe1tZc7AQAA3dXU1KRgMNhpjc90JaI41NraquPHjysQCMjn80mSIpGI8vLyVFdXp7S0tF7usP9hfuOPOY4/5ji+mN/4S/Q5NsaoqalJOTk5GjSo86c6+tzKx6BBg5Sbm9vhWFpaWkL+D0kUzG/8McfxxxzHF/Mbf4k8x7YVjwt44BQAADhF+AAAAE4lRPjw+/168skn5ff7e7uVfon5jT/mOP6Y4/hifuNvIM1xn3vgFAAA9G8JsfIBAAD6D8IHAABwivABAACcInwAAACnCB8AAMCpPh8+XnzxRRUUFGjIkCEaN26c/vSnP/V2Swlr586dmjlzpnJycuTz+bRp06Y248YYlZWVKScnR6mpqSosLNShQ4d6p9kEVF5ergkTJigQCCgzM1OzZs3Shx9+2KaGOe6ZlStX6vrrr4/tADl58mT9/ve/j40zv94qLy+Xz+dTaWlp7Bxz3DNlZWXy+XxtjlAoFBsfKPPbp8PH+vXrVVpaqiVLlmj//v2aNm2aiouL9dFHH/V2awmpublZY8eO1YoVKzocf+aZZ7Rs2TKtWLFCe/bsUSgU0u233x77sD90rqqqSiUlJdq9e7cqKirU0tKioqIiNTc3x2qY457Jzc3V008/rb1792rv3r265ZZbdOedd8a+OTO/3tmzZ49eeuklXX/99W3OM8c9N2rUKNXX18eO6urq2NiAmV/Th910003mkUceaXPu2muvNT/+8Y97qaP+Q5LZuHFj7HVra6sJhULm6aefjp37/PPPTTAYNL/85S97ocPE19jYaCSZqqoqYwxzHC+XX365+fWvf838eqipqcmMGDHCVFRUmOnTp5vHHnvMGMOfYS88+eSTZuzYsR2ODaT57bMrH2fPntW+fftUVFTU5nxRUZF27drVS131X7W1tWpoaGgz336/X9OnT2e+L1E4HJYkpaenS2KOvXb+/HmtW7dOzc3Nmjx5MvProZKSEn3zm9/Ubbfd1uY8c+yNmpoa5eTkqKCgQPfee6+OHDkiaWDNb5/7VNsLTpw4ofPnzysrK6vN+aysLDU0NPRSV/3XhTntaL6PHTvWGy0lNGOMFi5cqKlTp2r06NGSmGOvVFdXa/Lkyfr888912WWXaePGjfr6178e++bM/PbMunXrtG/fPu3du7fdGH+Ge27ixIlas2aNRo4cqU8++URPPfWUpkyZokOHDg2o+e2z4eMCn8/X5rUxpt05eIf59sb8+fN18OBBvf322+3GmOOeueaaa3TgwAGdOnVKv/vd7zRnzhxVVVXFxpnfS1dXV6fHHntM27dv15AhQy5axxxfuuLi4th/jxkzRpMnT9ZVV12l1atXa9KkSZIGxvz22bddMjIylJSU1G6Vo7GxsV0qRM9deNqa+e65BQsW6I033tBbb72l3Nzc2Hnm2BuDBw/W1VdfrfHjx6u8vFxjx47V888/z/x6YN++fWpsbNS4ceOUnJys5ORkVVVV6ec//7mSk5Nj88gce2fYsGEaM2aMampqBtSf4T4bPgYPHqxx48apoqKizfmKigpNmTKll7rqvwoKChQKhdrM99mzZ1VVVcV8d5ExRvPnz9eGDRu0Y8cOFRQUtBlnjuPDGKNoNMr8euDWW29VdXW1Dhw4EDvGjx+vBx54QAcOHNCVV17JHHssGo3qgw8+UHZ29sD6M9xrj7p2wbp160xKSop55ZVXzPvvv29KS0vNsGHDzNGjR3u7tYTU1NRk9u/fb/bv328kmWXLlpn9+/ebY8eOGWOMefrpp00wGDQbNmww1dXV5r777jPZ2dkmEon0cueJ4Yc//KEJBoOmsrLS1NfXx47PPvssVsMc98zixYvNzp07TW1trTl48KB54oknzKBBg8z27duNMcxvPHz5p12MYY576kc/+pGprKw0R44cMbt37zbf+ta3TCAQiP29NlDmt0+HD2OM+cUvfmHy8/PN4MGDzY033hj7sUV031tvvWUktTvmzJljjPnix7yefPJJEwqFjN/vNzfffLOprq7u3aYTSEdzK8msWrUqVsMc98wPfvCD2PeDK664wtx6662x4GEM8xsPXw0fzHHP3HPPPSY7O9ukpKSYnJwcM3v2bHPo0KHY+ECZX58xxvTOmgsAABiI+uwzHwAAoH8ifAAAAKcIHwAAwCnCBwAAcIrwAQAAnCJ8AAAApwgfAADAKcIHAABwivABAACcInwAAACnCB8AAMCp/wf7xsmloAjRoQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image0 = df.iloc[3, :-1]\n",
    "image0\n",
    "plt.imshow(np.array(image0).reshape(28,56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c77b85a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('data/train_result.csv', index_col = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42d486ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.values.reshape(y.values.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "131fcdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df.iloc[:40000, :-1]\n",
    "y_train = y[:40000]\n",
    "x_test = df.iloc[40000:, :-1]\n",
    "y_test = y[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "284ec0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c6132d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4165"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.score(x_test , y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "c61984a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rforest = RandomForestClassifier()\n",
    "rforest.fit(x_train , np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "aeb6bcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7092"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rforest.score(x_test,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "796ccb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train ,np.ravel(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "536980ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3eb3188f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6228"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0a80b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf27494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dff5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1908d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "959969b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f970e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a53645c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Lambda, MaxPooling2D # convolution layers\n",
    "from keras.layers import Dense, Dropout, Flatten # core layers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1eb8a98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10728\\1710797709.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "882a2e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_train.values.reshape(-1,28,56,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c187d864",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x_test.values.reshape(-1,28,56,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf4f725e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28d182040>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6a19cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2567d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5daf1c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 19)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23d14423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "254867a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 28, 56, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3700522f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 18:49:07.438024: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-24 18:49:07.438864: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "X_train__ = X.reshape(X.shape[0], 28, 56)\n",
    "\n",
    "fig, axis = plt.subplots(1, 4, figsize=(20, 10))\n",
    "for i, ax in enumerate(axis.flat):\n",
    "    ax.imshow(X_train__[i], cmap='binary')\n",
    "    digit = y_train[i].argmax()\n",
    "    ax.set(title = f\"Real Number is {digit}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70782061",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X)\n",
    "std = np.std(X)\n",
    "\n",
    "def standardize(x):\n",
    "    return (x-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75283b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 56, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d16ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.add(Lambda(standardize,input_shape=(28,56,1)))    \n",
    "model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\", input_shape=X.shape[1:]))\n",
    "model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())    \n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "    \n",
    "model.add(Dense(19,activation=\"softmax\"))\n",
    "    \n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65a09c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 54, 64)        640       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 52, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 26, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 12, 26, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 24, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 22, 128)        147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 4, 11, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 4, 11, 128)       512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 2, 9, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1, 4, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 19)                9747      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,090,515\n",
      "Trainable params: 1,089,619\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "217b640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 128\n",
    "train_steps = X.shape[0] // batch_size\n",
    "valid_steps = X_test.shape[0] // batch_size\n",
    "\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_acc\", # metrics to monitor\n",
    "        patience=10, # how many epochs before stop\n",
    "        verbose=1,\n",
    "        mode=\"max\", # we need the maximum accuracy.\n",
    "        restore_best_weights=True, # \n",
    "     )\n",
    "\n",
    "rp = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_acc\",\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        verbose=1,\n",
    "        mode=\"max\",\n",
    "        min_lr=0.00001,\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ef828a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 56, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "89bd97d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 19:12:59.005029: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66/313 [=====>........................] - ETA: 18s - loss: 0.0228 - accuracy: 0.9923"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y_train, batch_size=batch_size, validation_split=0.2, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e72eba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14/313 [>.............................] - ETA: 2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 18:52:25.817311: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "769c481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56a1187b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at confusion matrix \n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_test)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "# Y_true = to_categorical(y_test)\n",
    "Y_true = np.argmax(y_test,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(19)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14a2495c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  2, 17, ...,  1,  7,  9])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da38baa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_submission(arr):\n",
    "    with open('submission.csv', 'w') as f:\n",
    "        f.writelines('Index, Class\\n')\n",
    "        for x in range(arr.shape[0]):\n",
    "            print(str(x)+', '+ str(arr[x]))\n",
    "            f.writelines(str(x)+', '+ str(arr[x])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d43d014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 12\n",
      "1, 2\n",
      "2, 17\n",
      "3, 13\n",
      "4, 7\n",
      "5, 6\n",
      "6, 12\n",
      "7, 8\n",
      "8, 6\n",
      "9, 8\n",
      "10, 4\n",
      "11, 3\n",
      "12, 8\n",
      "13, 12\n",
      "14, 7\n",
      "15, 11\n",
      "16, 3\n",
      "17, 15\n",
      "18, 16\n",
      "19, 5\n",
      "20, 16\n",
      "21, 12\n",
      "22, 9\n",
      "23, 11\n",
      "24, 11\n",
      "25, 16\n",
      "26, 7\n",
      "27, 10\n",
      "28, 12\n",
      "29, 2\n",
      "30, 11\n",
      "31, 11\n",
      "32, 7\n",
      "33, 4\n",
      "34, 5\n",
      "35, 14\n",
      "36, 7\n",
      "37, 6\n",
      "38, 2\n",
      "39, 2\n",
      "40, 12\n",
      "41, 8\n",
      "42, 8\n",
      "43, 9\n",
      "44, 12\n",
      "45, 10\n",
      "46, 6\n",
      "47, 11\n",
      "48, 10\n",
      "49, 13\n",
      "50, 8\n",
      "51, 12\n",
      "52, 5\n",
      "53, 11\n",
      "54, 1\n",
      "55, 10\n",
      "56, 17\n",
      "57, 7\n",
      "58, 6\n",
      "59, 6\n",
      "60, 6\n",
      "61, 15\n",
      "62, 4\n",
      "63, 9\n",
      "64, 13\n",
      "65, 12\n",
      "66, 1\n",
      "67, 15\n",
      "68, 14\n",
      "69, 6\n",
      "70, 9\n",
      "71, 17\n",
      "72, 10\n",
      "73, 9\n",
      "74, 7\n",
      "75, 14\n",
      "76, 3\n",
      "77, 8\n",
      "78, 15\n",
      "79, 5\n",
      "80, 4\n",
      "81, 6\n",
      "82, 3\n",
      "83, 6\n",
      "84, 14\n",
      "85, 8\n",
      "86, 6\n",
      "87, 6\n",
      "88, 8\n",
      "89, 13\n",
      "90, 12\n",
      "91, 11\n",
      "92, 13\n",
      "93, 6\n",
      "94, 9\n",
      "95, 10\n",
      "96, 4\n",
      "97, 4\n",
      "98, 6\n",
      "99, 1\n",
      "100, 14\n",
      "101, 10\n",
      "102, 5\n",
      "103, 11\n",
      "104, 10\n",
      "105, 4\n",
      "106, 11\n",
      "107, 6\n",
      "108, 1\n",
      "109, 1\n",
      "110, 9\n",
      "111, 5\n",
      "112, 4\n",
      "113, 9\n",
      "114, 7\n",
      "115, 16\n",
      "116, 4\n",
      "117, 15\n",
      "118, 2\n",
      "119, 14\n",
      "120, 12\n",
      "121, 15\n",
      "122, 7\n",
      "123, 14\n",
      "124, 15\n",
      "125, 5\n",
      "126, 15\n",
      "127, 6\n",
      "128, 6\n",
      "129, 10\n",
      "130, 13\n",
      "131, 5\n",
      "132, 16\n",
      "133, 16\n",
      "134, 16\n",
      "135, 12\n",
      "136, 15\n",
      "137, 6\n",
      "138, 6\n",
      "139, 4\n",
      "140, 13\n",
      "141, 3\n",
      "142, 13\n",
      "143, 7\n",
      "144, 5\n",
      "145, 9\n",
      "146, 6\n",
      "147, 9\n",
      "148, 4\n",
      "149, 3\n",
      "150, 10\n",
      "151, 12\n",
      "152, 11\n",
      "153, 5\n",
      "154, 8\n",
      "155, 10\n",
      "156, 14\n",
      "157, 11\n",
      "158, 14\n",
      "159, 9\n",
      "160, 6\n",
      "161, 10\n",
      "162, 10\n",
      "163, 10\n",
      "164, 8\n",
      "165, 15\n",
      "166, 11\n",
      "167, 14\n",
      "168, 14\n",
      "169, 12\n",
      "170, 2\n",
      "171, 3\n",
      "172, 9\n",
      "173, 11\n",
      "174, 7\n",
      "175, 9\n",
      "176, 9\n",
      "177, 4\n",
      "178, 6\n",
      "179, 4\n",
      "180, 11\n",
      "181, 6\n",
      "182, 6\n",
      "183, 15\n",
      "184, 12\n",
      "185, 13\n",
      "186, 12\n",
      "187, 12\n",
      "188, 5\n",
      "189, 12\n",
      "190, 8\n",
      "191, 12\n",
      "192, 9\n",
      "193, 12\n",
      "194, 3\n",
      "195, 7\n",
      "196, 7\n",
      "197, 11\n",
      "198, 8\n",
      "199, 9\n",
      "200, 8\n",
      "201, 12\n",
      "202, 8\n",
      "203, 11\n",
      "204, 10\n",
      "205, 9\n",
      "206, 11\n",
      "207, 11\n",
      "208, 7\n",
      "209, 12\n",
      "210, 13\n",
      "211, 8\n",
      "212, 12\n",
      "213, 2\n",
      "214, 13\n",
      "215, 9\n",
      "216, 4\n",
      "217, 1\n",
      "218, 4\n",
      "219, 10\n",
      "220, 7\n",
      "221, 8\n",
      "222, 6\n",
      "223, 8\n",
      "224, 8\n",
      "225, 10\n",
      "226, 6\n",
      "227, 10\n",
      "228, 10\n",
      "229, 2\n",
      "230, 4\n",
      "231, 10\n",
      "232, 16\n",
      "233, 13\n",
      "234, 3\n",
      "235, 12\n",
      "236, 4\n",
      "237, 3\n",
      "238, 8\n",
      "239, 12\n",
      "240, 13\n",
      "241, 8\n",
      "242, 8\n",
      "243, 3\n",
      "244, 7\n",
      "245, 12\n",
      "246, 11\n",
      "247, 10\n",
      "248, 10\n",
      "249, 18\n",
      "250, 14\n",
      "251, 8\n",
      "252, 11\n",
      "253, 7\n",
      "254, 14\n",
      "255, 9\n",
      "256, 9\n",
      "257, 8\n",
      "258, 11\n",
      "259, 12\n",
      "260, 2\n",
      "261, 11\n",
      "262, 10\n",
      "263, 3\n",
      "264, 6\n",
      "265, 10\n",
      "266, 17\n",
      "267, 9\n",
      "268, 2\n",
      "269, 16\n",
      "270, 12\n",
      "271, 7\n",
      "272, 10\n",
      "273, 9\n",
      "274, 9\n",
      "275, 13\n",
      "276, 9\n",
      "277, 9\n",
      "278, 11\n",
      "279, 6\n",
      "280, 10\n",
      "281, 10\n",
      "282, 5\n",
      "283, 4\n",
      "284, 7\n",
      "285, 11\n",
      "286, 11\n",
      "287, 16\n",
      "288, 14\n",
      "289, 11\n",
      "290, 11\n",
      "291, 12\n",
      "292, 11\n",
      "293, 11\n",
      "294, 8\n",
      "295, 8\n",
      "296, 14\n",
      "297, 9\n",
      "298, 8\n",
      "299, 9\n",
      "300, 10\n",
      "301, 16\n",
      "302, 11\n",
      "303, 5\n",
      "304, 7\n",
      "305, 5\n",
      "306, 2\n",
      "307, 9\n",
      "308, 3\n",
      "309, 7\n",
      "310, 11\n",
      "311, 6\n",
      "312, 10\n",
      "313, 12\n",
      "314, 13\n",
      "315, 13\n",
      "316, 15\n",
      "317, 5\n",
      "318, 8\n",
      "319, 16\n",
      "320, 11\n",
      "321, 10\n",
      "322, 9\n",
      "323, 11\n",
      "324, 5\n",
      "325, 7\n",
      "326, 14\n",
      "327, 7\n",
      "328, 10\n",
      "329, 8\n",
      "330, 9\n",
      "331, 7\n",
      "332, 7\n",
      "333, 8\n",
      "334, 11\n",
      "335, 12\n",
      "336, 15\n",
      "337, 12\n",
      "338, 15\n",
      "339, 4\n",
      "340, 4\n",
      "341, 15\n",
      "342, 11\n",
      "343, 17\n",
      "344, 9\n",
      "345, 7\n",
      "346, 6\n",
      "347, 16\n",
      "348, 9\n",
      "349, 13\n",
      "350, 7\n",
      "351, 10\n",
      "352, 14\n",
      "353, 14\n",
      "354, 10\n",
      "355, 14\n",
      "356, 17\n",
      "357, 13\n",
      "358, 17\n",
      "359, 16\n",
      "360, 2\n",
      "361, 4\n",
      "362, 6\n",
      "363, 2\n",
      "364, 12\n",
      "365, 3\n",
      "366, 9\n",
      "367, 11\n",
      "368, 5\n",
      "369, 14\n",
      "370, 13\n",
      "371, 8\n",
      "372, 12\n",
      "373, 8\n",
      "374, 10\n",
      "375, 15\n",
      "376, 10\n",
      "377, 8\n",
      "378, 12\n",
      "379, 10\n",
      "380, 7\n",
      "381, 6\n",
      "382, 12\n",
      "383, 12\n",
      "384, 5\n",
      "385, 12\n",
      "386, 7\n",
      "387, 15\n",
      "388, 15\n",
      "389, 4\n",
      "390, 9\n",
      "391, 10\n",
      "392, 15\n",
      "393, 6\n",
      "394, 5\n",
      "395, 13\n",
      "396, 9\n",
      "397, 8\n",
      "398, 9\n",
      "399, 11\n",
      "400, 3\n",
      "401, 9\n",
      "402, 10\n",
      "403, 8\n",
      "404, 14\n",
      "405, 7\n",
      "406, 4\n",
      "407, 10\n",
      "408, 3\n",
      "409, 10\n",
      "410, 11\n",
      "411, 12\n",
      "412, 2\n",
      "413, 16\n",
      "414, 13\n",
      "415, 7\n",
      "416, 9\n",
      "417, 1\n",
      "418, 0\n",
      "419, 0\n",
      "420, 10\n",
      "421, 15\n",
      "422, 0\n",
      "423, 17\n",
      "424, 16\n",
      "425, 8\n",
      "426, 13\n",
      "427, 10\n",
      "428, 8\n",
      "429, 9\n",
      "430, 11\n",
      "431, 11\n",
      "432, 9\n",
      "433, 10\n",
      "434, 5\n",
      "435, 9\n",
      "436, 4\n",
      "437, 10\n",
      "438, 7\n",
      "439, 6\n",
      "440, 1\n",
      "441, 5\n",
      "442, 7\n",
      "443, 3\n",
      "444, 7\n",
      "445, 12\n",
      "446, 11\n",
      "447, 12\n",
      "448, 14\n",
      "449, 2\n",
      "450, 9\n",
      "451, 9\n",
      "452, 3\n",
      "453, 12\n",
      "454, 4\n",
      "455, 10\n",
      "456, 10\n",
      "457, 8\n",
      "458, 3\n",
      "459, 12\n",
      "460, 11\n",
      "461, 10\n",
      "462, 10\n",
      "463, 5\n",
      "464, 6\n",
      "465, 9\n",
      "466, 9\n",
      "467, 9\n",
      "468, 9\n",
      "469, 8\n",
      "470, 16\n",
      "471, 9\n",
      "472, 9\n",
      "473, 8\n",
      "474, 7\n",
      "475, 13\n",
      "476, 11\n",
      "477, 18\n",
      "478, 2\n",
      "479, 14\n",
      "480, 3\n",
      "481, 11\n",
      "482, 12\n",
      "483, 0\n",
      "484, 0\n",
      "485, 11\n",
      "486, 10\n",
      "487, 8\n",
      "488, 11\n",
      "489, 9\n",
      "490, 6\n",
      "491, 7\n",
      "492, 11\n",
      "493, 7\n",
      "494, 5\n",
      "495, 1\n",
      "496, 16\n",
      "497, 13\n",
      "498, 0\n",
      "499, 9\n",
      "500, 9\n",
      "501, 9\n",
      "502, 1\n",
      "503, 3\n",
      "504, 6\n",
      "505, 13\n",
      "506, 9\n",
      "507, 3\n",
      "508, 7\n",
      "509, 8\n",
      "510, 6\n",
      "511, 10\n",
      "512, 14\n",
      "513, 9\n",
      "514, 2\n",
      "515, 4\n",
      "516, 12\n",
      "517, 12\n",
      "518, 10\n",
      "519, 14\n",
      "520, 11\n",
      "521, 10\n",
      "522, 8\n",
      "523, 15\n",
      "524, 5\n",
      "525, 13\n",
      "526, 7\n",
      "527, 13\n",
      "528, 13\n",
      "529, 13\n",
      "530, 7\n",
      "531, 5\n",
      "532, 7\n",
      "533, 4\n",
      "534, 6\n",
      "535, 4\n",
      "536, 7\n",
      "537, 5\n",
      "538, 13\n",
      "539, 1\n",
      "540, 15\n",
      "541, 6\n",
      "542, 14\n",
      "543, 9\n",
      "544, 10\n",
      "545, 10\n",
      "546, 7\n",
      "547, 14\n",
      "548, 3\n",
      "549, 2\n",
      "550, 1\n",
      "551, 13\n",
      "552, 4\n",
      "553, 17\n",
      "554, 15\n",
      "555, 10\n",
      "556, 8\n",
      "557, 6\n",
      "558, 4\n",
      "559, 10\n",
      "560, 5\n",
      "561, 7\n",
      "562, 14\n",
      "563, 8\n",
      "564, 11\n",
      "565, 9\n",
      "566, 6\n",
      "567, 7\n",
      "568, 9\n",
      "569, 5\n",
      "570, 13\n",
      "571, 13\n",
      "572, 13\n",
      "573, 7\n",
      "574, 13\n",
      "575, 8\n",
      "576, 10\n",
      "577, 8\n",
      "578, 7\n",
      "579, 13\n",
      "580, 3\n",
      "581, 12\n",
      "582, 6\n",
      "583, 8\n",
      "584, 13\n",
      "585, 7\n",
      "586, 5\n",
      "587, 3\n",
      "588, 11\n",
      "589, 7\n",
      "590, 15\n",
      "591, 2\n",
      "592, 2\n",
      "593, 11\n",
      "594, 9\n",
      "595, 2\n",
      "596, 5\n",
      "597, 10\n",
      "598, 2\n",
      "599, 5\n",
      "600, 9\n",
      "601, 15\n",
      "602, 13\n",
      "603, 11\n",
      "604, 11\n",
      "605, 6\n",
      "606, 13\n",
      "607, 5\n",
      "608, 3\n",
      "609, 11\n",
      "610, 8\n",
      "611, 15\n",
      "612, 11\n",
      "613, 13\n",
      "614, 3\n",
      "615, 7\n",
      "616, 7\n",
      "617, 11\n",
      "618, 6\n",
      "619, 16\n",
      "620, 13\n",
      "621, 1\n",
      "622, 6\n",
      "623, 10\n",
      "624, 4\n",
      "625, 11\n",
      "626, 9\n",
      "627, 10\n",
      "628, 15\n",
      "629, 15\n",
      "630, 8\n",
      "631, 6\n",
      "632, 14\n",
      "633, 14\n",
      "634, 5\n",
      "635, 3\n",
      "636, 3\n",
      "637, 7\n",
      "638, 6\n",
      "639, 5\n",
      "640, 6\n",
      "641, 7\n",
      "642, 3\n",
      "643, 9\n",
      "644, 10\n",
      "645, 8\n",
      "646, 2\n",
      "647, 15\n",
      "648, 9\n",
      "649, 5\n",
      "650, 10\n",
      "651, 12\n",
      "652, 7\n",
      "653, 16\n",
      "654, 10\n",
      "655, 9\n",
      "656, 5\n",
      "657, 6\n",
      "658, 1\n",
      "659, 4\n",
      "660, 1\n",
      "661, 5\n",
      "662, 13\n",
      "663, 14\n",
      "664, 13\n",
      "665, 10\n",
      "666, 7\n",
      "667, 13\n",
      "668, 11\n",
      "669, 10\n",
      "670, 7\n",
      "671, 4\n",
      "672, 10\n",
      "673, 5\n",
      "674, 11\n",
      "675, 11\n",
      "676, 8\n",
      "677, 9\n",
      "678, 8\n",
      "679, 6\n",
      "680, 12\n",
      "681, 5\n",
      "682, 4\n",
      "683, 7\n",
      "684, 4\n",
      "685, 6\n",
      "686, 14\n",
      "687, 7\n",
      "688, 9\n",
      "689, 10\n",
      "690, 12\n",
      "691, 9\n",
      "692, 5\n",
      "693, 11\n",
      "694, 6\n",
      "695, 11\n",
      "696, 17\n",
      "697, 12\n",
      "698, 10\n",
      "699, 3\n",
      "700, 16\n",
      "701, 4\n",
      "702, 8\n",
      "703, 11\n",
      "704, 4\n",
      "705, 14\n",
      "706, 6\n",
      "707, 12\n",
      "708, 9\n",
      "709, 2\n",
      "710, 3\n",
      "711, 13\n",
      "712, 0\n",
      "713, 13\n",
      "714, 8\n",
      "715, 11\n",
      "716, 15\n",
      "717, 15\n",
      "718, 6\n",
      "719, 9\n",
      "720, 13\n",
      "721, 8\n",
      "722, 6\n",
      "723, 9\n",
      "724, 11\n",
      "725, 10\n",
      "726, 9\n",
      "727, 7\n",
      "728, 5\n",
      "729, 11\n",
      "730, 11\n",
      "731, 14\n",
      "732, 12\n",
      "733, 11\n",
      "734, 8\n",
      "735, 9\n",
      "736, 10\n",
      "737, 5\n",
      "738, 6\n",
      "739, 8\n",
      "740, 13\n",
      "741, 8\n",
      "742, 3\n",
      "743, 5\n",
      "744, 7\n",
      "745, 10\n",
      "746, 10\n",
      "747, 15\n",
      "748, 8\n",
      "749, 12\n",
      "750, 7\n",
      "751, 8\n",
      "752, 13\n",
      "753, 6\n",
      "754, 13\n",
      "755, 11\n",
      "756, 6\n",
      "757, 9\n",
      "758, 4\n",
      "759, 9\n",
      "760, 11\n",
      "761, 7\n",
      "762, 9\n",
      "763, 6\n",
      "764, 2\n",
      "765, 9\n",
      "766, 10\n",
      "767, 8\n",
      "768, 1\n",
      "769, 4\n",
      "770, 12\n",
      "771, 8\n",
      "772, 10\n",
      "773, 6\n",
      "774, 14\n",
      "775, 12\n",
      "776, 12\n",
      "777, 7\n",
      "778, 15\n",
      "779, 7\n",
      "780, 17\n",
      "781, 11\n",
      "782, 11\n",
      "783, 14\n",
      "784, 3\n",
      "785, 4\n",
      "786, 8\n",
      "787, 11\n",
      "788, 9\n",
      "789, 8\n",
      "790, 15\n",
      "791, 7\n",
      "792, 7\n",
      "793, 7\n",
      "794, 8\n",
      "795, 7\n",
      "796, 18\n",
      "797, 2\n",
      "798, 2\n",
      "799, 7\n",
      "800, 5\n",
      "801, 8\n",
      "802, 3\n",
      "803, 7\n",
      "804, 11\n",
      "805, 11\n",
      "806, 13\n",
      "807, 11\n",
      "808, 9\n",
      "809, 11\n",
      "810, 7\n",
      "811, 7\n",
      "812, 9\n",
      "813, 9\n",
      "814, 6\n",
      "815, 12\n",
      "816, 9\n",
      "817, 16\n",
      "818, 4\n",
      "819, 5\n",
      "820, 8\n",
      "821, 3\n",
      "822, 5\n",
      "823, 2\n",
      "824, 9\n",
      "825, 6\n",
      "826, 12\n",
      "827, 14\n",
      "828, 14\n",
      "829, 6\n",
      "830, 13\n",
      "831, 1\n",
      "832, 6\n",
      "833, 3\n",
      "834, 9\n",
      "835, 12\n",
      "836, 9\n",
      "837, 7\n",
      "838, 6\n",
      "839, 0\n",
      "840, 10\n",
      "841, 8\n",
      "842, 12\n",
      "843, 14\n",
      "844, 13\n",
      "845, 8\n",
      "846, 12\n",
      "847, 9\n",
      "848, 8\n",
      "849, 10\n",
      "850, 12\n",
      "851, 12\n",
      "852, 12\n",
      "853, 9\n",
      "854, 4\n",
      "855, 9\n",
      "856, 6\n",
      "857, 3\n",
      "858, 9\n",
      "859, 12\n",
      "860, 1\n",
      "861, 9\n",
      "862, 12\n",
      "863, 10\n",
      "864, 5\n",
      "865, 11\n",
      "866, 15\n",
      "867, 9\n",
      "868, 10\n",
      "869, 1\n",
      "870, 15\n",
      "871, 6\n",
      "872, 16\n",
      "873, 4\n",
      "874, 3\n",
      "875, 7\n",
      "876, 11\n",
      "877, 7\n",
      "878, 5\n",
      "879, 8\n",
      "880, 16\n",
      "881, 10\n",
      "882, 15\n",
      "883, 5\n",
      "884, 10\n",
      "885, 13\n",
      "886, 5\n",
      "887, 16\n",
      "888, 1\n",
      "889, 17\n",
      "890, 2\n",
      "891, 10\n",
      "892, 8\n",
      "893, 10\n",
      "894, 5\n",
      "895, 2\n",
      "896, 9\n",
      "897, 13\n",
      "898, 17\n",
      "899, 11\n",
      "900, 2\n",
      "901, 2\n",
      "902, 13\n",
      "903, 10\n",
      "904, 10\n",
      "905, 13\n",
      "906, 8\n",
      "907, 12\n",
      "908, 6\n",
      "909, 6\n",
      "910, 9\n",
      "911, 3\n",
      "912, 8\n",
      "913, 12\n",
      "914, 2\n",
      "915, 11\n",
      "916, 7\n",
      "917, 11\n",
      "918, 1\n",
      "919, 5\n",
      "920, 12\n",
      "921, 15\n",
      "922, 7\n",
      "923, 4\n",
      "924, 5\n",
      "925, 7\n",
      "926, 9\n",
      "927, 14\n",
      "928, 10\n",
      "929, 5\n",
      "930, 5\n",
      "931, 16\n",
      "932, 14\n",
      "933, 7\n",
      "934, 17\n",
      "935, 1\n",
      "936, 16\n",
      "937, 8\n",
      "938, 13\n",
      "939, 9\n",
      "940, 10\n",
      "941, 8\n",
      "942, 5\n",
      "943, 8\n",
      "944, 17\n",
      "945, 5\n",
      "946, 8\n",
      "947, 16\n",
      "948, 8\n",
      "949, 11\n",
      "950, 9\n",
      "951, 4\n",
      "952, 13\n",
      "953, 13\n",
      "954, 5\n",
      "955, 1\n",
      "956, 13\n",
      "957, 13\n",
      "958, 16\n",
      "959, 10\n",
      "960, 5\n",
      "961, 1\n",
      "962, 9\n",
      "963, 7\n",
      "964, 7\n",
      "965, 13\n",
      "966, 9\n",
      "967, 4\n",
      "968, 10\n",
      "969, 1\n",
      "970, 6\n",
      "971, 2\n",
      "972, 5\n",
      "973, 12\n",
      "974, 7\n",
      "975, 6\n",
      "976, 10\n",
      "977, 8\n",
      "978, 5\n",
      "979, 8\n",
      "980, 4\n",
      "981, 9\n",
      "982, 2\n",
      "983, 2\n",
      "984, 10\n",
      "985, 2\n",
      "986, 16\n",
      "987, 10\n",
      "988, 10\n",
      "989, 8\n",
      "990, 13\n",
      "991, 9\n",
      "992, 9\n",
      "993, 7\n",
      "994, 6\n",
      "995, 0\n",
      "996, 4\n",
      "997, 13\n",
      "998, 8\n",
      "999, 9\n",
      "1000, 2\n",
      "1001, 12\n",
      "1002, 11\n",
      "1003, 8\n",
      "1004, 17\n",
      "1005, 13\n",
      "1006, 9\n",
      "1007, 12\n",
      "1008, 10\n",
      "1009, 8\n",
      "1010, 11\n",
      "1011, 9\n",
      "1012, 3\n",
      "1013, 5\n",
      "1014, 10\n",
      "1015, 7\n",
      "1016, 5\n",
      "1017, 11\n",
      "1018, 3\n",
      "1019, 10\n",
      "1020, 12\n",
      "1021, 5\n",
      "1022, 7\n",
      "1023, 8\n",
      "1024, 1\n",
      "1025, 9\n",
      "1026, 10\n",
      "1027, 15\n",
      "1028, 14\n",
      "1029, 11\n",
      "1030, 12\n",
      "1031, 14\n",
      "1032, 4\n",
      "1033, 4\n",
      "1034, 16\n",
      "1035, 13\n",
      "1036, 9\n",
      "1037, 14\n",
      "1038, 12\n",
      "1039, 10\n",
      "1040, 9\n",
      "1041, 6\n",
      "1042, 11\n",
      "1043, 7\n",
      "1044, 8\n",
      "1045, 5\n",
      "1046, 5\n",
      "1047, 8\n",
      "1048, 14\n",
      "1049, 16\n",
      "1050, 11\n",
      "1051, 7\n",
      "1052, 12\n",
      "1053, 14\n",
      "1054, 7\n",
      "1055, 2\n",
      "1056, 10\n",
      "1057, 12\n",
      "1058, 5\n",
      "1059, 2\n",
      "1060, 0\n",
      "1061, 14\n",
      "1062, 7\n",
      "1063, 2\n",
      "1064, 1\n",
      "1065, 14\n",
      "1066, 16\n",
      "1067, 3\n",
      "1068, 7\n",
      "1069, 14\n",
      "1070, 10\n",
      "1071, 13\n",
      "1072, 12\n",
      "1073, 7\n",
      "1074, 6\n",
      "1075, 8\n",
      "1076, 11\n",
      "1077, 16\n",
      "1078, 5\n",
      "1079, 10\n",
      "1080, 1\n",
      "1081, 14\n",
      "1082, 10\n",
      "1083, 12\n",
      "1084, 5\n",
      "1085, 15\n",
      "1086, 4\n",
      "1087, 11\n",
      "1088, 8\n",
      "1089, 3\n",
      "1090, 6\n",
      "1091, 11\n",
      "1092, 14\n",
      "1093, 6\n",
      "1094, 9\n",
      "1095, 11\n",
      "1096, 14\n",
      "1097, 11\n",
      "1098, 13\n",
      "1099, 4\n",
      "1100, 6\n",
      "1101, 2\n",
      "1102, 0\n",
      "1103, 15\n",
      "1104, 6\n",
      "1105, 10\n",
      "1106, 8\n",
      "1107, 14\n",
      "1108, 7\n",
      "1109, 3\n",
      "1110, 7\n",
      "1111, 9\n",
      "1112, 9\n",
      "1113, 12\n",
      "1114, 7\n",
      "1115, 9\n",
      "1116, 7\n",
      "1117, 16\n",
      "1118, 1\n",
      "1119, 4\n",
      "1120, 3\n",
      "1121, 9\n",
      "1122, 8\n",
      "1123, 9\n",
      "1124, 10\n",
      "1125, 1\n",
      "1126, 5\n",
      "1127, 14\n",
      "1128, 7\n",
      "1129, 8\n",
      "1130, 12\n",
      "1131, 9\n",
      "1132, 12\n",
      "1133, 9\n",
      "1134, 9\n",
      "1135, 1\n",
      "1136, 2\n",
      "1137, 6\n",
      "1138, 11\n",
      "1139, 10\n",
      "1140, 3\n",
      "1141, 7\n",
      "1142, 3\n",
      "1143, 1\n",
      "1144, 6\n",
      "1145, 15\n",
      "1146, 11\n",
      "1147, 4\n",
      "1148, 8\n",
      "1149, 15\n",
      "1150, 13\n",
      "1151, 13\n",
      "1152, 4\n",
      "1153, 2\n",
      "1154, 7\n",
      "1155, 14\n",
      "1156, 10\n",
      "1157, 6\n",
      "1158, 13\n",
      "1159, 9\n",
      "1160, 13\n",
      "1161, 7\n",
      "1162, 7\n",
      "1163, 8\n",
      "1164, 17\n",
      "1165, 8\n",
      "1166, 2\n",
      "1167, 11\n",
      "1168, 10\n",
      "1169, 10\n",
      "1170, 3\n",
      "1171, 4\n",
      "1172, 4\n",
      "1173, 0\n",
      "1174, 5\n",
      "1175, 16\n",
      "1176, 8\n",
      "1177, 1\n",
      "1178, 9\n",
      "1179, 8\n",
      "1180, 6\n",
      "1181, 9\n",
      "1182, 15\n",
      "1183, 2\n",
      "1184, 4\n",
      "1185, 10\n",
      "1186, 13\n",
      "1187, 8\n",
      "1188, 10\n",
      "1189, 5\n",
      "1190, 13\n",
      "1191, 7\n",
      "1192, 13\n",
      "1193, 12\n",
      "1194, 12\n",
      "1195, 11\n",
      "1196, 12\n",
      "1197, 14\n",
      "1198, 4\n",
      "1199, 9\n",
      "1200, 17\n",
      "1201, 2\n",
      "1202, 7\n",
      "1203, 12\n",
      "1204, 7\n",
      "1205, 13\n",
      "1206, 13\n",
      "1207, 6\n",
      "1208, 9\n",
      "1209, 15\n",
      "1210, 13\n",
      "1211, 8\n",
      "1212, 6\n",
      "1213, 0\n",
      "1214, 18\n",
      "1215, 15\n",
      "1216, 10\n",
      "1217, 9\n",
      "1218, 16\n",
      "1219, 8\n",
      "1220, 2\n",
      "1221, 9\n",
      "1222, 11\n",
      "1223, 12\n",
      "1224, 7\n",
      "1225, 16\n",
      "1226, 12\n",
      "1227, 10\n",
      "1228, 7\n",
      "1229, 2\n",
      "1230, 1\n",
      "1231, 12\n",
      "1232, 10\n",
      "1233, 4\n",
      "1234, 10\n",
      "1235, 9\n",
      "1236, 9\n",
      "1237, 9\n",
      "1238, 5\n",
      "1239, 12\n",
      "1240, 15\n",
      "1241, 7\n",
      "1242, 16\n",
      "1243, 5\n",
      "1244, 8\n",
      "1245, 9\n",
      "1246, 13\n",
      "1247, 3\n",
      "1248, 5\n",
      "1249, 16\n",
      "1250, 7\n",
      "1251, 12\n",
      "1252, 10\n",
      "1253, 8\n",
      "1254, 12\n",
      "1255, 6\n",
      "1256, 10\n",
      "1257, 7\n",
      "1258, 8\n",
      "1259, 7\n",
      "1260, 10\n",
      "1261, 10\n",
      "1262, 15\n",
      "1263, 8\n",
      "1264, 13\n",
      "1265, 18\n",
      "1266, 17\n",
      "1267, 7\n",
      "1268, 16\n",
      "1269, 13\n",
      "1270, 9\n",
      "1271, 7\n",
      "1272, 8\n",
      "1273, 6\n",
      "1274, 11\n",
      "1275, 4\n",
      "1276, 17\n",
      "1277, 6\n",
      "1278, 13\n",
      "1279, 17\n",
      "1280, 10\n",
      "1281, 5\n",
      "1282, 9\n",
      "1283, 12\n",
      "1284, 2\n",
      "1285, 8\n",
      "1286, 10\n",
      "1287, 8\n",
      "1288, 13\n",
      "1289, 10\n",
      "1290, 12\n",
      "1291, 12\n",
      "1292, 8\n",
      "1293, 7\n",
      "1294, 13\n",
      "1295, 15\n",
      "1296, 4\n",
      "1297, 14\n",
      "1298, 10\n",
      "1299, 8\n",
      "1300, 8\n",
      "1301, 15\n",
      "1302, 4\n",
      "1303, 9\n",
      "1304, 6\n",
      "1305, 12\n",
      "1306, 4\n",
      "1307, 8\n",
      "1308, 8\n",
      "1309, 4\n",
      "1310, 6\n",
      "1311, 3\n",
      "1312, 4\n",
      "1313, 4\n",
      "1314, 8\n",
      "1315, 8\n",
      "1316, 15\n",
      "1317, 10\n",
      "1318, 14\n",
      "1319, 11\n",
      "1320, 9\n",
      "1321, 9\n",
      "1322, 10\n",
      "1323, 0\n",
      "1324, 1\n",
      "1325, 16\n",
      "1326, 7\n",
      "1327, 10\n",
      "1328, 12\n",
      "1329, 10\n",
      "1330, 17\n",
      "1331, 9\n",
      "1332, 14\n",
      "1333, 5\n",
      "1334, 5\n",
      "1335, 17\n",
      "1336, 7\n",
      "1337, 11\n",
      "1338, 5\n",
      "1339, 12\n",
      "1340, 4\n",
      "1341, 8\n",
      "1342, 6\n",
      "1343, 1\n",
      "1344, 11\n",
      "1345, 9\n",
      "1346, 1\n",
      "1347, 1\n",
      "1348, 11\n",
      "1349, 14\n",
      "1350, 11\n",
      "1351, 17\n",
      "1352, 15\n",
      "1353, 6\n",
      "1354, 8\n",
      "1355, 14\n",
      "1356, 11\n",
      "1357, 7\n",
      "1358, 7\n",
      "1359, 3\n",
      "1360, 14\n",
      "1361, 8\n",
      "1362, 16\n",
      "1363, 10\n",
      "1364, 15\n",
      "1365, 4\n",
      "1366, 8\n",
      "1367, 17\n",
      "1368, 2\n",
      "1369, 11\n",
      "1370, 3\n",
      "1371, 11\n",
      "1372, 7\n",
      "1373, 5\n",
      "1374, 10\n",
      "1375, 10\n",
      "1376, 7\n",
      "1377, 3\n",
      "1378, 4\n",
      "1379, 12\n",
      "1380, 10\n",
      "1381, 8\n",
      "1382, 3\n",
      "1383, 5\n",
      "1384, 12\n",
      "1385, 1\n",
      "1386, 13\n",
      "1387, 8\n",
      "1388, 5\n",
      "1389, 14\n",
      "1390, 12\n",
      "1391, 17\n",
      "1392, 3\n",
      "1393, 8\n",
      "1394, 9\n",
      "1395, 6\n",
      "1396, 12\n",
      "1397, 9\n",
      "1398, 8\n",
      "1399, 12\n",
      "1400, 5\n",
      "1401, 9\n",
      "1402, 11\n",
      "1403, 14\n",
      "1404, 5\n",
      "1405, 14\n",
      "1406, 9\n",
      "1407, 11\n",
      "1408, 18\n",
      "1409, 9\n",
      "1410, 10\n",
      "1411, 13\n",
      "1412, 15\n",
      "1413, 4\n",
      "1414, 17\n",
      "1415, 4\n",
      "1416, 11\n",
      "1417, 7\n",
      "1418, 11\n",
      "1419, 6\n",
      "1420, 16\n",
      "1421, 3\n",
      "1422, 6\n",
      "1423, 16\n",
      "1424, 10\n",
      "1425, 6\n",
      "1426, 7\n",
      "1427, 3\n",
      "1428, 7\n",
      "1429, 9\n",
      "1430, 7\n",
      "1431, 10\n",
      "1432, 10\n",
      "1433, 7\n",
      "1434, 12\n",
      "1435, 10\n",
      "1436, 6\n",
      "1437, 12\n",
      "1438, 14\n",
      "1439, 7\n",
      "1440, 6\n",
      "1441, 8\n",
      "1442, 15\n",
      "1443, 7\n",
      "1444, 5\n",
      "1445, 11\n",
      "1446, 11\n",
      "1447, 17\n",
      "1448, 7\n",
      "1449, 13\n",
      "1450, 12\n",
      "1451, 9\n",
      "1452, 10\n",
      "1453, 8\n",
      "1454, 14\n",
      "1455, 11\n",
      "1456, 11\n",
      "1457, 9\n",
      "1458, 10\n",
      "1459, 4\n",
      "1460, 8\n",
      "1461, 10\n",
      "1462, 12\n",
      "1463, 3\n",
      "1464, 9\n",
      "1465, 8\n",
      "1466, 13\n",
      "1467, 5\n",
      "1468, 9\n",
      "1469, 6\n",
      "1470, 16\n",
      "1471, 3\n",
      "1472, 14\n",
      "1473, 10\n",
      "1474, 7\n",
      "1475, 9\n",
      "1476, 15\n",
      "1477, 11\n",
      "1478, 10\n",
      "1479, 10\n",
      "1480, 4\n",
      "1481, 1\n",
      "1482, 8\n",
      "1483, 14\n",
      "1484, 8\n",
      "1485, 14\n",
      "1486, 8\n",
      "1487, 4\n",
      "1488, 15\n",
      "1489, 10\n",
      "1490, 8\n",
      "1491, 6\n",
      "1492, 10\n",
      "1493, 8\n",
      "1494, 9\n",
      "1495, 10\n",
      "1496, 4\n",
      "1497, 15\n",
      "1498, 9\n",
      "1499, 11\n",
      "1500, 9\n",
      "1501, 7\n",
      "1502, 9\n",
      "1503, 7\n",
      "1504, 11\n",
      "1505, 15\n",
      "1506, 11\n",
      "1507, 7\n",
      "1508, 14\n",
      "1509, 2\n",
      "1510, 4\n",
      "1511, 9\n",
      "1512, 10\n",
      "1513, 10\n",
      "1514, 13\n",
      "1515, 12\n",
      "1516, 8\n",
      "1517, 5\n",
      "1518, 14\n",
      "1519, 13\n",
      "1520, 4\n",
      "1521, 2\n",
      "1522, 7\n",
      "1523, 9\n",
      "1524, 3\n",
      "1525, 4\n",
      "1526, 13\n",
      "1527, 11\n",
      "1528, 12\n",
      "1529, 13\n",
      "1530, 10\n",
      "1531, 13\n",
      "1532, 11\n",
      "1533, 12\n",
      "1534, 9\n",
      "1535, 10\n",
      "1536, 16\n",
      "1537, 5\n",
      "1538, 15\n",
      "1539, 11\n",
      "1540, 10\n",
      "1541, 15\n",
      "1542, 3\n",
      "1543, 2\n",
      "1544, 10\n",
      "1545, 12\n",
      "1546, 11\n",
      "1547, 2\n",
      "1548, 7\n",
      "1549, 16\n",
      "1550, 11\n",
      "1551, 8\n",
      "1552, 6\n",
      "1553, 5\n",
      "1554, 15\n",
      "1555, 8\n",
      "1556, 9\n",
      "1557, 9\n",
      "1558, 5\n",
      "1559, 12\n",
      "1560, 3\n",
      "1561, 5\n",
      "1562, 9\n",
      "1563, 5\n",
      "1564, 17\n",
      "1565, 12\n",
      "1566, 11\n",
      "1567, 4\n",
      "1568, 2\n",
      "1569, 6\n",
      "1570, 9\n",
      "1571, 15\n",
      "1572, 10\n",
      "1573, 12\n",
      "1574, 6\n",
      "1575, 16\n",
      "1576, 8\n",
      "1577, 11\n",
      "1578, 10\n",
      "1579, 10\n",
      "1580, 8\n",
      "1581, 4\n",
      "1582, 5\n",
      "1583, 10\n",
      "1584, 9\n",
      "1585, 9\n",
      "1586, 9\n",
      "1587, 4\n",
      "1588, 10\n",
      "1589, 11\n",
      "1590, 13\n",
      "1591, 2\n",
      "1592, 16\n",
      "1593, 8\n",
      "1594, 14\n",
      "1595, 6\n",
      "1596, 9\n",
      "1597, 7\n",
      "1598, 12\n",
      "1599, 4\n",
      "1600, 10\n",
      "1601, 8\n",
      "1602, 14\n",
      "1603, 7\n",
      "1604, 12\n",
      "1605, 4\n",
      "1606, 8\n",
      "1607, 3\n",
      "1608, 14\n",
      "1609, 11\n",
      "1610, 12\n",
      "1611, 5\n",
      "1612, 9\n",
      "1613, 12\n",
      "1614, 10\n",
      "1615, 9\n",
      "1616, 7\n",
      "1617, 12\n",
      "1618, 12\n",
      "1619, 11\n",
      "1620, 12\n",
      "1621, 10\n",
      "1622, 13\n",
      "1623, 3\n",
      "1624, 15\n",
      "1625, 16\n",
      "1626, 7\n",
      "1627, 8\n",
      "1628, 2\n",
      "1629, 12\n",
      "1630, 9\n",
      "1631, 13\n",
      "1632, 10\n",
      "1633, 6\n",
      "1634, 6\n",
      "1635, 8\n",
      "1636, 8\n",
      "1637, 1\n",
      "1638, 12\n",
      "1639, 12\n",
      "1640, 13\n",
      "1641, 1\n",
      "1642, 5\n",
      "1643, 17\n",
      "1644, 7\n",
      "1645, 5\n",
      "1646, 7\n",
      "1647, 10\n",
      "1648, 12\n",
      "1649, 8\n",
      "1650, 12\n",
      "1651, 13\n",
      "1652, 9\n",
      "1653, 9\n",
      "1654, 11\n",
      "1655, 9\n",
      "1656, 16\n",
      "1657, 5\n",
      "1658, 8\n",
      "1659, 13\n",
      "1660, 6\n",
      "1661, 16\n",
      "1662, 14\n",
      "1663, 15\n",
      "1664, 4\n",
      "1665, 9\n",
      "1666, 6\n",
      "1667, 13\n",
      "1668, 2\n",
      "1669, 10\n",
      "1670, 3\n",
      "1671, 4\n",
      "1672, 10\n",
      "1673, 2\n",
      "1674, 16\n",
      "1675, 11\n",
      "1676, 12\n",
      "1677, 8\n",
      "1678, 5\n",
      "1679, 11\n",
      "1680, 10\n",
      "1681, 4\n",
      "1682, 7\n",
      "1683, 12\n",
      "1684, 7\n",
      "1685, 4\n",
      "1686, 12\n",
      "1687, 9\n",
      "1688, 4\n",
      "1689, 14\n",
      "1690, 4\n",
      "1691, 9\n",
      "1692, 2\n",
      "1693, 13\n",
      "1694, 16\n",
      "1695, 11\n",
      "1696, 10\n",
      "1697, 8\n",
      "1698, 11\n",
      "1699, 6\n",
      "1700, 16\n",
      "1701, 0\n",
      "1702, 9\n",
      "1703, 18\n",
      "1704, 3\n",
      "1705, 12\n",
      "1706, 11\n",
      "1707, 0\n",
      "1708, 11\n",
      "1709, 13\n",
      "1710, 12\n",
      "1711, 11\n",
      "1712, 12\n",
      "1713, 10\n",
      "1714, 6\n",
      "1715, 8\n",
      "1716, 14\n",
      "1717, 14\n",
      "1718, 14\n",
      "1719, 6\n",
      "1720, 14\n",
      "1721, 15\n",
      "1722, 15\n",
      "1723, 12\n",
      "1724, 9\n",
      "1725, 9\n",
      "1726, 11\n",
      "1727, 7\n",
      "1728, 5\n",
      "1729, 5\n",
      "1730, 18\n",
      "1731, 10\n",
      "1732, 7\n",
      "1733, 10\n",
      "1734, 1\n",
      "1735, 12\n",
      "1736, 2\n",
      "1737, 5\n",
      "1738, 4\n",
      "1739, 12\n",
      "1740, 14\n",
      "1741, 3\n",
      "1742, 16\n",
      "1743, 5\n",
      "1744, 9\n",
      "1745, 16\n",
      "1746, 7\n",
      "1747, 18\n",
      "1748, 9\n",
      "1749, 1\n",
      "1750, 13\n",
      "1751, 13\n",
      "1752, 11\n",
      "1753, 10\n",
      "1754, 4\n",
      "1755, 6\n",
      "1756, 9\n",
      "1757, 11\n",
      "1758, 9\n",
      "1759, 4\n",
      "1760, 9\n",
      "1761, 10\n",
      "1762, 11\n",
      "1763, 4\n",
      "1764, 7\n",
      "1765, 10\n",
      "1766, 14\n",
      "1767, 14\n",
      "1768, 7\n",
      "1769, 7\n",
      "1770, 11\n",
      "1771, 12\n",
      "1772, 3\n",
      "1773, 3\n",
      "1774, 13\n",
      "1775, 2\n",
      "1776, 14\n",
      "1777, 9\n",
      "1778, 5\n",
      "1779, 15\n",
      "1780, 9\n",
      "1781, 6\n",
      "1782, 9\n",
      "1783, 11\n",
      "1784, 9\n",
      "1785, 10\n",
      "1786, 5\n",
      "1787, 13\n",
      "1788, 10\n",
      "1789, 8\n",
      "1790, 9\n",
      "1791, 6\n",
      "1792, 17\n",
      "1793, 10\n",
      "1794, 10\n",
      "1795, 1\n",
      "1796, 11\n",
      "1797, 14\n",
      "1798, 4\n",
      "1799, 12\n",
      "1800, 12\n",
      "1801, 3\n",
      "1802, 6\n",
      "1803, 12\n",
      "1804, 4\n",
      "1805, 11\n",
      "1806, 1\n",
      "1807, 10\n",
      "1808, 9\n",
      "1809, 9\n",
      "1810, 13\n",
      "1811, 13\n",
      "1812, 15\n",
      "1813, 10\n",
      "1814, 4\n",
      "1815, 11\n",
      "1816, 3\n",
      "1817, 11\n",
      "1818, 10\n",
      "1819, 8\n",
      "1820, 6\n",
      "1821, 8\n",
      "1822, 3\n",
      "1823, 1\n",
      "1824, 4\n",
      "1825, 5\n",
      "1826, 5\n",
      "1827, 9\n",
      "1828, 1\n",
      "1829, 4\n",
      "1830, 15\n",
      "1831, 9\n",
      "1832, 6\n",
      "1833, 11\n",
      "1834, 8\n",
      "1835, 8\n",
      "1836, 11\n",
      "1837, 4\n",
      "1838, 16\n",
      "1839, 13\n",
      "1840, 3\n",
      "1841, 13\n",
      "1842, 5\n",
      "1843, 8\n",
      "1844, 13\n",
      "1845, 7\n",
      "1846, 12\n",
      "1847, 1\n",
      "1848, 12\n",
      "1849, 9\n",
      "1850, 8\n",
      "1851, 5\n",
      "1852, 0\n",
      "1853, 9\n",
      "1854, 11\n",
      "1855, 11\n",
      "1856, 8\n",
      "1857, 12\n",
      "1858, 8\n",
      "1859, 11\n",
      "1860, 12\n",
      "1861, 6\n",
      "1862, 5\n",
      "1863, 15\n",
      "1864, 12\n",
      "1865, 11\n",
      "1866, 15\n",
      "1867, 13\n",
      "1868, 8\n",
      "1869, 3\n",
      "1870, 6\n",
      "1871, 8\n",
      "1872, 6\n",
      "1873, 6\n",
      "1874, 13\n",
      "1875, 9\n",
      "1876, 4\n",
      "1877, 9\n",
      "1878, 17\n",
      "1879, 12\n",
      "1880, 16\n",
      "1881, 12\n",
      "1882, 12\n",
      "1883, 12\n",
      "1884, 10\n",
      "1885, 4\n",
      "1886, 4\n",
      "1887, 11\n",
      "1888, 0\n",
      "1889, 7\n",
      "1890, 16\n",
      "1891, 11\n",
      "1892, 5\n",
      "1893, 8\n",
      "1894, 12\n",
      "1895, 5\n",
      "1896, 7\n",
      "1897, 13\n",
      "1898, 11\n",
      "1899, 7\n",
      "1900, 10\n",
      "1901, 5\n",
      "1902, 7\n",
      "1903, 17\n",
      "1904, 8\n",
      "1905, 10\n",
      "1906, 14\n",
      "1907, 10\n",
      "1908, 4\n",
      "1909, 8\n",
      "1910, 4\n",
      "1911, 7\n",
      "1912, 11\n",
      "1913, 8\n",
      "1914, 7\n",
      "1915, 10\n",
      "1916, 7\n",
      "1917, 5\n",
      "1918, 7\n",
      "1919, 9\n",
      "1920, 2\n",
      "1921, 13\n",
      "1922, 3\n",
      "1923, 8\n",
      "1924, 5\n",
      "1925, 10\n",
      "1926, 11\n",
      "1927, 7\n",
      "1928, 10\n",
      "1929, 11\n",
      "1930, 7\n",
      "1931, 8\n",
      "1932, 9\n",
      "1933, 8\n",
      "1934, 2\n",
      "1935, 10\n",
      "1936, 10\n",
      "1937, 3\n",
      "1938, 7\n",
      "1939, 16\n",
      "1940, 5\n",
      "1941, 9\n",
      "1942, 1\n",
      "1943, 7\n",
      "1944, 12\n",
      "1945, 13\n",
      "1946, 11\n",
      "1947, 4\n",
      "1948, 5\n",
      "1949, 12\n",
      "1950, 5\n",
      "1951, 6\n",
      "1952, 11\n",
      "1953, 14\n",
      "1954, 7\n",
      "1955, 3\n",
      "1956, 8\n",
      "1957, 15\n",
      "1958, 10\n",
      "1959, 5\n",
      "1960, 6\n",
      "1961, 11\n",
      "1962, 2\n",
      "1963, 6\n",
      "1964, 8\n",
      "1965, 10\n",
      "1966, 11\n",
      "1967, 15\n",
      "1968, 15\n",
      "1969, 9\n",
      "1970, 5\n",
      "1971, 12\n",
      "1972, 11\n",
      "1973, 5\n",
      "1974, 11\n",
      "1975, 2\n",
      "1976, 7\n",
      "1977, 11\n",
      "1978, 12\n",
      "1979, 14\n",
      "1980, 16\n",
      "1981, 10\n",
      "1982, 4\n",
      "1983, 10\n",
      "1984, 2\n",
      "1985, 13\n",
      "1986, 5\n",
      "1987, 9\n",
      "1988, 12\n",
      "1989, 14\n",
      "1990, 10\n",
      "1991, 11\n",
      "1992, 6\n",
      "1993, 9\n",
      "1994, 9\n",
      "1995, 9\n",
      "1996, 5\n",
      "1997, 3\n",
      "1998, 8\n",
      "1999, 10\n",
      "2000, 10\n",
      "2001, 11\n",
      "2002, 8\n",
      "2003, 4\n",
      "2004, 16\n",
      "2005, 0\n",
      "2006, 8\n",
      "2007, 17\n",
      "2008, 10\n",
      "2009, 6\n",
      "2010, 7\n",
      "2011, 4\n",
      "2012, 14\n",
      "2013, 6\n",
      "2014, 16\n",
      "2015, 6\n",
      "2016, 5\n",
      "2017, 9\n",
      "2018, 15\n",
      "2019, 9\n",
      "2020, 7\n",
      "2021, 8\n",
      "2022, 11\n",
      "2023, 5\n",
      "2024, 3\n",
      "2025, 8\n",
      "2026, 5\n",
      "2027, 8\n",
      "2028, 11\n",
      "2029, 11\n",
      "2030, 6\n",
      "2031, 1\n",
      "2032, 10\n",
      "2033, 6\n",
      "2034, 4\n",
      "2035, 9\n",
      "2036, 7\n",
      "2037, 9\n",
      "2038, 8\n",
      "2039, 8\n",
      "2040, 6\n",
      "2041, 5\n",
      "2042, 7\n",
      "2043, 3\n",
      "2044, 10\n",
      "2045, 16\n",
      "2046, 9\n",
      "2047, 11\n",
      "2048, 13\n",
      "2049, 9\n",
      "2050, 13\n",
      "2051, 4\n",
      "2052, 16\n",
      "2053, 3\n",
      "2054, 9\n",
      "2055, 9\n",
      "2056, 14\n",
      "2057, 11\n",
      "2058, 5\n",
      "2059, 6\n",
      "2060, 9\n",
      "2061, 9\n",
      "2062, 9\n",
      "2063, 2\n",
      "2064, 15\n",
      "2065, 16\n",
      "2066, 8\n",
      "2067, 8\n",
      "2068, 10\n",
      "2069, 14\n",
      "2070, 6\n",
      "2071, 10\n",
      "2072, 11\n",
      "2073, 1\n",
      "2074, 4\n",
      "2075, 7\n",
      "2076, 13\n",
      "2077, 1\n",
      "2078, 5\n",
      "2079, 11\n",
      "2080, 10\n",
      "2081, 13\n",
      "2082, 8\n",
      "2083, 10\n",
      "2084, 10\n",
      "2085, 13\n",
      "2086, 1\n",
      "2087, 12\n",
      "2088, 16\n",
      "2089, 5\n",
      "2090, 14\n",
      "2091, 6\n",
      "2092, 18\n",
      "2093, 18\n",
      "2094, 10\n",
      "2095, 16\n",
      "2096, 9\n",
      "2097, 5\n",
      "2098, 9\n",
      "2099, 15\n",
      "2100, 10\n",
      "2101, 10\n",
      "2102, 11\n",
      "2103, 6\n",
      "2104, 17\n",
      "2105, 17\n",
      "2106, 14\n",
      "2107, 7\n",
      "2108, 4\n",
      "2109, 12\n",
      "2110, 18\n",
      "2111, 5\n",
      "2112, 13\n",
      "2113, 6\n",
      "2114, 2\n",
      "2115, 6\n",
      "2116, 11\n",
      "2117, 10\n",
      "2118, 10\n",
      "2119, 4\n",
      "2120, 8\n",
      "2121, 18\n",
      "2122, 15\n",
      "2123, 8\n",
      "2124, 15\n",
      "2125, 15\n",
      "2126, 2\n",
      "2127, 11\n",
      "2128, 9\n",
      "2129, 9\n",
      "2130, 8\n",
      "2131, 4\n",
      "2132, 7\n",
      "2133, 7\n",
      "2134, 12\n",
      "2135, 10\n",
      "2136, 9\n",
      "2137, 5\n",
      "2138, 13\n",
      "2139, 3\n",
      "2140, 10\n",
      "2141, 12\n",
      "2142, 12\n",
      "2143, 2\n",
      "2144, 11\n",
      "2145, 11\n",
      "2146, 7\n",
      "2147, 10\n",
      "2148, 4\n",
      "2149, 10\n",
      "2150, 8\n",
      "2151, 6\n",
      "2152, 17\n",
      "2153, 5\n",
      "2154, 7\n",
      "2155, 11\n",
      "2156, 10\n",
      "2157, 7\n",
      "2158, 14\n",
      "2159, 8\n",
      "2160, 2\n",
      "2161, 12\n",
      "2162, 7\n",
      "2163, 13\n",
      "2164, 2\n",
      "2165, 3\n",
      "2166, 9\n",
      "2167, 1\n",
      "2168, 7\n",
      "2169, 15\n",
      "2170, 12\n",
      "2171, 9\n",
      "2172, 8\n",
      "2173, 6\n",
      "2174, 12\n",
      "2175, 9\n",
      "2176, 13\n",
      "2177, 15\n",
      "2178, 5\n",
      "2179, 2\n",
      "2180, 11\n",
      "2181, 4\n",
      "2182, 1\n",
      "2183, 13\n",
      "2184, 0\n",
      "2185, 9\n",
      "2186, 4\n",
      "2187, 8\n",
      "2188, 12\n",
      "2189, 18\n",
      "2190, 10\n",
      "2191, 7\n",
      "2192, 2\n",
      "2193, 3\n",
      "2194, 7\n",
      "2195, 1\n",
      "2196, 9\n",
      "2197, 6\n",
      "2198, 4\n",
      "2199, 10\n",
      "2200, 9\n",
      "2201, 8\n",
      "2202, 13\n",
      "2203, 3\n",
      "2204, 10\n",
      "2205, 9\n",
      "2206, 14\n",
      "2207, 8\n",
      "2208, 8\n",
      "2209, 6\n",
      "2210, 11\n",
      "2211, 0\n",
      "2212, 16\n",
      "2213, 11\n",
      "2214, 7\n",
      "2215, 15\n",
      "2216, 10\n",
      "2217, 8\n",
      "2218, 3\n",
      "2219, 9\n",
      "2220, 12\n",
      "2221, 6\n",
      "2222, 16\n",
      "2223, 10\n",
      "2224, 4\n",
      "2225, 13\n",
      "2226, 17\n",
      "2227, 10\n",
      "2228, 4\n",
      "2229, 4\n",
      "2230, 6\n",
      "2231, 13\n",
      "2232, 9\n",
      "2233, 10\n",
      "2234, 10\n",
      "2235, 6\n",
      "2236, 10\n",
      "2237, 8\n",
      "2238, 10\n",
      "2239, 16\n",
      "2240, 13\n",
      "2241, 13\n",
      "2242, 4\n",
      "2243, 7\n",
      "2244, 10\n",
      "2245, 10\n",
      "2246, 4\n",
      "2247, 9\n",
      "2248, 15\n",
      "2249, 5\n",
      "2250, 7\n",
      "2251, 12\n",
      "2252, 13\n",
      "2253, 12\n",
      "2254, 7\n",
      "2255, 7\n",
      "2256, 1\n",
      "2257, 13\n",
      "2258, 10\n",
      "2259, 13\n",
      "2260, 4\n",
      "2261, 9\n",
      "2262, 10\n",
      "2263, 8\n",
      "2264, 10\n",
      "2265, 8\n",
      "2266, 4\n",
      "2267, 9\n",
      "2268, 9\n",
      "2269, 12\n",
      "2270, 11\n",
      "2271, 10\n",
      "2272, 13\n",
      "2273, 11\n",
      "2274, 12\n",
      "2275, 10\n",
      "2276, 3\n",
      "2277, 11\n",
      "2278, 10\n",
      "2279, 4\n",
      "2280, 17\n",
      "2281, 10\n",
      "2282, 14\n",
      "2283, 8\n",
      "2284, 13\n",
      "2285, 5\n",
      "2286, 7\n",
      "2287, 11\n",
      "2288, 8\n",
      "2289, 8\n",
      "2290, 8\n",
      "2291, 4\n",
      "2292, 6\n",
      "2293, 9\n",
      "2294, 2\n",
      "2295, 4\n",
      "2296, 7\n",
      "2297, 16\n",
      "2298, 6\n",
      "2299, 8\n",
      "2300, 6\n",
      "2301, 8\n",
      "2302, 6\n",
      "2303, 14\n",
      "2304, 5\n",
      "2305, 3\n",
      "2306, 11\n",
      "2307, 1\n",
      "2308, 9\n",
      "2309, 8\n",
      "2310, 5\n",
      "2311, 6\n",
      "2312, 7\n",
      "2313, 3\n",
      "2314, 3\n",
      "2315, 6\n",
      "2316, 16\n",
      "2317, 7\n",
      "2318, 15\n",
      "2319, 13\n",
      "2320, 8\n",
      "2321, 5\n",
      "2322, 6\n",
      "2323, 7\n",
      "2324, 6\n",
      "2325, 11\n",
      "2326, 7\n",
      "2327, 5\n",
      "2328, 8\n",
      "2329, 5\n",
      "2330, 14\n",
      "2331, 3\n",
      "2332, 14\n",
      "2333, 3\n",
      "2334, 8\n",
      "2335, 3\n",
      "2336, 16\n",
      "2337, 6\n",
      "2338, 6\n",
      "2339, 18\n",
      "2340, 14\n",
      "2341, 15\n",
      "2342, 7\n",
      "2343, 15\n",
      "2344, 12\n",
      "2345, 9\n",
      "2346, 5\n",
      "2347, 10\n",
      "2348, 4\n",
      "2349, 14\n",
      "2350, 12\n",
      "2351, 3\n",
      "2352, 1\n",
      "2353, 16\n",
      "2354, 13\n",
      "2355, 14\n",
      "2356, 3\n",
      "2357, 7\n",
      "2358, 12\n",
      "2359, 8\n",
      "2360, 9\n",
      "2361, 15\n",
      "2362, 11\n",
      "2363, 18\n",
      "2364, 9\n",
      "2365, 17\n",
      "2366, 10\n",
      "2367, 2\n",
      "2368, 14\n",
      "2369, 11\n",
      "2370, 14\n",
      "2371, 6\n",
      "2372, 10\n",
      "2373, 9\n",
      "2374, 16\n",
      "2375, 14\n",
      "2376, 12\n",
      "2377, 10\n",
      "2378, 5\n",
      "2379, 13\n",
      "2380, 8\n",
      "2381, 15\n",
      "2382, 10\n",
      "2383, 8\n",
      "2384, 15\n",
      "2385, 10\n",
      "2386, 12\n",
      "2387, 5\n",
      "2388, 9\n",
      "2389, 7\n",
      "2390, 1\n",
      "2391, 4\n",
      "2392, 6\n",
      "2393, 3\n",
      "2394, 5\n",
      "2395, 11\n",
      "2396, 6\n",
      "2397, 11\n",
      "2398, 9\n",
      "2399, 3\n",
      "2400, 6\n",
      "2401, 6\n",
      "2402, 12\n",
      "2403, 13\n",
      "2404, 8\n",
      "2405, 9\n",
      "2406, 11\n",
      "2407, 14\n",
      "2408, 10\n",
      "2409, 10\n",
      "2410, 1\n",
      "2411, 15\n",
      "2412, 5\n",
      "2413, 7\n",
      "2414, 8\n",
      "2415, 8\n",
      "2416, 4\n",
      "2417, 11\n",
      "2418, 8\n",
      "2419, 7\n",
      "2420, 12\n",
      "2421, 6\n",
      "2422, 6\n",
      "2423, 13\n",
      "2424, 8\n",
      "2425, 14\n",
      "2426, 9\n",
      "2427, 14\n",
      "2428, 8\n",
      "2429, 12\n",
      "2430, 15\n",
      "2431, 14\n",
      "2432, 9\n",
      "2433, 8\n",
      "2434, 10\n",
      "2435, 12\n",
      "2436, 8\n",
      "2437, 1\n",
      "2438, 12\n",
      "2439, 5\n",
      "2440, 13\n",
      "2441, 1\n",
      "2442, 14\n",
      "2443, 14\n",
      "2444, 4\n",
      "2445, 8\n",
      "2446, 7\n",
      "2447, 4\n",
      "2448, 6\n",
      "2449, 9\n",
      "2450, 4\n",
      "2451, 11\n",
      "2452, 6\n",
      "2453, 3\n",
      "2454, 2\n",
      "2455, 7\n",
      "2456, 12\n",
      "2457, 10\n",
      "2458, 4\n",
      "2459, 7\n",
      "2460, 9\n",
      "2461, 5\n",
      "2462, 11\n",
      "2463, 15\n",
      "2464, 5\n",
      "2465, 9\n",
      "2466, 10\n",
      "2467, 13\n",
      "2468, 12\n",
      "2469, 15\n",
      "2470, 5\n",
      "2471, 10\n",
      "2472, 16\n",
      "2473, 11\n",
      "2474, 9\n",
      "2475, 8\n",
      "2476, 4\n",
      "2477, 2\n",
      "2478, 6\n",
      "2479, 7\n",
      "2480, 14\n",
      "2481, 15\n",
      "2482, 9\n",
      "2483, 7\n",
      "2484, 3\n",
      "2485, 10\n",
      "2486, 16\n",
      "2487, 15\n",
      "2488, 12\n",
      "2489, 5\n",
      "2490, 12\n",
      "2491, 14\n",
      "2492, 12\n",
      "2493, 11\n",
      "2494, 5\n",
      "2495, 7\n",
      "2496, 7\n",
      "2497, 9\n",
      "2498, 6\n",
      "2499, 11\n",
      "2500, 3\n",
      "2501, 4\n",
      "2502, 4\n",
      "2503, 6\n",
      "2504, 11\n",
      "2505, 11\n",
      "2506, 10\n",
      "2507, 13\n",
      "2508, 6\n",
      "2509, 15\n",
      "2510, 3\n",
      "2511, 6\n",
      "2512, 9\n",
      "2513, 9\n",
      "2514, 9\n",
      "2515, 12\n",
      "2516, 0\n",
      "2517, 7\n",
      "2518, 17\n",
      "2519, 6\n",
      "2520, 11\n",
      "2521, 7\n",
      "2522, 6\n",
      "2523, 12\n",
      "2524, 14\n",
      "2525, 6\n",
      "2526, 7\n",
      "2527, 15\n",
      "2528, 5\n",
      "2529, 1\n",
      "2530, 3\n",
      "2531, 11\n",
      "2532, 7\n",
      "2533, 15\n",
      "2534, 3\n",
      "2535, 4\n",
      "2536, 9\n",
      "2537, 10\n",
      "2538, 8\n",
      "2539, 9\n",
      "2540, 16\n",
      "2541, 11\n",
      "2542, 8\n",
      "2543, 8\n",
      "2544, 2\n",
      "2545, 14\n",
      "2546, 17\n",
      "2547, 14\n",
      "2548, 5\n",
      "2549, 17\n",
      "2550, 10\n",
      "2551, 4\n",
      "2552, 12\n",
      "2553, 5\n",
      "2554, 13\n",
      "2555, 6\n",
      "2556, 13\n",
      "2557, 13\n",
      "2558, 10\n",
      "2559, 6\n",
      "2560, 6\n",
      "2561, 10\n",
      "2562, 8\n",
      "2563, 6\n",
      "2564, 9\n",
      "2565, 16\n",
      "2566, 8\n",
      "2567, 4\n",
      "2568, 4\n",
      "2569, 6\n",
      "2570, 7\n",
      "2571, 5\n",
      "2572, 13\n",
      "2573, 14\n",
      "2574, 12\n",
      "2575, 7\n",
      "2576, 4\n",
      "2577, 6\n",
      "2578, 13\n",
      "2579, 10\n",
      "2580, 16\n",
      "2581, 11\n",
      "2582, 17\n",
      "2583, 6\n",
      "2584, 8\n",
      "2585, 15\n",
      "2586, 12\n",
      "2587, 11\n",
      "2588, 8\n",
      "2589, 10\n",
      "2590, 13\n",
      "2591, 12\n",
      "2592, 4\n",
      "2593, 3\n",
      "2594, 13\n",
      "2595, 10\n",
      "2596, 16\n",
      "2597, 9\n",
      "2598, 0\n",
      "2599, 10\n",
      "2600, 1\n",
      "2601, 8\n",
      "2602, 11\n",
      "2603, 11\n",
      "2604, 4\n",
      "2605, 6\n",
      "2606, 5\n",
      "2607, 6\n",
      "2608, 13\n",
      "2609, 7\n",
      "2610, 11\n",
      "2611, 6\n",
      "2612, 14\n",
      "2613, 14\n",
      "2614, 9\n",
      "2615, 7\n",
      "2616, 13\n",
      "2617, 5\n",
      "2618, 13\n",
      "2619, 1\n",
      "2620, 2\n",
      "2621, 5\n",
      "2622, 13\n",
      "2623, 14\n",
      "2624, 12\n",
      "2625, 12\n",
      "2626, 8\n",
      "2627, 2\n",
      "2628, 9\n",
      "2629, 7\n",
      "2630, 10\n",
      "2631, 13\n",
      "2632, 10\n",
      "2633, 2\n",
      "2634, 6\n",
      "2635, 11\n",
      "2636, 3\n",
      "2637, 10\n",
      "2638, 9\n",
      "2639, 9\n",
      "2640, 11\n",
      "2641, 14\n",
      "2642, 7\n",
      "2643, 12\n",
      "2644, 13\n",
      "2645, 11\n",
      "2646, 14\n",
      "2647, 6\n",
      "2648, 7\n",
      "2649, 4\n",
      "2650, 5\n",
      "2651, 15\n",
      "2652, 5\n",
      "2653, 10\n",
      "2654, 1\n",
      "2655, 6\n",
      "2656, 11\n",
      "2657, 11\n",
      "2658, 7\n",
      "2659, 7\n",
      "2660, 6\n",
      "2661, 9\n",
      "2662, 14\n",
      "2663, 6\n",
      "2664, 13\n",
      "2665, 9\n",
      "2666, 12\n",
      "2667, 10\n",
      "2668, 13\n",
      "2669, 7\n",
      "2670, 6\n",
      "2671, 0\n",
      "2672, 14\n",
      "2673, 4\n",
      "2674, 9\n",
      "2675, 9\n",
      "2676, 7\n",
      "2677, 18\n",
      "2678, 13\n",
      "2679, 6\n",
      "2680, 6\n",
      "2681, 12\n",
      "2682, 10\n",
      "2683, 8\n",
      "2684, 10\n",
      "2685, 6\n",
      "2686, 12\n",
      "2687, 7\n",
      "2688, 2\n",
      "2689, 9\n",
      "2690, 11\n",
      "2691, 15\n",
      "2692, 8\n",
      "2693, 10\n",
      "2694, 10\n",
      "2695, 2\n",
      "2696, 10\n",
      "2697, 9\n",
      "2698, 10\n",
      "2699, 7\n",
      "2700, 5\n",
      "2701, 14\n",
      "2702, 8\n",
      "2703, 13\n",
      "2704, 6\n",
      "2705, 14\n",
      "2706, 11\n",
      "2707, 7\n",
      "2708, 3\n",
      "2709, 10\n",
      "2710, 10\n",
      "2711, 9\n",
      "2712, 7\n",
      "2713, 6\n",
      "2714, 8\n",
      "2715, 8\n",
      "2716, 11\n",
      "2717, 6\n",
      "2718, 5\n",
      "2719, 13\n",
      "2720, 6\n",
      "2721, 7\n",
      "2722, 6\n",
      "2723, 9\n",
      "2724, 6\n",
      "2725, 12\n",
      "2726, 13\n",
      "2727, 14\n",
      "2728, 7\n",
      "2729, 4\n",
      "2730, 10\n",
      "2731, 10\n",
      "2732, 7\n",
      "2733, 8\n",
      "2734, 3\n",
      "2735, 12\n",
      "2736, 7\n",
      "2737, 10\n",
      "2738, 10\n",
      "2739, 7\n",
      "2740, 3\n",
      "2741, 6\n",
      "2742, 4\n",
      "2743, 8\n",
      "2744, 15\n",
      "2745, 12\n",
      "2746, 10\n",
      "2747, 11\n",
      "2748, 4\n",
      "2749, 12\n",
      "2750, 15\n",
      "2751, 7\n",
      "2752, 1\n",
      "2753, 3\n",
      "2754, 11\n",
      "2755, 10\n",
      "2756, 6\n",
      "2757, 3\n",
      "2758, 5\n",
      "2759, 16\n",
      "2760, 14\n",
      "2761, 6\n",
      "2762, 12\n",
      "2763, 13\n",
      "2764, 10\n",
      "2765, 11\n",
      "2766, 16\n",
      "2767, 9\n",
      "2768, 7\n",
      "2769, 4\n",
      "2770, 5\n",
      "2771, 0\n",
      "2772, 12\n",
      "2773, 12\n",
      "2774, 10\n",
      "2775, 5\n",
      "2776, 3\n",
      "2777, 9\n",
      "2778, 12\n",
      "2779, 11\n",
      "2780, 3\n",
      "2781, 17\n",
      "2782, 12\n",
      "2783, 9\n",
      "2784, 11\n",
      "2785, 9\n",
      "2786, 8\n",
      "2787, 13\n",
      "2788, 14\n",
      "2789, 13\n",
      "2790, 7\n",
      "2791, 6\n",
      "2792, 4\n",
      "2793, 14\n",
      "2794, 4\n",
      "2795, 4\n",
      "2796, 4\n",
      "2797, 6\n",
      "2798, 11\n",
      "2799, 7\n",
      "2800, 15\n",
      "2801, 13\n",
      "2802, 8\n",
      "2803, 6\n",
      "2804, 13\n",
      "2805, 12\n",
      "2806, 5\n",
      "2807, 7\n",
      "2808, 12\n",
      "2809, 11\n",
      "2810, 1\n",
      "2811, 5\n",
      "2812, 3\n",
      "2813, 8\n",
      "2814, 9\n",
      "2815, 2\n",
      "2816, 2\n",
      "2817, 12\n",
      "2818, 2\n",
      "2819, 12\n",
      "2820, 6\n",
      "2821, 10\n",
      "2822, 13\n",
      "2823, 2\n",
      "2824, 12\n",
      "2825, 7\n",
      "2826, 6\n",
      "2827, 12\n",
      "2828, 14\n",
      "2829, 10\n",
      "2830, 7\n",
      "2831, 10\n",
      "2832, 12\n",
      "2833, 6\n",
      "2834, 16\n",
      "2835, 18\n",
      "2836, 14\n",
      "2837, 7\n",
      "2838, 5\n",
      "2839, 12\n",
      "2840, 9\n",
      "2841, 14\n",
      "2842, 15\n",
      "2843, 7\n",
      "2844, 6\n",
      "2845, 8\n",
      "2846, 5\n",
      "2847, 6\n",
      "2848, 7\n",
      "2849, 1\n",
      "2850, 10\n",
      "2851, 14\n",
      "2852, 16\n",
      "2853, 4\n",
      "2854, 12\n",
      "2855, 11\n",
      "2856, 10\n",
      "2857, 6\n",
      "2858, 12\n",
      "2859, 9\n",
      "2860, 17\n",
      "2861, 6\n",
      "2862, 12\n",
      "2863, 13\n",
      "2864, 5\n",
      "2865, 11\n",
      "2866, 10\n",
      "2867, 14\n",
      "2868, 0\n",
      "2869, 12\n",
      "2870, 2\n",
      "2871, 9\n",
      "2872, 9\n",
      "2873, 5\n",
      "2874, 12\n",
      "2875, 10\n",
      "2876, 5\n",
      "2877, 11\n",
      "2878, 5\n",
      "2879, 10\n",
      "2880, 10\n",
      "2881, 4\n",
      "2882, 14\n",
      "2883, 9\n",
      "2884, 15\n",
      "2885, 5\n",
      "2886, 16\n",
      "2887, 9\n",
      "2888, 6\n",
      "2889, 16\n",
      "2890, 12\n",
      "2891, 6\n",
      "2892, 15\n",
      "2893, 9\n",
      "2894, 10\n",
      "2895, 14\n",
      "2896, 6\n",
      "2897, 10\n",
      "2898, 13\n",
      "2899, 10\n",
      "2900, 11\n",
      "2901, 9\n",
      "2902, 8\n",
      "2903, 14\n",
      "2904, 10\n",
      "2905, 4\n",
      "2906, 12\n",
      "2907, 10\n",
      "2908, 1\n",
      "2909, 18\n",
      "2910, 16\n",
      "2911, 7\n",
      "2912, 8\n",
      "2913, 11\n",
      "2914, 8\n",
      "2915, 6\n",
      "2916, 14\n",
      "2917, 8\n",
      "2918, 1\n",
      "2919, 8\n",
      "2920, 4\n",
      "2921, 4\n",
      "2922, 8\n",
      "2923, 11\n",
      "2924, 8\n",
      "2925, 15\n",
      "2926, 13\n",
      "2927, 12\n",
      "2928, 11\n",
      "2929, 5\n",
      "2930, 8\n",
      "2931, 12\n",
      "2932, 5\n",
      "2933, 4\n",
      "2934, 11\n",
      "2935, 8\n",
      "2936, 12\n",
      "2937, 2\n",
      "2938, 3\n",
      "2939, 13\n",
      "2940, 10\n",
      "2941, 5\n",
      "2942, 7\n",
      "2943, 13\n",
      "2944, 12\n",
      "2945, 8\n",
      "2946, 12\n",
      "2947, 4\n",
      "2948, 7\n",
      "2949, 0\n",
      "2950, 9\n",
      "2951, 11\n",
      "2952, 12\n",
      "2953, 5\n",
      "2954, 0\n",
      "2955, 10\n",
      "2956, 14\n",
      "2957, 6\n",
      "2958, 6\n",
      "2959, 6\n",
      "2960, 6\n",
      "2961, 7\n",
      "2962, 6\n",
      "2963, 12\n",
      "2964, 1\n",
      "2965, 14\n",
      "2966, 8\n",
      "2967, 8\n",
      "2968, 6\n",
      "2969, 4\n",
      "2970, 6\n",
      "2971, 14\n",
      "2972, 7\n",
      "2973, 7\n",
      "2974, 3\n",
      "2975, 5\n",
      "2976, 1\n",
      "2977, 4\n",
      "2978, 16\n",
      "2979, 10\n",
      "2980, 10\n",
      "2981, 17\n",
      "2982, 3\n",
      "2983, 17\n",
      "2984, 9\n",
      "2985, 11\n",
      "2986, 8\n",
      "2987, 3\n",
      "2988, 2\n",
      "2989, 12\n",
      "2990, 6\n",
      "2991, 15\n",
      "2992, 6\n",
      "2993, 7\n",
      "2994, 7\n",
      "2995, 8\n",
      "2996, 8\n",
      "2997, 7\n",
      "2998, 8\n",
      "2999, 6\n",
      "3000, 9\n",
      "3001, 7\n",
      "3002, 16\n",
      "3003, 17\n",
      "3004, 13\n",
      "3005, 15\n",
      "3006, 2\n",
      "3007, 10\n",
      "3008, 15\n",
      "3009, 14\n",
      "3010, 13\n",
      "3011, 4\n",
      "3012, 9\n",
      "3013, 8\n",
      "3014, 10\n",
      "3015, 18\n",
      "3016, 7\n",
      "3017, 9\n",
      "3018, 6\n",
      "3019, 13\n",
      "3020, 9\n",
      "3021, 7\n",
      "3022, 5\n",
      "3023, 3\n",
      "3024, 11\n",
      "3025, 4\n",
      "3026, 8\n",
      "3027, 7\n",
      "3028, 6\n",
      "3029, 7\n",
      "3030, 7\n",
      "3031, 8\n",
      "3032, 2\n",
      "3033, 13\n",
      "3034, 9\n",
      "3035, 13\n",
      "3036, 8\n",
      "3037, 8\n",
      "3038, 11\n",
      "3039, 4\n",
      "3040, 14\n",
      "3041, 13\n",
      "3042, 2\n",
      "3043, 3\n",
      "3044, 7\n",
      "3045, 9\n",
      "3046, 4\n",
      "3047, 9\n",
      "3048, 2\n",
      "3049, 2\n",
      "3050, 3\n",
      "3051, 1\n",
      "3052, 10\n",
      "3053, 3\n",
      "3054, 11\n",
      "3055, 8\n",
      "3056, 9\n",
      "3057, 9\n",
      "3058, 7\n",
      "3059, 14\n",
      "3060, 9\n",
      "3061, 17\n",
      "3062, 3\n",
      "3063, 10\n",
      "3064, 12\n",
      "3065, 10\n",
      "3066, 17\n",
      "3067, 10\n",
      "3068, 15\n",
      "3069, 6\n",
      "3070, 6\n",
      "3071, 7\n",
      "3072, 9\n",
      "3073, 11\n",
      "3074, 12\n",
      "3075, 10\n",
      "3076, 10\n",
      "3077, 12\n",
      "3078, 8\n",
      "3079, 8\n",
      "3080, 8\n",
      "3081, 6\n",
      "3082, 15\n",
      "3083, 4\n",
      "3084, 17\n",
      "3085, 7\n",
      "3086, 16\n",
      "3087, 18\n",
      "3088, 7\n",
      "3089, 11\n",
      "3090, 2\n",
      "3091, 9\n",
      "3092, 7\n",
      "3093, 18\n",
      "3094, 15\n",
      "3095, 4\n",
      "3096, 11\n",
      "3097, 12\n",
      "3098, 3\n",
      "3099, 11\n",
      "3100, 2\n",
      "3101, 9\n",
      "3102, 12\n",
      "3103, 13\n",
      "3104, 8\n",
      "3105, 9\n",
      "3106, 8\n",
      "3107, 10\n",
      "3108, 9\n",
      "3109, 2\n",
      "3110, 13\n",
      "3111, 12\n",
      "3112, 12\n",
      "3113, 4\n",
      "3114, 15\n",
      "3115, 8\n",
      "3116, 4\n",
      "3117, 2\n",
      "3118, 9\n",
      "3119, 17\n",
      "3120, 13\n",
      "3121, 10\n",
      "3122, 13\n",
      "3123, 8\n",
      "3124, 14\n",
      "3125, 2\n",
      "3126, 0\n",
      "3127, 9\n",
      "3128, 5\n",
      "3129, 13\n",
      "3130, 9\n",
      "3131, 11\n",
      "3132, 9\n",
      "3133, 10\n",
      "3134, 8\n",
      "3135, 5\n",
      "3136, 11\n",
      "3137, 12\n",
      "3138, 6\n",
      "3139, 9\n",
      "3140, 10\n",
      "3141, 5\n",
      "3142, 10\n",
      "3143, 3\n",
      "3144, 4\n",
      "3145, 7\n",
      "3146, 10\n",
      "3147, 4\n",
      "3148, 11\n",
      "3149, 10\n",
      "3150, 6\n",
      "3151, 7\n",
      "3152, 4\n",
      "3153, 8\n",
      "3154, 15\n",
      "3155, 4\n",
      "3156, 8\n",
      "3157, 8\n",
      "3158, 5\n",
      "3159, 8\n",
      "3160, 6\n",
      "3161, 7\n",
      "3162, 4\n",
      "3163, 4\n",
      "3164, 3\n",
      "3165, 8\n",
      "3166, 4\n",
      "3167, 11\n",
      "3168, 2\n",
      "3169, 10\n",
      "3170, 11\n",
      "3171, 1\n",
      "3172, 7\n",
      "3173, 9\n",
      "3174, 7\n",
      "3175, 8\n",
      "3176, 10\n",
      "3177, 0\n",
      "3178, 7\n",
      "3179, 2\n",
      "3180, 14\n",
      "3181, 8\n",
      "3182, 5\n",
      "3183, 11\n",
      "3184, 7\n",
      "3185, 17\n",
      "3186, 8\n",
      "3187, 16\n",
      "3188, 8\n",
      "3189, 9\n",
      "3190, 14\n",
      "3191, 2\n",
      "3192, 11\n",
      "3193, 15\n",
      "3194, 8\n",
      "3195, 8\n",
      "3196, 9\n",
      "3197, 12\n",
      "3198, 11\n",
      "3199, 7\n",
      "3200, 8\n",
      "3201, 16\n",
      "3202, 3\n",
      "3203, 1\n",
      "3204, 12\n",
      "3205, 6\n",
      "3206, 6\n",
      "3207, 13\n",
      "3208, 8\n",
      "3209, 16\n",
      "3210, 10\n",
      "3211, 12\n",
      "3212, 17\n",
      "3213, 10\n",
      "3214, 18\n",
      "3215, 16\n",
      "3216, 11\n",
      "3217, 11\n",
      "3218, 3\n",
      "3219, 8\n",
      "3220, 9\n",
      "3221, 6\n",
      "3222, 12\n",
      "3223, 7\n",
      "3224, 13\n",
      "3225, 9\n",
      "3226, 6\n",
      "3227, 2\n",
      "3228, 10\n",
      "3229, 4\n",
      "3230, 5\n",
      "3231, 16\n",
      "3232, 13\n",
      "3233, 12\n",
      "3234, 7\n",
      "3235, 11\n",
      "3236, 6\n",
      "3237, 9\n",
      "3238, 12\n",
      "3239, 14\n",
      "3240, 4\n",
      "3241, 17\n",
      "3242, 13\n",
      "3243, 10\n",
      "3244, 7\n",
      "3245, 9\n",
      "3246, 16\n",
      "3247, 12\n",
      "3248, 4\n",
      "3249, 11\n",
      "3250, 7\n",
      "3251, 10\n",
      "3252, 4\n",
      "3253, 3\n",
      "3254, 11\n",
      "3255, 2\n",
      "3256, 10\n",
      "3257, 13\n",
      "3258, 5\n",
      "3259, 8\n",
      "3260, 6\n",
      "3261, 11\n",
      "3262, 9\n",
      "3263, 10\n",
      "3264, 14\n",
      "3265, 7\n",
      "3266, 13\n",
      "3267, 10\n",
      "3268, 11\n",
      "3269, 2\n",
      "3270, 16\n",
      "3271, 10\n",
      "3272, 7\n",
      "3273, 12\n",
      "3274, 2\n",
      "3275, 12\n",
      "3276, 15\n",
      "3277, 2\n",
      "3278, 9\n",
      "3279, 4\n",
      "3280, 2\n",
      "3281, 13\n",
      "3282, 5\n",
      "3283, 10\n",
      "3284, 10\n",
      "3285, 4\n",
      "3286, 6\n",
      "3287, 16\n",
      "3288, 11\n",
      "3289, 17\n",
      "3290, 3\n",
      "3291, 1\n",
      "3292, 5\n",
      "3293, 3\n",
      "3294, 4\n",
      "3295, 11\n",
      "3296, 1\n",
      "3297, 11\n",
      "3298, 10\n",
      "3299, 9\n",
      "3300, 6\n",
      "3301, 8\n",
      "3302, 4\n",
      "3303, 13\n",
      "3304, 8\n",
      "3305, 4\n",
      "3306, 4\n",
      "3307, 10\n",
      "3308, 8\n",
      "3309, 9\n",
      "3310, 2\n",
      "3311, 9\n",
      "3312, 10\n",
      "3313, 5\n",
      "3314, 2\n",
      "3315, 8\n",
      "3316, 10\n",
      "3317, 7\n",
      "3318, 14\n",
      "3319, 7\n",
      "3320, 4\n",
      "3321, 4\n",
      "3322, 3\n",
      "3323, 7\n",
      "3324, 6\n",
      "3325, 9\n",
      "3326, 9\n",
      "3327, 8\n",
      "3328, 9\n",
      "3329, 4\n",
      "3330, 13\n",
      "3331, 12\n",
      "3332, 12\n",
      "3333, 9\n",
      "3334, 14\n",
      "3335, 8\n",
      "3336, 10\n",
      "3337, 6\n",
      "3338, 7\n",
      "3339, 10\n",
      "3340, 4\n",
      "3341, 12\n",
      "3342, 8\n",
      "3343, 15\n",
      "3344, 17\n",
      "3345, 8\n",
      "3346, 10\n",
      "3347, 12\n",
      "3348, 12\n",
      "3349, 15\n",
      "3350, 8\n",
      "3351, 5\n",
      "3352, 11\n",
      "3353, 10\n",
      "3354, 8\n",
      "3355, 0\n",
      "3356, 5\n",
      "3357, 7\n",
      "3358, 12\n",
      "3359, 6\n",
      "3360, 8\n",
      "3361, 11\n",
      "3362, 4\n",
      "3363, 10\n",
      "3364, 6\n",
      "3365, 13\n",
      "3366, 7\n",
      "3367, 11\n",
      "3368, 6\n",
      "3369, 9\n",
      "3370, 11\n",
      "3371, 5\n",
      "3372, 12\n",
      "3373, 4\n",
      "3374, 7\n",
      "3375, 6\n",
      "3376, 5\n",
      "3377, 1\n",
      "3378, 9\n",
      "3379, 8\n",
      "3380, 14\n",
      "3381, 12\n",
      "3382, 9\n",
      "3383, 17\n",
      "3384, 13\n",
      "3385, 12\n",
      "3386, 6\n",
      "3387, 9\n",
      "3388, 7\n",
      "3389, 9\n",
      "3390, 4\n",
      "3391, 5\n",
      "3392, 7\n",
      "3393, 12\n",
      "3394, 14\n",
      "3395, 2\n",
      "3396, 11\n",
      "3397, 9\n",
      "3398, 14\n",
      "3399, 13\n",
      "3400, 1\n",
      "3401, 11\n",
      "3402, 8\n",
      "3403, 13\n",
      "3404, 4\n",
      "3405, 6\n",
      "3406, 11\n",
      "3407, 5\n",
      "3408, 7\n",
      "3409, 12\n",
      "3410, 13\n",
      "3411, 12\n",
      "3412, 4\n",
      "3413, 9\n",
      "3414, 2\n",
      "3415, 4\n",
      "3416, 7\n",
      "3417, 6\n",
      "3418, 9\n",
      "3419, 4\n",
      "3420, 4\n",
      "3421, 8\n",
      "3422, 9\n",
      "3423, 4\n",
      "3424, 14\n",
      "3425, 8\n",
      "3426, 10\n",
      "3427, 13\n",
      "3428, 8\n",
      "3429, 12\n",
      "3430, 5\n",
      "3431, 10\n",
      "3432, 9\n",
      "3433, 6\n",
      "3434, 13\n",
      "3435, 10\n",
      "3436, 5\n",
      "3437, 15\n",
      "3438, 14\n",
      "3439, 1\n",
      "3440, 15\n",
      "3441, 12\n",
      "3442, 8\n",
      "3443, 12\n",
      "3444, 11\n",
      "3445, 5\n",
      "3446, 14\n",
      "3447, 2\n",
      "3448, 14\n",
      "3449, 3\n",
      "3450, 6\n",
      "3451, 12\n",
      "3452, 6\n",
      "3453, 8\n",
      "3454, 5\n",
      "3455, 12\n",
      "3456, 4\n",
      "3457, 11\n",
      "3458, 3\n",
      "3459, 7\n",
      "3460, 7\n",
      "3461, 7\n",
      "3462, 12\n",
      "3463, 8\n",
      "3464, 11\n",
      "3465, 18\n",
      "3466, 11\n",
      "3467, 15\n",
      "3468, 6\n",
      "3469, 5\n",
      "3470, 2\n",
      "3471, 6\n",
      "3472, 6\n",
      "3473, 3\n",
      "3474, 8\n",
      "3475, 9\n",
      "3476, 1\n",
      "3477, 3\n",
      "3478, 5\n",
      "3479, 9\n",
      "3480, 11\n",
      "3481, 9\n",
      "3482, 10\n",
      "3483, 8\n",
      "3484, 3\n",
      "3485, 10\n",
      "3486, 10\n",
      "3487, 6\n",
      "3488, 14\n",
      "3489, 10\n",
      "3490, 15\n",
      "3491, 15\n",
      "3492, 13\n",
      "3493, 10\n",
      "3494, 8\n",
      "3495, 15\n",
      "3496, 12\n",
      "3497, 2\n",
      "3498, 11\n",
      "3499, 7\n",
      "3500, 10\n",
      "3501, 7\n",
      "3502, 4\n",
      "3503, 15\n",
      "3504, 5\n",
      "3505, 17\n",
      "3506, 11\n",
      "3507, 1\n",
      "3508, 9\n",
      "3509, 11\n",
      "3510, 12\n",
      "3511, 2\n",
      "3512, 15\n",
      "3513, 16\n",
      "3514, 6\n",
      "3515, 11\n",
      "3516, 4\n",
      "3517, 8\n",
      "3518, 11\n",
      "3519, 8\n",
      "3520, 3\n",
      "3521, 13\n",
      "3522, 8\n",
      "3523, 9\n",
      "3524, 11\n",
      "3525, 11\n",
      "3526, 15\n",
      "3527, 17\n",
      "3528, 16\n",
      "3529, 15\n",
      "3530, 15\n",
      "3531, 16\n",
      "3532, 9\n",
      "3533, 9\n",
      "3534, 15\n",
      "3535, 3\n",
      "3536, 3\n",
      "3537, 10\n",
      "3538, 9\n",
      "3539, 9\n",
      "3540, 10\n",
      "3541, 10\n",
      "3542, 9\n",
      "3543, 4\n",
      "3544, 12\n",
      "3545, 8\n",
      "3546, 8\n",
      "3547, 11\n",
      "3548, 3\n",
      "3549, 1\n",
      "3550, 7\n",
      "3551, 16\n",
      "3552, 14\n",
      "3553, 3\n",
      "3554, 8\n",
      "3555, 10\n",
      "3556, 15\n",
      "3557, 6\n",
      "3558, 15\n",
      "3559, 9\n",
      "3560, 13\n",
      "3561, 9\n",
      "3562, 8\n",
      "3563, 10\n",
      "3564, 13\n",
      "3565, 1\n",
      "3566, 6\n",
      "3567, 11\n",
      "3568, 14\n",
      "3569, 8\n",
      "3570, 4\n",
      "3571, 11\n",
      "3572, 0\n",
      "3573, 15\n",
      "3574, 8\n",
      "3575, 16\n",
      "3576, 5\n",
      "3577, 12\n",
      "3578, 5\n",
      "3579, 8\n",
      "3580, 3\n",
      "3581, 1\n",
      "3582, 6\n",
      "3583, 11\n",
      "3584, 10\n",
      "3585, 6\n",
      "3586, 16\n",
      "3587, 5\n",
      "3588, 11\n",
      "3589, 10\n",
      "3590, 1\n",
      "3591, 4\n",
      "3592, 13\n",
      "3593, 13\n",
      "3594, 10\n",
      "3595, 8\n",
      "3596, 8\n",
      "3597, 11\n",
      "3598, 6\n",
      "3599, 10\n",
      "3600, 2\n",
      "3601, 11\n",
      "3602, 12\n",
      "3603, 7\n",
      "3604, 14\n",
      "3605, 8\n",
      "3606, 17\n",
      "3607, 11\n",
      "3608, 12\n",
      "3609, 7\n",
      "3610, 12\n",
      "3611, 12\n",
      "3612, 11\n",
      "3613, 3\n",
      "3614, 1\n",
      "3615, 9\n",
      "3616, 10\n",
      "3617, 13\n",
      "3618, 8\n",
      "3619, 10\n",
      "3620, 7\n",
      "3621, 13\n",
      "3622, 7\n",
      "3623, 9\n",
      "3624, 6\n",
      "3625, 12\n",
      "3626, 7\n",
      "3627, 7\n",
      "3628, 6\n",
      "3629, 12\n",
      "3630, 9\n",
      "3631, 5\n",
      "3632, 7\n",
      "3633, 2\n",
      "3634, 1\n",
      "3635, 11\n",
      "3636, 6\n",
      "3637, 13\n",
      "3638, 13\n",
      "3639, 4\n",
      "3640, 8\n",
      "3641, 14\n",
      "3642, 5\n",
      "3643, 8\n",
      "3644, 6\n",
      "3645, 12\n",
      "3646, 6\n",
      "3647, 10\n",
      "3648, 2\n",
      "3649, 8\n",
      "3650, 6\n",
      "3651, 14\n",
      "3652, 16\n",
      "3653, 14\n",
      "3654, 8\n",
      "3655, 11\n",
      "3656, 13\n",
      "3657, 7\n",
      "3658, 9\n",
      "3659, 8\n",
      "3660, 14\n",
      "3661, 13\n",
      "3662, 4\n",
      "3663, 15\n",
      "3664, 7\n",
      "3665, 12\n",
      "3666, 10\n",
      "3667, 3\n",
      "3668, 10\n",
      "3669, 11\n",
      "3670, 16\n",
      "3671, 13\n",
      "3672, 6\n",
      "3673, 14\n",
      "3674, 18\n",
      "3675, 11\n",
      "3676, 9\n",
      "3677, 12\n",
      "3678, 12\n",
      "3679, 4\n",
      "3680, 7\n",
      "3681, 15\n",
      "3682, 8\n",
      "3683, 4\n",
      "3684, 11\n",
      "3685, 7\n",
      "3686, 6\n",
      "3687, 3\n",
      "3688, 8\n",
      "3689, 9\n",
      "3690, 11\n",
      "3691, 7\n",
      "3692, 16\n",
      "3693, 13\n",
      "3694, 12\n",
      "3695, 6\n",
      "3696, 12\n",
      "3697, 6\n",
      "3698, 2\n",
      "3699, 6\n",
      "3700, 11\n",
      "3701, 8\n",
      "3702, 9\n",
      "3703, 9\n",
      "3704, 8\n",
      "3705, 15\n",
      "3706, 11\n",
      "3707, 6\n",
      "3708, 4\n",
      "3709, 6\n",
      "3710, 1\n",
      "3711, 8\n",
      "3712, 8\n",
      "3713, 11\n",
      "3714, 9\n",
      "3715, 5\n",
      "3716, 11\n",
      "3717, 9\n",
      "3718, 16\n",
      "3719, 6\n",
      "3720, 1\n",
      "3721, 9\n",
      "3722, 5\n",
      "3723, 13\n",
      "3724, 3\n",
      "3725, 10\n",
      "3726, 12\n",
      "3727, 13\n",
      "3728, 6\n",
      "3729, 15\n",
      "3730, 12\n",
      "3731, 10\n",
      "3732, 5\n",
      "3733, 3\n",
      "3734, 8\n",
      "3735, 7\n",
      "3736, 8\n",
      "3737, 7\n",
      "3738, 15\n",
      "3739, 2\n",
      "3740, 16\n",
      "3741, 5\n",
      "3742, 10\n",
      "3743, 1\n",
      "3744, 11\n",
      "3745, 10\n",
      "3746, 5\n",
      "3747, 0\n",
      "3748, 10\n",
      "3749, 12\n",
      "3750, 13\n",
      "3751, 2\n",
      "3752, 9\n",
      "3753, 11\n",
      "3754, 14\n",
      "3755, 8\n",
      "3756, 8\n",
      "3757, 13\n",
      "3758, 16\n",
      "3759, 8\n",
      "3760, 9\n",
      "3761, 4\n",
      "3762, 7\n",
      "3763, 7\n",
      "3764, 5\n",
      "3765, 15\n",
      "3766, 5\n",
      "3767, 11\n",
      "3768, 16\n",
      "3769, 12\n",
      "3770, 8\n",
      "3771, 3\n",
      "3772, 8\n",
      "3773, 12\n",
      "3774, 4\n",
      "3775, 12\n",
      "3776, 14\n",
      "3777, 10\n",
      "3778, 14\n",
      "3779, 13\n",
      "3780, 4\n",
      "3781, 5\n",
      "3782, 8\n",
      "3783, 1\n",
      "3784, 14\n",
      "3785, 11\n",
      "3786, 13\n",
      "3787, 8\n",
      "3788, 6\n",
      "3789, 6\n",
      "3790, 13\n",
      "3791, 8\n",
      "3792, 11\n",
      "3793, 8\n",
      "3794, 8\n",
      "3795, 10\n",
      "3796, 11\n",
      "3797, 8\n",
      "3798, 6\n",
      "3799, 14\n",
      "3800, 9\n",
      "3801, 13\n",
      "3802, 4\n",
      "3803, 13\n",
      "3804, 9\n",
      "3805, 12\n",
      "3806, 12\n",
      "3807, 6\n",
      "3808, 10\n",
      "3809, 3\n",
      "3810, 9\n",
      "3811, 9\n",
      "3812, 2\n",
      "3813, 7\n",
      "3814, 8\n",
      "3815, 8\n",
      "3816, 15\n",
      "3817, 4\n",
      "3818, 12\n",
      "3819, 6\n",
      "3820, 17\n",
      "3821, 13\n",
      "3822, 4\n",
      "3823, 9\n",
      "3824, 7\n",
      "3825, 2\n",
      "3826, 15\n",
      "3827, 6\n",
      "3828, 5\n",
      "3829, 11\n",
      "3830, 7\n",
      "3831, 6\n",
      "3832, 11\n",
      "3833, 7\n",
      "3834, 5\n",
      "3835, 7\n",
      "3836, 10\n",
      "3837, 5\n",
      "3838, 13\n",
      "3839, 16\n",
      "3840, 1\n",
      "3841, 12\n",
      "3842, 13\n",
      "3843, 13\n",
      "3844, 4\n",
      "3845, 12\n",
      "3846, 10\n",
      "3847, 11\n",
      "3848, 9\n",
      "3849, 5\n",
      "3850, 7\n",
      "3851, 0\n",
      "3852, 6\n",
      "3853, 10\n",
      "3854, 6\n",
      "3855, 8\n",
      "3856, 7\n",
      "3857, 10\n",
      "3858, 10\n",
      "3859, 11\n",
      "3860, 6\n",
      "3861, 2\n",
      "3862, 10\n",
      "3863, 6\n",
      "3864, 17\n",
      "3865, 5\n",
      "3866, 16\n",
      "3867, 10\n",
      "3868, 9\n",
      "3869, 14\n",
      "3870, 8\n",
      "3871, 9\n",
      "3872, 15\n",
      "3873, 4\n",
      "3874, 3\n",
      "3875, 6\n",
      "3876, 9\n",
      "3877, 2\n",
      "3878, 4\n",
      "3879, 8\n",
      "3880, 12\n",
      "3881, 18\n",
      "3882, 11\n",
      "3883, 5\n",
      "3884, 2\n",
      "3885, 2\n",
      "3886, 18\n",
      "3887, 13\n",
      "3888, 10\n",
      "3889, 2\n",
      "3890, 3\n",
      "3891, 16\n",
      "3892, 10\n",
      "3893, 9\n",
      "3894, 9\n",
      "3895, 5\n",
      "3896, 6\n",
      "3897, 11\n",
      "3898, 18\n",
      "3899, 5\n",
      "3900, 3\n",
      "3901, 13\n",
      "3902, 8\n",
      "3903, 4\n",
      "3904, 12\n",
      "3905, 15\n",
      "3906, 5\n",
      "3907, 11\n",
      "3908, 3\n",
      "3909, 7\n",
      "3910, 12\n",
      "3911, 9\n",
      "3912, 8\n",
      "3913, 7\n",
      "3914, 8\n",
      "3915, 15\n",
      "3916, 2\n",
      "3917, 4\n",
      "3918, 10\n",
      "3919, 3\n",
      "3920, 3\n",
      "3921, 2\n",
      "3922, 11\n",
      "3923, 9\n",
      "3924, 9\n",
      "3925, 7\n",
      "3926, 8\n",
      "3927, 14\n",
      "3928, 8\n",
      "3929, 11\n",
      "3930, 5\n",
      "3931, 15\n",
      "3932, 2\n",
      "3933, 3\n",
      "3934, 11\n",
      "3935, 10\n",
      "3936, 6\n",
      "3937, 14\n",
      "3938, 12\n",
      "3939, 3\n",
      "3940, 16\n",
      "3941, 12\n",
      "3942, 9\n",
      "3943, 7\n",
      "3944, 1\n",
      "3945, 7\n",
      "3946, 11\n",
      "3947, 10\n",
      "3948, 12\n",
      "3949, 6\n",
      "3950, 15\n",
      "3951, 16\n",
      "3952, 9\n",
      "3953, 9\n",
      "3954, 2\n",
      "3955, 17\n",
      "3956, 14\n",
      "3957, 4\n",
      "3958, 11\n",
      "3959, 10\n",
      "3960, 10\n",
      "3961, 4\n",
      "3962, 6\n",
      "3963, 6\n",
      "3964, 9\n",
      "3965, 8\n",
      "3966, 15\n",
      "3967, 8\n",
      "3968, 12\n",
      "3969, 9\n",
      "3970, 4\n",
      "3971, 8\n",
      "3972, 10\n",
      "3973, 8\n",
      "3974, 0\n",
      "3975, 10\n",
      "3976, 6\n",
      "3977, 7\n",
      "3978, 2\n",
      "3979, 13\n",
      "3980, 10\n",
      "3981, 13\n",
      "3982, 4\n",
      "3983, 8\n",
      "3984, 9\n",
      "3985, 12\n",
      "3986, 15\n",
      "3987, 4\n",
      "3988, 4\n",
      "3989, 13\n",
      "3990, 8\n",
      "3991, 8\n",
      "3992, 13\n",
      "3993, 3\n",
      "3994, 12\n",
      "3995, 6\n",
      "3996, 11\n",
      "3997, 5\n",
      "3998, 1\n",
      "3999, 9\n",
      "4000, 11\n",
      "4001, 6\n",
      "4002, 12\n",
      "4003, 4\n",
      "4004, 2\n",
      "4005, 6\n",
      "4006, 12\n",
      "4007, 16\n",
      "4008, 0\n",
      "4009, 11\n",
      "4010, 12\n",
      "4011, 13\n",
      "4012, 11\n",
      "4013, 8\n",
      "4014, 8\n",
      "4015, 6\n",
      "4016, 5\n",
      "4017, 15\n",
      "4018, 9\n",
      "4019, 8\n",
      "4020, 0\n",
      "4021, 10\n",
      "4022, 17\n",
      "4023, 12\n",
      "4024, 6\n",
      "4025, 7\n",
      "4026, 13\n",
      "4027, 2\n",
      "4028, 8\n",
      "4029, 3\n",
      "4030, 10\n",
      "4031, 12\n",
      "4032, 16\n",
      "4033, 1\n",
      "4034, 4\n",
      "4035, 12\n",
      "4036, 0\n",
      "4037, 3\n",
      "4038, 16\n",
      "4039, 8\n",
      "4040, 6\n",
      "4041, 5\n",
      "4042, 8\n",
      "4043, 7\n",
      "4044, 6\n",
      "4045, 14\n",
      "4046, 4\n",
      "4047, 6\n",
      "4048, 16\n",
      "4049, 10\n",
      "4050, 11\n",
      "4051, 7\n",
      "4052, 11\n",
      "4053, 13\n",
      "4054, 8\n",
      "4055, 7\n",
      "4056, 16\n",
      "4057, 6\n",
      "4058, 14\n",
      "4059, 10\n",
      "4060, 2\n",
      "4061, 10\n",
      "4062, 10\n",
      "4063, 7\n",
      "4064, 8\n",
      "4065, 11\n",
      "4066, 10\n",
      "4067, 7\n",
      "4068, 5\n",
      "4069, 13\n",
      "4070, 9\n",
      "4071, 12\n",
      "4072, 9\n",
      "4073, 15\n",
      "4074, 2\n",
      "4075, 10\n",
      "4076, 8\n",
      "4077, 4\n",
      "4078, 8\n",
      "4079, 8\n",
      "4080, 6\n",
      "4081, 5\n",
      "4082, 10\n",
      "4083, 4\n",
      "4084, 6\n",
      "4085, 7\n",
      "4086, 3\n",
      "4087, 11\n",
      "4088, 11\n",
      "4089, 13\n",
      "4090, 9\n",
      "4091, 9\n",
      "4092, 10\n",
      "4093, 7\n",
      "4094, 7\n",
      "4095, 15\n",
      "4096, 8\n",
      "4097, 12\n",
      "4098, 15\n",
      "4099, 7\n",
      "4100, 4\n",
      "4101, 0\n",
      "4102, 4\n",
      "4103, 1\n",
      "4104, 6\n",
      "4105, 8\n",
      "4106, 0\n",
      "4107, 10\n",
      "4108, 16\n",
      "4109, 8\n",
      "4110, 9\n",
      "4111, 4\n",
      "4112, 6\n",
      "4113, 7\n",
      "4114, 8\n",
      "4115, 8\n",
      "4116, 10\n",
      "4117, 10\n",
      "4118, 9\n",
      "4119, 6\n",
      "4120, 4\n",
      "4121, 7\n",
      "4122, 15\n",
      "4123, 10\n",
      "4124, 6\n",
      "4125, 15\n",
      "4126, 0\n",
      "4127, 4\n",
      "4128, 10\n",
      "4129, 6\n",
      "4130, 8\n",
      "4131, 5\n",
      "4132, 12\n",
      "4133, 4\n",
      "4134, 2\n",
      "4135, 15\n",
      "4136, 11\n",
      "4137, 2\n",
      "4138, 11\n",
      "4139, 5\n",
      "4140, 6\n",
      "4141, 4\n",
      "4142, 11\n",
      "4143, 13\n",
      "4144, 12\n",
      "4145, 8\n",
      "4146, 9\n",
      "4147, 10\n",
      "4148, 11\n",
      "4149, 11\n",
      "4150, 3\n",
      "4151, 5\n",
      "4152, 5\n",
      "4153, 10\n",
      "4154, 16\n",
      "4155, 3\n",
      "4156, 8\n",
      "4157, 5\n",
      "4158, 7\n",
      "4159, 13\n",
      "4160, 5\n",
      "4161, 16\n",
      "4162, 13\n",
      "4163, 17\n",
      "4164, 17\n",
      "4165, 11\n",
      "4166, 12\n",
      "4167, 14\n",
      "4168, 4\n",
      "4169, 12\n",
      "4170, 13\n",
      "4171, 18\n",
      "4172, 6\n",
      "4173, 1\n",
      "4174, 11\n",
      "4175, 6\n",
      "4176, 4\n",
      "4177, 8\n",
      "4178, 7\n",
      "4179, 4\n",
      "4180, 12\n",
      "4181, 12\n",
      "4182, 4\n",
      "4183, 4\n",
      "4184, 11\n",
      "4185, 12\n",
      "4186, 3\n",
      "4187, 10\n",
      "4188, 10\n",
      "4189, 2\n",
      "4190, 8\n",
      "4191, 11\n",
      "4192, 7\n",
      "4193, 10\n",
      "4194, 1\n",
      "4195, 6\n",
      "4196, 12\n",
      "4197, 10\n",
      "4198, 8\n",
      "4199, 11\n",
      "4200, 12\n",
      "4201, 8\n",
      "4202, 3\n",
      "4203, 12\n",
      "4204, 7\n",
      "4205, 9\n",
      "4206, 11\n",
      "4207, 10\n",
      "4208, 11\n",
      "4209, 5\n",
      "4210, 13\n",
      "4211, 18\n",
      "4212, 3\n",
      "4213, 13\n",
      "4214, 9\n",
      "4215, 6\n",
      "4216, 6\n",
      "4217, 17\n",
      "4218, 5\n",
      "4219, 5\n",
      "4220, 7\n",
      "4221, 5\n",
      "4222, 11\n",
      "4223, 4\n",
      "4224, 15\n",
      "4225, 9\n",
      "4226, 6\n",
      "4227, 5\n",
      "4228, 10\n",
      "4229, 8\n",
      "4230, 7\n",
      "4231, 10\n",
      "4232, 8\n",
      "4233, 14\n",
      "4234, 2\n",
      "4235, 12\n",
      "4236, 7\n",
      "4237, 11\n",
      "4238, 11\n",
      "4239, 4\n",
      "4240, 10\n",
      "4241, 5\n",
      "4242, 1\n",
      "4243, 4\n",
      "4244, 3\n",
      "4245, 13\n",
      "4246, 10\n",
      "4247, 11\n",
      "4248, 0\n",
      "4249, 11\n",
      "4250, 8\n",
      "4251, 10\n",
      "4252, 5\n",
      "4253, 1\n",
      "4254, 15\n",
      "4255, 12\n",
      "4256, 8\n",
      "4257, 8\n",
      "4258, 12\n",
      "4259, 8\n",
      "4260, 9\n",
      "4261, 15\n",
      "4262, 3\n",
      "4263, 8\n",
      "4264, 4\n",
      "4265, 8\n",
      "4266, 9\n",
      "4267, 13\n",
      "4268, 17\n",
      "4269, 9\n",
      "4270, 7\n",
      "4271, 11\n",
      "4272, 7\n",
      "4273, 10\n",
      "4274, 7\n",
      "4275, 13\n",
      "4276, 7\n",
      "4277, 9\n",
      "4278, 10\n",
      "4279, 9\n",
      "4280, 13\n",
      "4281, 4\n",
      "4282, 12\n",
      "4283, 3\n",
      "4284, 11\n",
      "4285, 2\n",
      "4286, 7\n",
      "4287, 6\n",
      "4288, 3\n",
      "4289, 11\n",
      "4290, 10\n",
      "4291, 5\n",
      "4292, 4\n",
      "4293, 6\n",
      "4294, 6\n",
      "4295, 12\n",
      "4296, 17\n",
      "4297, 10\n",
      "4298, 10\n",
      "4299, 15\n",
      "4300, 4\n",
      "4301, 9\n",
      "4302, 13\n",
      "4303, 1\n",
      "4304, 10\n",
      "4305, 13\n",
      "4306, 11\n",
      "4307, 10\n",
      "4308, 11\n",
      "4309, 5\n",
      "4310, 5\n",
      "4311, 4\n",
      "4312, 8\n",
      "4313, 7\n",
      "4314, 13\n",
      "4315, 10\n",
      "4316, 15\n",
      "4317, 9\n",
      "4318, 12\n",
      "4319, 13\n",
      "4320, 9\n",
      "4321, 5\n",
      "4322, 16\n",
      "4323, 13\n",
      "4324, 10\n",
      "4325, 9\n",
      "4326, 9\n",
      "4327, 3\n",
      "4328, 9\n",
      "4329, 7\n",
      "4330, 7\n",
      "4331, 14\n",
      "4332, 6\n",
      "4333, 9\n",
      "4334, 7\n",
      "4335, 4\n",
      "4336, 13\n",
      "4337, 8\n",
      "4338, 5\n",
      "4339, 7\n",
      "4340, 5\n",
      "4341, 1\n",
      "4342, 12\n",
      "4343, 4\n",
      "4344, 12\n",
      "4345, 6\n",
      "4346, 0\n",
      "4347, 9\n",
      "4348, 5\n",
      "4349, 5\n",
      "4350, 4\n",
      "4351, 9\n",
      "4352, 8\n",
      "4353, 8\n",
      "4354, 4\n",
      "4355, 14\n",
      "4356, 11\n",
      "4357, 9\n",
      "4358, 17\n",
      "4359, 8\n",
      "4360, 12\n",
      "4361, 10\n",
      "4362, 6\n",
      "4363, 5\n",
      "4364, 15\n",
      "4365, 8\n",
      "4366, 14\n",
      "4367, 8\n",
      "4368, 7\n",
      "4369, 17\n",
      "4370, 3\n",
      "4371, 8\n",
      "4372, 16\n",
      "4373, 4\n",
      "4374, 10\n",
      "4375, 10\n",
      "4376, 7\n",
      "4377, 10\n",
      "4378, 8\n",
      "4379, 8\n",
      "4380, 7\n",
      "4381, 10\n",
      "4382, 11\n",
      "4383, 3\n",
      "4384, 10\n",
      "4385, 6\n",
      "4386, 5\n",
      "4387, 2\n",
      "4388, 2\n",
      "4389, 10\n",
      "4390, 11\n",
      "4391, 4\n",
      "4392, 5\n",
      "4393, 8\n",
      "4394, 7\n",
      "4395, 8\n",
      "4396, 4\n",
      "4397, 11\n",
      "4398, 7\n",
      "4399, 14\n",
      "4400, 5\n",
      "4401, 6\n",
      "4402, 16\n",
      "4403, 17\n",
      "4404, 2\n",
      "4405, 0\n",
      "4406, 10\n",
      "4407, 9\n",
      "4408, 17\n",
      "4409, 14\n",
      "4410, 6\n",
      "4411, 9\n",
      "4412, 5\n",
      "4413, 16\n",
      "4414, 13\n",
      "4415, 4\n",
      "4416, 14\n",
      "4417, 7\n",
      "4418, 3\n",
      "4419, 10\n",
      "4420, 8\n",
      "4421, 8\n",
      "4422, 7\n",
      "4423, 4\n",
      "4424, 8\n",
      "4425, 11\n",
      "4426, 11\n",
      "4427, 5\n",
      "4428, 12\n",
      "4429, 9\n",
      "4430, 13\n",
      "4431, 13\n",
      "4432, 15\n",
      "4433, 11\n",
      "4434, 17\n",
      "4435, 7\n",
      "4436, 4\n",
      "4437, 9\n",
      "4438, 13\n",
      "4439, 14\n",
      "4440, 3\n",
      "4441, 6\n",
      "4442, 2\n",
      "4443, 10\n",
      "4444, 5\n",
      "4445, 4\n",
      "4446, 11\n",
      "4447, 7\n",
      "4448, 15\n",
      "4449, 6\n",
      "4450, 15\n",
      "4451, 8\n",
      "4452, 12\n",
      "4453, 14\n",
      "4454, 10\n",
      "4455, 8\n",
      "4456, 9\n",
      "4457, 3\n",
      "4458, 6\n",
      "4459, 15\n",
      "4460, 10\n",
      "4461, 8\n",
      "4462, 11\n",
      "4463, 8\n",
      "4464, 14\n",
      "4465, 17\n",
      "4466, 0\n",
      "4467, 15\n",
      "4468, 10\n",
      "4469, 9\n",
      "4470, 5\n",
      "4471, 5\n",
      "4472, 9\n",
      "4473, 6\n",
      "4474, 9\n",
      "4475, 14\n",
      "4476, 5\n",
      "4477, 4\n",
      "4478, 11\n",
      "4479, 11\n",
      "4480, 12\n",
      "4481, 2\n",
      "4482, 5\n",
      "4483, 10\n",
      "4484, 5\n",
      "4485, 9\n",
      "4486, 1\n",
      "4487, 14\n",
      "4488, 9\n",
      "4489, 14\n",
      "4490, 8\n",
      "4491, 10\n",
      "4492, 12\n",
      "4493, 8\n",
      "4494, 10\n",
      "4495, 8\n",
      "4496, 9\n",
      "4497, 9\n",
      "4498, 9\n",
      "4499, 3\n",
      "4500, 5\n",
      "4501, 8\n",
      "4502, 2\n",
      "4503, 10\n",
      "4504, 7\n",
      "4505, 4\n",
      "4506, 10\n",
      "4507, 3\n",
      "4508, 18\n",
      "4509, 2\n",
      "4510, 8\n",
      "4511, 10\n",
      "4512, 10\n",
      "4513, 6\n",
      "4514, 4\n",
      "4515, 10\n",
      "4516, 5\n",
      "4517, 5\n",
      "4518, 8\n",
      "4519, 13\n",
      "4520, 12\n",
      "4521, 2\n",
      "4522, 8\n",
      "4523, 6\n",
      "4524, 13\n",
      "4525, 11\n",
      "4526, 12\n",
      "4527, 13\n",
      "4528, 14\n",
      "4529, 14\n",
      "4530, 13\n",
      "4531, 6\n",
      "4532, 10\n",
      "4533, 10\n",
      "4534, 9\n",
      "4535, 4\n",
      "4536, 11\n",
      "4537, 10\n",
      "4538, 8\n",
      "4539, 9\n",
      "4540, 6\n",
      "4541, 12\n",
      "4542, 5\n",
      "4543, 4\n",
      "4544, 12\n",
      "4545, 3\n",
      "4546, 5\n",
      "4547, 6\n",
      "4548, 6\n",
      "4549, 9\n",
      "4550, 14\n",
      "4551, 3\n",
      "4552, 5\n",
      "4553, 12\n",
      "4554, 14\n",
      "4555, 9\n",
      "4556, 16\n",
      "4557, 9\n",
      "4558, 4\n",
      "4559, 11\n",
      "4560, 5\n",
      "4561, 10\n",
      "4562, 10\n",
      "4563, 9\n",
      "4564, 14\n",
      "4565, 4\n",
      "4566, 14\n",
      "4567, 3\n",
      "4568, 6\n",
      "4569, 10\n",
      "4570, 2\n",
      "4571, 6\n",
      "4572, 10\n",
      "4573, 9\n",
      "4574, 11\n",
      "4575, 2\n",
      "4576, 3\n",
      "4577, 7\n",
      "4578, 4\n",
      "4579, 9\n",
      "4580, 12\n",
      "4581, 11\n",
      "4582, 5\n",
      "4583, 12\n",
      "4584, 8\n",
      "4585, 4\n",
      "4586, 14\n",
      "4587, 3\n",
      "4588, 7\n",
      "4589, 8\n",
      "4590, 4\n",
      "4591, 13\n",
      "4592, 10\n",
      "4593, 12\n",
      "4594, 10\n",
      "4595, 1\n",
      "4596, 12\n",
      "4597, 4\n",
      "4598, 16\n",
      "4599, 7\n",
      "4600, 9\n",
      "4601, 6\n",
      "4602, 12\n",
      "4603, 12\n",
      "4604, 9\n",
      "4605, 9\n",
      "4606, 12\n",
      "4607, 8\n",
      "4608, 11\n",
      "4609, 9\n",
      "4610, 10\n",
      "4611, 17\n",
      "4612, 5\n",
      "4613, 7\n",
      "4614, 9\n",
      "4615, 5\n",
      "4616, 13\n",
      "4617, 12\n",
      "4618, 10\n",
      "4619, 3\n",
      "4620, 7\n",
      "4621, 16\n",
      "4622, 14\n",
      "4623, 10\n",
      "4624, 13\n",
      "4625, 3\n",
      "4626, 7\n",
      "4627, 8\n",
      "4628, 13\n",
      "4629, 8\n",
      "4630, 18\n",
      "4631, 12\n",
      "4632, 6\n",
      "4633, 18\n",
      "4634, 8\n",
      "4635, 4\n",
      "4636, 1\n",
      "4637, 5\n",
      "4638, 18\n",
      "4639, 13\n",
      "4640, 4\n",
      "4641, 14\n",
      "4642, 10\n",
      "4643, 8\n",
      "4644, 15\n",
      "4645, 13\n",
      "4646, 6\n",
      "4647, 13\n",
      "4648, 10\n",
      "4649, 11\n",
      "4650, 9\n",
      "4651, 7\n",
      "4652, 8\n",
      "4653, 9\n",
      "4654, 10\n",
      "4655, 2\n",
      "4656, 12\n",
      "4657, 12\n",
      "4658, 2\n",
      "4659, 3\n",
      "4660, 3\n",
      "4661, 12\n",
      "4662, 8\n",
      "4663, 14\n",
      "4664, 12\n",
      "4665, 18\n",
      "4666, 5\n",
      "4667, 15\n",
      "4668, 10\n",
      "4669, 16\n",
      "4670, 7\n",
      "4671, 18\n",
      "4672, 8\n",
      "4673, 4\n",
      "4674, 9\n",
      "4675, 14\n",
      "4676, 3\n",
      "4677, 11\n",
      "4678, 3\n",
      "4679, 6\n",
      "4680, 11\n",
      "4681, 7\n",
      "4682, 11\n",
      "4683, 8\n",
      "4684, 2\n",
      "4685, 2\n",
      "4686, 4\n",
      "4687, 7\n",
      "4688, 10\n",
      "4689, 6\n",
      "4690, 1\n",
      "4691, 16\n",
      "4692, 2\n",
      "4693, 14\n",
      "4694, 4\n",
      "4695, 9\n",
      "4696, 8\n",
      "4697, 3\n",
      "4698, 13\n",
      "4699, 2\n",
      "4700, 9\n",
      "4701, 8\n",
      "4702, 4\n",
      "4703, 13\n",
      "4704, 8\n",
      "4705, 15\n",
      "4706, 8\n",
      "4707, 5\n",
      "4708, 11\n",
      "4709, 14\n",
      "4710, 9\n",
      "4711, 9\n",
      "4712, 8\n",
      "4713, 14\n",
      "4714, 17\n",
      "4715, 5\n",
      "4716, 8\n",
      "4717, 0\n",
      "4718, 6\n",
      "4719, 11\n",
      "4720, 2\n",
      "4721, 15\n",
      "4722, 10\n",
      "4723, 14\n",
      "4724, 7\n",
      "4725, 4\n",
      "4726, 13\n",
      "4727, 16\n",
      "4728, 5\n",
      "4729, 17\n",
      "4730, 4\n",
      "4731, 8\n",
      "4732, 14\n",
      "4733, 15\n",
      "4734, 15\n",
      "4735, 13\n",
      "4736, 4\n",
      "4737, 3\n",
      "4738, 9\n",
      "4739, 6\n",
      "4740, 8\n",
      "4741, 14\n",
      "4742, 13\n",
      "4743, 3\n",
      "4744, 4\n",
      "4745, 13\n",
      "4746, 5\n",
      "4747, 8\n",
      "4748, 9\n",
      "4749, 16\n",
      "4750, 0\n",
      "4751, 13\n",
      "4752, 11\n",
      "4753, 11\n",
      "4754, 6\n",
      "4755, 7\n",
      "4756, 4\n",
      "4757, 8\n",
      "4758, 8\n",
      "4759, 8\n",
      "4760, 3\n",
      "4761, 2\n",
      "4762, 5\n",
      "4763, 13\n",
      "4764, 12\n",
      "4765, 13\n",
      "4766, 12\n",
      "4767, 6\n",
      "4768, 16\n",
      "4769, 9\n",
      "4770, 9\n",
      "4771, 12\n",
      "4772, 10\n",
      "4773, 6\n",
      "4774, 16\n",
      "4775, 9\n",
      "4776, 5\n",
      "4777, 2\n",
      "4778, 6\n",
      "4779, 10\n",
      "4780, 0\n",
      "4781, 10\n",
      "4782, 11\n",
      "4783, 7\n",
      "4784, 10\n",
      "4785, 14\n",
      "4786, 9\n",
      "4787, 9\n",
      "4788, 5\n",
      "4789, 15\n",
      "4790, 16\n",
      "4791, 6\n",
      "4792, 10\n",
      "4793, 10\n",
      "4794, 1\n",
      "4795, 7\n",
      "4796, 9\n",
      "4797, 11\n",
      "4798, 10\n",
      "4799, 3\n",
      "4800, 14\n",
      "4801, 5\n",
      "4802, 12\n",
      "4803, 3\n",
      "4804, 8\n",
      "4805, 14\n",
      "4806, 9\n",
      "4807, 4\n",
      "4808, 9\n",
      "4809, 16\n",
      "4810, 13\n",
      "4811, 12\n",
      "4812, 11\n",
      "4813, 13\n",
      "4814, 13\n",
      "4815, 7\n",
      "4816, 8\n",
      "4817, 6\n",
      "4818, 5\n",
      "4819, 9\n",
      "4820, 18\n",
      "4821, 14\n",
      "4822, 4\n",
      "4823, 9\n",
      "4824, 4\n",
      "4825, 8\n",
      "4826, 12\n",
      "4827, 5\n",
      "4828, 5\n",
      "4829, 9\n",
      "4830, 14\n",
      "4831, 8\n",
      "4832, 11\n",
      "4833, 16\n",
      "4834, 10\n",
      "4835, 4\n",
      "4836, 12\n",
      "4837, 8\n",
      "4838, 14\n",
      "4839, 3\n",
      "4840, 6\n",
      "4841, 13\n",
      "4842, 17\n",
      "4843, 0\n",
      "4844, 13\n",
      "4845, 2\n",
      "4846, 2\n",
      "4847, 2\n",
      "4848, 12\n",
      "4849, 9\n",
      "4850, 11\n",
      "4851, 12\n",
      "4852, 5\n",
      "4853, 11\n",
      "4854, 5\n",
      "4855, 10\n",
      "4856, 13\n",
      "4857, 11\n",
      "4858, 6\n",
      "4859, 4\n",
      "4860, 17\n",
      "4861, 10\n",
      "4862, 7\n",
      "4863, 16\n",
      "4864, 5\n",
      "4865, 8\n",
      "4866, 2\n",
      "4867, 8\n",
      "4868, 14\n",
      "4869, 10\n",
      "4870, 3\n",
      "4871, 15\n",
      "4872, 9\n",
      "4873, 14\n",
      "4874, 3\n",
      "4875, 7\n",
      "4876, 6\n",
      "4877, 6\n",
      "4878, 7\n",
      "4879, 9\n",
      "4880, 8\n",
      "4881, 10\n",
      "4882, 14\n",
      "4883, 3\n",
      "4884, 2\n",
      "4885, 8\n",
      "4886, 5\n",
      "4887, 3\n",
      "4888, 3\n",
      "4889, 8\n",
      "4890, 12\n",
      "4891, 16\n",
      "4892, 5\n",
      "4893, 4\n",
      "4894, 6\n",
      "4895, 12\n",
      "4896, 10\n",
      "4897, 7\n",
      "4898, 15\n",
      "4899, 14\n",
      "4900, 12\n",
      "4901, 1\n",
      "4902, 2\n",
      "4903, 4\n",
      "4904, 17\n",
      "4905, 17\n",
      "4906, 12\n",
      "4907, 11\n",
      "4908, 4\n",
      "4909, 6\n",
      "4910, 11\n",
      "4911, 8\n",
      "4912, 14\n",
      "4913, 11\n",
      "4914, 17\n",
      "4915, 7\n",
      "4916, 2\n",
      "4917, 10\n",
      "4918, 7\n",
      "4919, 6\n",
      "4920, 11\n",
      "4921, 5\n",
      "4922, 0\n",
      "4923, 1\n",
      "4924, 8\n",
      "4925, 9\n",
      "4926, 12\n",
      "4927, 3\n",
      "4928, 9\n",
      "4929, 4\n",
      "4930, 3\n",
      "4931, 7\n",
      "4932, 3\n",
      "4933, 1\n",
      "4934, 16\n",
      "4935, 14\n",
      "4936, 13\n",
      "4937, 9\n",
      "4938, 4\n",
      "4939, 8\n",
      "4940, 10\n",
      "4941, 4\n",
      "4942, 3\n",
      "4943, 5\n",
      "4944, 9\n",
      "4945, 8\n",
      "4946, 11\n",
      "4947, 16\n",
      "4948, 9\n",
      "4949, 5\n",
      "4950, 7\n",
      "4951, 1\n",
      "4952, 12\n",
      "4953, 6\n",
      "4954, 5\n",
      "4955, 11\n",
      "4956, 12\n",
      "4957, 7\n",
      "4958, 13\n",
      "4959, 2\n",
      "4960, 5\n",
      "4961, 14\n",
      "4962, 11\n",
      "4963, 15\n",
      "4964, 6\n",
      "4965, 5\n",
      "4966, 6\n",
      "4967, 8\n",
      "4968, 13\n",
      "4969, 2\n",
      "4970, 7\n",
      "4971, 15\n",
      "4972, 11\n",
      "4973, 10\n",
      "4974, 6\n",
      "4975, 15\n",
      "4976, 10\n",
      "4977, 13\n",
      "4978, 4\n",
      "4979, 12\n",
      "4980, 2\n",
      "4981, 7\n",
      "4982, 1\n",
      "4983, 7\n",
      "4984, 15\n",
      "4985, 11\n",
      "4986, 10\n",
      "4987, 17\n",
      "4988, 9\n",
      "4989, 7\n",
      "4990, 14\n",
      "4991, 12\n",
      "4992, 11\n",
      "4993, 15\n",
      "4994, 15\n",
      "4995, 11\n",
      "4996, 9\n",
      "4997, 8\n",
      "4998, 1\n",
      "4999, 2\n",
      "5000, 9\n",
      "5001, 13\n",
      "5002, 3\n",
      "5003, 8\n",
      "5004, 5\n",
      "5005, 12\n",
      "5006, 8\n",
      "5007, 8\n",
      "5008, 12\n",
      "5009, 7\n",
      "5010, 15\n",
      "5011, 6\n",
      "5012, 2\n",
      "5013, 10\n",
      "5014, 10\n",
      "5015, 14\n",
      "5016, 9\n",
      "5017, 11\n",
      "5018, 17\n",
      "5019, 3\n",
      "5020, 8\n",
      "5021, 14\n",
      "5022, 8\n",
      "5023, 13\n",
      "5024, 17\n",
      "5025, 18\n",
      "5026, 2\n",
      "5027, 2\n",
      "5028, 8\n",
      "5029, 1\n",
      "5030, 12\n",
      "5031, 10\n",
      "5032, 10\n",
      "5033, 6\n",
      "5034, 8\n",
      "5035, 10\n",
      "5036, 6\n",
      "5037, 9\n",
      "5038, 9\n",
      "5039, 6\n",
      "5040, 6\n",
      "5041, 2\n",
      "5042, 4\n",
      "5043, 10\n",
      "5044, 10\n",
      "5045, 6\n",
      "5046, 9\n",
      "5047, 11\n",
      "5048, 2\n",
      "5049, 16\n",
      "5050, 8\n",
      "5051, 6\n",
      "5052, 11\n",
      "5053, 12\n",
      "5054, 12\n",
      "5055, 7\n",
      "5056, 14\n",
      "5057, 13\n",
      "5058, 14\n",
      "5059, 6\n",
      "5060, 8\n",
      "5061, 5\n",
      "5062, 6\n",
      "5063, 8\n",
      "5064, 2\n",
      "5065, 15\n",
      "5066, 9\n",
      "5067, 9\n",
      "5068, 14\n",
      "5069, 7\n",
      "5070, 7\n",
      "5071, 8\n",
      "5072, 7\n",
      "5073, 3\n",
      "5074, 2\n",
      "5075, 11\n",
      "5076, 17\n",
      "5077, 15\n",
      "5078, 15\n",
      "5079, 9\n",
      "5080, 8\n",
      "5081, 4\n",
      "5082, 4\n",
      "5083, 9\n",
      "5084, 3\n",
      "5085, 6\n",
      "5086, 4\n",
      "5087, 17\n",
      "5088, 4\n",
      "5089, 7\n",
      "5090, 8\n",
      "5091, 12\n",
      "5092, 8\n",
      "5093, 7\n",
      "5094, 10\n",
      "5095, 2\n",
      "5096, 2\n",
      "5097, 6\n",
      "5098, 17\n",
      "5099, 10\n",
      "5100, 6\n",
      "5101, 8\n",
      "5102, 7\n",
      "5103, 5\n",
      "5104, 1\n",
      "5105, 5\n",
      "5106, 13\n",
      "5107, 10\n",
      "5108, 0\n",
      "5109, 3\n",
      "5110, 10\n",
      "5111, 14\n",
      "5112, 12\n",
      "5113, 16\n",
      "5114, 6\n",
      "5115, 13\n",
      "5116, 17\n",
      "5117, 9\n",
      "5118, 7\n",
      "5119, 18\n",
      "5120, 12\n",
      "5121, 7\n",
      "5122, 13\n",
      "5123, 13\n",
      "5124, 3\n",
      "5125, 3\n",
      "5126, 5\n",
      "5127, 7\n",
      "5128, 14\n",
      "5129, 9\n",
      "5130, 1\n",
      "5131, 13\n",
      "5132, 4\n",
      "5133, 11\n",
      "5134, 8\n",
      "5135, 10\n",
      "5136, 6\n",
      "5137, 10\n",
      "5138, 16\n",
      "5139, 9\n",
      "5140, 9\n",
      "5141, 8\n",
      "5142, 4\n",
      "5143, 5\n",
      "5144, 8\n",
      "5145, 3\n",
      "5146, 4\n",
      "5147, 11\n",
      "5148, 15\n",
      "5149, 9\n",
      "5150, 9\n",
      "5151, 3\n",
      "5152, 5\n",
      "5153, 9\n",
      "5154, 7\n",
      "5155, 15\n",
      "5156, 8\n",
      "5157, 7\n",
      "5158, 9\n",
      "5159, 15\n",
      "5160, 10\n",
      "5161, 5\n",
      "5162, 10\n",
      "5163, 12\n",
      "5164, 5\n",
      "5165, 4\n",
      "5166, 4\n",
      "5167, 11\n",
      "5168, 6\n",
      "5169, 11\n",
      "5170, 2\n",
      "5171, 9\n",
      "5172, 3\n",
      "5173, 16\n",
      "5174, 11\n",
      "5175, 14\n",
      "5176, 12\n",
      "5177, 7\n",
      "5178, 12\n",
      "5179, 13\n",
      "5180, 11\n",
      "5181, 11\n",
      "5182, 11\n",
      "5183, 15\n",
      "5184, 9\n",
      "5185, 5\n",
      "5186, 8\n",
      "5187, 5\n",
      "5188, 10\n",
      "5189, 4\n",
      "5190, 12\n",
      "5191, 7\n",
      "5192, 7\n",
      "5193, 8\n",
      "5194, 7\n",
      "5195, 1\n",
      "5196, 15\n",
      "5197, 12\n",
      "5198, 0\n",
      "5199, 10\n",
      "5200, 9\n",
      "5201, 8\n",
      "5202, 7\n",
      "5203, 8\n",
      "5204, 16\n",
      "5205, 10\n",
      "5206, 9\n",
      "5207, 12\n",
      "5208, 16\n",
      "5209, 11\n",
      "5210, 3\n",
      "5211, 7\n",
      "5212, 10\n",
      "5213, 8\n",
      "5214, 8\n",
      "5215, 15\n",
      "5216, 12\n",
      "5217, 12\n",
      "5218, 4\n",
      "5219, 16\n",
      "5220, 5\n",
      "5221, 6\n",
      "5222, 13\n",
      "5223, 10\n",
      "5224, 2\n",
      "5225, 9\n",
      "5226, 7\n",
      "5227, 5\n",
      "5228, 3\n",
      "5229, 10\n",
      "5230, 10\n",
      "5231, 7\n",
      "5232, 7\n",
      "5233, 3\n",
      "5234, 6\n",
      "5235, 4\n",
      "5236, 5\n",
      "5237, 2\n",
      "5238, 9\n",
      "5239, 6\n",
      "5240, 4\n",
      "5241, 4\n",
      "5242, 11\n",
      "5243, 5\n",
      "5244, 9\n",
      "5245, 16\n",
      "5246, 14\n",
      "5247, 5\n",
      "5248, 7\n",
      "5249, 4\n",
      "5250, 9\n",
      "5251, 10\n",
      "5252, 16\n",
      "5253, 12\n",
      "5254, 10\n",
      "5255, 14\n",
      "5256, 2\n",
      "5257, 5\n",
      "5258, 4\n",
      "5259, 3\n",
      "5260, 8\n",
      "5261, 7\n",
      "5262, 4\n",
      "5263, 9\n",
      "5264, 10\n",
      "5265, 3\n",
      "5266, 8\n",
      "5267, 8\n",
      "5268, 3\n",
      "5269, 4\n",
      "5270, 10\n",
      "5271, 8\n",
      "5272, 1\n",
      "5273, 11\n",
      "5274, 17\n",
      "5275, 14\n",
      "5276, 2\n",
      "5277, 0\n",
      "5278, 16\n",
      "5279, 10\n",
      "5280, 13\n",
      "5281, 9\n",
      "5282, 3\n",
      "5283, 9\n",
      "5284, 5\n",
      "5285, 11\n",
      "5286, 11\n",
      "5287, 7\n",
      "5288, 9\n",
      "5289, 7\n",
      "5290, 12\n",
      "5291, 11\n",
      "5292, 12\n",
      "5293, 13\n",
      "5294, 9\n",
      "5295, 13\n",
      "5296, 13\n",
      "5297, 12\n",
      "5298, 10\n",
      "5299, 3\n",
      "5300, 1\n",
      "5301, 9\n",
      "5302, 7\n",
      "5303, 7\n",
      "5304, 14\n",
      "5305, 12\n",
      "5306, 13\n",
      "5307, 5\n",
      "5308, 8\n",
      "5309, 15\n",
      "5310, 6\n",
      "5311, 14\n",
      "5312, 7\n",
      "5313, 9\n",
      "5314, 0\n",
      "5315, 9\n",
      "5316, 7\n",
      "5317, 6\n",
      "5318, 9\n",
      "5319, 8\n",
      "5320, 9\n",
      "5321, 11\n",
      "5322, 5\n",
      "5323, 2\n",
      "5324, 8\n",
      "5325, 3\n",
      "5326, 11\n",
      "5327, 12\n",
      "5328, 9\n",
      "5329, 7\n",
      "5330, 8\n",
      "5331, 10\n",
      "5332, 2\n",
      "5333, 8\n",
      "5334, 14\n",
      "5335, 3\n",
      "5336, 9\n",
      "5337, 10\n",
      "5338, 16\n",
      "5339, 5\n",
      "5340, 12\n",
      "5341, 7\n",
      "5342, 12\n",
      "5343, 2\n",
      "5344, 12\n",
      "5345, 8\n",
      "5346, 13\n",
      "5347, 9\n",
      "5348, 9\n",
      "5349, 1\n",
      "5350, 9\n",
      "5351, 2\n",
      "5352, 0\n",
      "5353, 7\n",
      "5354, 11\n",
      "5355, 1\n",
      "5356, 6\n",
      "5357, 11\n",
      "5358, 8\n",
      "5359, 10\n",
      "5360, 7\n",
      "5361, 10\n",
      "5362, 9\n",
      "5363, 0\n",
      "5364, 13\n",
      "5365, 11\n",
      "5366, 4\n",
      "5367, 13\n",
      "5368, 5\n",
      "5369, 14\n",
      "5370, 9\n",
      "5371, 2\n",
      "5372, 6\n",
      "5373, 9\n",
      "5374, 9\n",
      "5375, 7\n",
      "5376, 12\n",
      "5377, 0\n",
      "5378, 1\n",
      "5379, 10\n",
      "5380, 17\n",
      "5381, 6\n",
      "5382, 10\n",
      "5383, 11\n",
      "5384, 10\n",
      "5385, 8\n",
      "5386, 9\n",
      "5387, 16\n",
      "5388, 13\n",
      "5389, 10\n",
      "5390, 12\n",
      "5391, 16\n",
      "5392, 10\n",
      "5393, 7\n",
      "5394, 13\n",
      "5395, 5\n",
      "5396, 4\n",
      "5397, 3\n",
      "5398, 12\n",
      "5399, 2\n",
      "5400, 14\n",
      "5401, 5\n",
      "5402, 15\n",
      "5403, 12\n",
      "5404, 14\n",
      "5405, 9\n",
      "5406, 5\n",
      "5407, 17\n",
      "5408, 9\n",
      "5409, 4\n",
      "5410, 18\n",
      "5411, 8\n",
      "5412, 11\n",
      "5413, 8\n",
      "5414, 12\n",
      "5415, 13\n",
      "5416, 17\n",
      "5417, 5\n",
      "5418, 2\n",
      "5419, 7\n",
      "5420, 16\n",
      "5421, 2\n",
      "5422, 8\n",
      "5423, 12\n",
      "5424, 13\n",
      "5425, 11\n",
      "5426, 7\n",
      "5427, 8\n",
      "5428, 12\n",
      "5429, 6\n",
      "5430, 14\n",
      "5431, 9\n",
      "5432, 10\n",
      "5433, 13\n",
      "5434, 7\n",
      "5435, 13\n",
      "5436, 4\n",
      "5437, 7\n",
      "5438, 8\n",
      "5439, 4\n",
      "5440, 13\n",
      "5441, 12\n",
      "5442, 8\n",
      "5443, 9\n",
      "5444, 8\n",
      "5445, 7\n",
      "5446, 7\n",
      "5447, 6\n",
      "5448, 4\n",
      "5449, 10\n",
      "5450, 9\n",
      "5451, 3\n",
      "5452, 10\n",
      "5453, 10\n",
      "5454, 8\n",
      "5455, 0\n",
      "5456, 9\n",
      "5457, 17\n",
      "5458, 7\n",
      "5459, 5\n",
      "5460, 7\n",
      "5461, 11\n",
      "5462, 4\n",
      "5463, 6\n",
      "5464, 13\n",
      "5465, 3\n",
      "5466, 11\n",
      "5467, 10\n",
      "5468, 17\n",
      "5469, 8\n",
      "5470, 10\n",
      "5471, 5\n",
      "5472, 3\n",
      "5473, 12\n",
      "5474, 18\n",
      "5475, 8\n",
      "5476, 16\n",
      "5477, 2\n",
      "5478, 8\n",
      "5479, 12\n",
      "5480, 11\n",
      "5481, 12\n",
      "5482, 10\n",
      "5483, 8\n",
      "5484, 2\n",
      "5485, 12\n",
      "5486, 14\n",
      "5487, 13\n",
      "5488, 9\n",
      "5489, 9\n",
      "5490, 8\n",
      "5491, 17\n",
      "5492, 12\n",
      "5493, 5\n",
      "5494, 12\n",
      "5495, 11\n",
      "5496, 9\n",
      "5497, 10\n",
      "5498, 4\n",
      "5499, 17\n",
      "5500, 8\n",
      "5501, 6\n",
      "5502, 5\n",
      "5503, 4\n",
      "5504, 14\n",
      "5505, 6\n",
      "5506, 9\n",
      "5507, 12\n",
      "5508, 11\n",
      "5509, 10\n",
      "5510, 11\n",
      "5511, 3\n",
      "5512, 5\n",
      "5513, 14\n",
      "5514, 4\n",
      "5515, 8\n",
      "5516, 9\n",
      "5517, 6\n",
      "5518, 7\n",
      "5519, 6\n",
      "5520, 8\n",
      "5521, 9\n",
      "5522, 11\n",
      "5523, 13\n",
      "5524, 11\n",
      "5525, 1\n",
      "5526, 10\n",
      "5527, 12\n",
      "5528, 15\n",
      "5529, 3\n",
      "5530, 2\n",
      "5531, 14\n",
      "5532, 7\n",
      "5533, 12\n",
      "5534, 0\n",
      "5535, 5\n",
      "5536, 8\n",
      "5537, 5\n",
      "5538, 3\n",
      "5539, 17\n",
      "5540, 11\n",
      "5541, 7\n",
      "5542, 10\n",
      "5543, 4\n",
      "5544, 16\n",
      "5545, 8\n",
      "5546, 10\n",
      "5547, 10\n",
      "5548, 11\n",
      "5549, 8\n",
      "5550, 12\n",
      "5551, 3\n",
      "5552, 13\n",
      "5553, 18\n",
      "5554, 11\n",
      "5555, 10\n",
      "5556, 8\n",
      "5557, 9\n",
      "5558, 11\n",
      "5559, 12\n",
      "5560, 11\n",
      "5561, 6\n",
      "5562, 9\n",
      "5563, 17\n",
      "5564, 13\n",
      "5565, 12\n",
      "5566, 8\n",
      "5567, 6\n",
      "5568, 7\n",
      "5569, 11\n",
      "5570, 10\n",
      "5571, 10\n",
      "5572, 8\n",
      "5573, 6\n",
      "5574, 9\n",
      "5575, 7\n",
      "5576, 12\n",
      "5577, 4\n",
      "5578, 10\n",
      "5579, 5\n",
      "5580, 4\n",
      "5581, 5\n",
      "5582, 3\n",
      "5583, 2\n",
      "5584, 1\n",
      "5585, 9\n",
      "5586, 7\n",
      "5587, 15\n",
      "5588, 2\n",
      "5589, 8\n",
      "5590, 12\n",
      "5591, 17\n",
      "5592, 11\n",
      "5593, 6\n",
      "5594, 3\n",
      "5595, 9\n",
      "5596, 2\n",
      "5597, 9\n",
      "5598, 3\n",
      "5599, 3\n",
      "5600, 9\n",
      "5601, 8\n",
      "5602, 12\n",
      "5603, 7\n",
      "5604, 11\n",
      "5605, 3\n",
      "5606, 3\n",
      "5607, 12\n",
      "5608, 4\n",
      "5609, 2\n",
      "5610, 9\n",
      "5611, 4\n",
      "5612, 11\n",
      "5613, 12\n",
      "5614, 16\n",
      "5615, 16\n",
      "5616, 11\n",
      "5617, 9\n",
      "5618, 15\n",
      "5619, 2\n",
      "5620, 10\n",
      "5621, 11\n",
      "5622, 10\n",
      "5623, 8\n",
      "5624, 12\n",
      "5625, 15\n",
      "5626, 8\n",
      "5627, 13\n",
      "5628, 11\n",
      "5629, 3\n",
      "5630, 15\n",
      "5631, 18\n",
      "5632, 3\n",
      "5633, 9\n",
      "5634, 10\n",
      "5635, 9\n",
      "5636, 10\n",
      "5637, 7\n",
      "5638, 17\n",
      "5639, 4\n",
      "5640, 13\n",
      "5641, 9\n",
      "5642, 8\n",
      "5643, 7\n",
      "5644, 5\n",
      "5645, 8\n",
      "5646, 11\n",
      "5647, 12\n",
      "5648, 1\n",
      "5649, 11\n",
      "5650, 11\n",
      "5651, 6\n",
      "5652, 16\n",
      "5653, 3\n",
      "5654, 7\n",
      "5655, 6\n",
      "5656, 11\n",
      "5657, 8\n",
      "5658, 10\n",
      "5659, 17\n",
      "5660, 9\n",
      "5661, 4\n",
      "5662, 8\n",
      "5663, 8\n",
      "5664, 17\n",
      "5665, 4\n",
      "5666, 12\n",
      "5667, 5\n",
      "5668, 14\n",
      "5669, 7\n",
      "5670, 13\n",
      "5671, 9\n",
      "5672, 13\n",
      "5673, 10\n",
      "5674, 13\n",
      "5675, 15\n",
      "5676, 7\n",
      "5677, 11\n",
      "5678, 14\n",
      "5679, 9\n",
      "5680, 3\n",
      "5681, 8\n",
      "5682, 13\n",
      "5683, 8\n",
      "5684, 9\n",
      "5685, 11\n",
      "5686, 4\n",
      "5687, 3\n",
      "5688, 11\n",
      "5689, 3\n",
      "5690, 2\n",
      "5691, 10\n",
      "5692, 10\n",
      "5693, 8\n",
      "5694, 2\n",
      "5695, 12\n",
      "5696, 13\n",
      "5697, 2\n",
      "5698, 5\n",
      "5699, 7\n",
      "5700, 10\n",
      "5701, 15\n",
      "5702, 8\n",
      "5703, 7\n",
      "5704, 15\n",
      "5705, 11\n",
      "5706, 11\n",
      "5707, 12\n",
      "5708, 7\n",
      "5709, 17\n",
      "5710, 0\n",
      "5711, 18\n",
      "5712, 9\n",
      "5713, 8\n",
      "5714, 6\n",
      "5715, 8\n",
      "5716, 10\n",
      "5717, 4\n",
      "5718, 14\n",
      "5719, 9\n",
      "5720, 10\n",
      "5721, 5\n",
      "5722, 8\n",
      "5723, 8\n",
      "5724, 12\n",
      "5725, 9\n",
      "5726, 11\n",
      "5727, 10\n",
      "5728, 15\n",
      "5729, 13\n",
      "5730, 6\n",
      "5731, 7\n",
      "5732, 9\n",
      "5733, 7\n",
      "5734, 6\n",
      "5735, 4\n",
      "5736, 7\n",
      "5737, 3\n",
      "5738, 13\n",
      "5739, 8\n",
      "5740, 15\n",
      "5741, 2\n",
      "5742, 7\n",
      "5743, 7\n",
      "5744, 3\n",
      "5745, 15\n",
      "5746, 11\n",
      "5747, 10\n",
      "5748, 6\n",
      "5749, 13\n",
      "5750, 5\n",
      "5751, 10\n",
      "5752, 17\n",
      "5753, 15\n",
      "5754, 6\n",
      "5755, 15\n",
      "5756, 12\n",
      "5757, 17\n",
      "5758, 8\n",
      "5759, 15\n",
      "5760, 8\n",
      "5761, 9\n",
      "5762, 2\n",
      "5763, 4\n",
      "5764, 2\n",
      "5765, 6\n",
      "5766, 12\n",
      "5767, 2\n",
      "5768, 12\n",
      "5769, 11\n",
      "5770, 7\n",
      "5771, 6\n",
      "5772, 10\n",
      "5773, 11\n",
      "5774, 4\n",
      "5775, 17\n",
      "5776, 13\n",
      "5777, 8\n",
      "5778, 6\n",
      "5779, 10\n",
      "5780, 3\n",
      "5781, 15\n",
      "5782, 5\n",
      "5783, 13\n",
      "5784, 13\n",
      "5785, 9\n",
      "5786, 8\n",
      "5787, 11\n",
      "5788, 12\n",
      "5789, 8\n",
      "5790, 15\n",
      "5791, 18\n",
      "5792, 3\n",
      "5793, 17\n",
      "5794, 11\n",
      "5795, 5\n",
      "5796, 4\n",
      "5797, 12\n",
      "5798, 8\n",
      "5799, 13\n",
      "5800, 4\n",
      "5801, 12\n",
      "5802, 11\n",
      "5803, 15\n",
      "5804, 9\n",
      "5805, 15\n",
      "5806, 1\n",
      "5807, 2\n",
      "5808, 4\n",
      "5809, 8\n",
      "5810, 9\n",
      "5811, 7\n",
      "5812, 4\n",
      "5813, 16\n",
      "5814, 4\n",
      "5815, 9\n",
      "5816, 5\n",
      "5817, 11\n",
      "5818, 7\n",
      "5819, 13\n",
      "5820, 12\n",
      "5821, 9\n",
      "5822, 9\n",
      "5823, 9\n",
      "5824, 5\n",
      "5825, 7\n",
      "5826, 3\n",
      "5827, 11\n",
      "5828, 11\n",
      "5829, 12\n",
      "5830, 17\n",
      "5831, 2\n",
      "5832, 9\n",
      "5833, 12\n",
      "5834, 16\n",
      "5835, 6\n",
      "5836, 8\n",
      "5837, 3\n",
      "5838, 14\n",
      "5839, 11\n",
      "5840, 6\n",
      "5841, 14\n",
      "5842, 2\n",
      "5843, 10\n",
      "5844, 14\n",
      "5845, 11\n",
      "5846, 10\n",
      "5847, 13\n",
      "5848, 2\n",
      "5849, 4\n",
      "5850, 9\n",
      "5851, 2\n",
      "5852, 8\n",
      "5853, 6\n",
      "5854, 6\n",
      "5855, 10\n",
      "5856, 7\n",
      "5857, 17\n",
      "5858, 12\n",
      "5859, 8\n",
      "5860, 3\n",
      "5861, 12\n",
      "5862, 6\n",
      "5863, 8\n",
      "5864, 8\n",
      "5865, 12\n",
      "5866, 9\n",
      "5867, 9\n",
      "5868, 11\n",
      "5869, 8\n",
      "5870, 8\n",
      "5871, 13\n",
      "5872, 10\n",
      "5873, 16\n",
      "5874, 11\n",
      "5875, 4\n",
      "5876, 10\n",
      "5877, 14\n",
      "5878, 10\n",
      "5879, 15\n",
      "5880, 10\n",
      "5881, 7\n",
      "5882, 12\n",
      "5883, 13\n",
      "5884, 10\n",
      "5885, 9\n",
      "5886, 13\n",
      "5887, 9\n",
      "5888, 14\n",
      "5889, 9\n",
      "5890, 5\n",
      "5891, 16\n",
      "5892, 9\n",
      "5893, 2\n",
      "5894, 1\n",
      "5895, 1\n",
      "5896, 18\n",
      "5897, 13\n",
      "5898, 6\n",
      "5899, 16\n",
      "5900, 16\n",
      "5901, 9\n",
      "5902, 3\n",
      "5903, 7\n",
      "5904, 6\n",
      "5905, 14\n",
      "5906, 9\n",
      "5907, 12\n",
      "5908, 12\n",
      "5909, 3\n",
      "5910, 0\n",
      "5911, 10\n",
      "5912, 13\n",
      "5913, 13\n",
      "5914, 9\n",
      "5915, 8\n",
      "5916, 12\n",
      "5917, 7\n",
      "5918, 13\n",
      "5919, 11\n",
      "5920, 9\n",
      "5921, 13\n",
      "5922, 14\n",
      "5923, 11\n",
      "5924, 7\n",
      "5925, 11\n",
      "5926, 12\n",
      "5927, 9\n",
      "5928, 8\n",
      "5929, 10\n",
      "5930, 11\n",
      "5931, 6\n",
      "5932, 15\n",
      "5933, 11\n",
      "5934, 1\n",
      "5935, 11\n",
      "5936, 10\n",
      "5937, 9\n",
      "5938, 9\n",
      "5939, 6\n",
      "5940, 9\n",
      "5941, 11\n",
      "5942, 11\n",
      "5943, 6\n",
      "5944, 10\n",
      "5945, 13\n",
      "5946, 16\n",
      "5947, 13\n",
      "5948, 12\n",
      "5949, 12\n",
      "5950, 11\n",
      "5951, 2\n",
      "5952, 7\n",
      "5953, 17\n",
      "5954, 14\n",
      "5955, 5\n",
      "5956, 5\n",
      "5957, 8\n",
      "5958, 15\n",
      "5959, 5\n",
      "5960, 16\n",
      "5961, 1\n",
      "5962, 8\n",
      "5963, 5\n",
      "5964, 11\n",
      "5965, 7\n",
      "5966, 17\n",
      "5967, 12\n",
      "5968, 9\n",
      "5969, 8\n",
      "5970, 2\n",
      "5971, 2\n",
      "5972, 9\n",
      "5973, 18\n",
      "5974, 9\n",
      "5975, 0\n",
      "5976, 16\n",
      "5977, 6\n",
      "5978, 16\n",
      "5979, 14\n",
      "5980, 6\n",
      "5981, 11\n",
      "5982, 12\n",
      "5983, 11\n",
      "5984, 8\n",
      "5985, 16\n",
      "5986, 0\n",
      "5987, 10\n",
      "5988, 8\n",
      "5989, 8\n",
      "5990, 1\n",
      "5991, 9\n",
      "5992, 4\n",
      "5993, 5\n",
      "5994, 6\n",
      "5995, 11\n",
      "5996, 7\n",
      "5997, 9\n",
      "5998, 12\n",
      "5999, 9\n",
      "6000, 9\n",
      "6001, 6\n",
      "6002, 9\n",
      "6003, 11\n",
      "6004, 14\n",
      "6005, 6\n",
      "6006, 11\n",
      "6007, 3\n",
      "6008, 6\n",
      "6009, 11\n",
      "6010, 15\n",
      "6011, 8\n",
      "6012, 12\n",
      "6013, 3\n",
      "6014, 8\n",
      "6015, 12\n",
      "6016, 8\n",
      "6017, 4\n",
      "6018, 8\n",
      "6019, 9\n",
      "6020, 16\n",
      "6021, 5\n",
      "6022, 2\n",
      "6023, 11\n",
      "6024, 5\n",
      "6025, 15\n",
      "6026, 13\n",
      "6027, 15\n",
      "6028, 10\n",
      "6029, 11\n",
      "6030, 5\n",
      "6031, 10\n",
      "6032, 9\n",
      "6033, 11\n",
      "6034, 8\n",
      "6035, 10\n",
      "6036, 6\n",
      "6037, 13\n",
      "6038, 6\n",
      "6039, 7\n",
      "6040, 14\n",
      "6041, 8\n",
      "6042, 8\n",
      "6043, 1\n",
      "6044, 10\n",
      "6045, 0\n",
      "6046, 4\n",
      "6047, 4\n",
      "6048, 6\n",
      "6049, 6\n",
      "6050, 5\n",
      "6051, 5\n",
      "6052, 13\n",
      "6053, 9\n",
      "6054, 1\n",
      "6055, 11\n",
      "6056, 10\n",
      "6057, 8\n",
      "6058, 15\n",
      "6059, 11\n",
      "6060, 8\n",
      "6061, 10\n",
      "6062, 8\n",
      "6063, 9\n",
      "6064, 11\n",
      "6065, 6\n",
      "6066, 14\n",
      "6067, 8\n",
      "6068, 9\n",
      "6069, 15\n",
      "6070, 11\n",
      "6071, 13\n",
      "6072, 12\n",
      "6073, 6\n",
      "6074, 11\n",
      "6075, 5\n",
      "6076, 6\n",
      "6077, 16\n",
      "6078, 11\n",
      "6079, 13\n",
      "6080, 3\n",
      "6081, 8\n",
      "6082, 8\n",
      "6083, 12\n",
      "6084, 11\n",
      "6085, 12\n",
      "6086, 10\n",
      "6087, 11\n",
      "6088, 8\n",
      "6089, 14\n",
      "6090, 16\n",
      "6091, 10\n",
      "6092, 11\n",
      "6093, 12\n",
      "6094, 4\n",
      "6095, 1\n",
      "6096, 9\n",
      "6097, 17\n",
      "6098, 1\n",
      "6099, 5\n",
      "6100, 10\n",
      "6101, 12\n",
      "6102, 12\n",
      "6103, 7\n",
      "6104, 4\n",
      "6105, 17\n",
      "6106, 3\n",
      "6107, 5\n",
      "6108, 13\n",
      "6109, 6\n",
      "6110, 6\n",
      "6111, 6\n",
      "6112, 7\n",
      "6113, 10\n",
      "6114, 2\n",
      "6115, 8\n",
      "6116, 3\n",
      "6117, 10\n",
      "6118, 12\n",
      "6119, 10\n",
      "6120, 13\n",
      "6121, 14\n",
      "6122, 10\n",
      "6123, 5\n",
      "6124, 11\n",
      "6125, 6\n",
      "6126, 8\n",
      "6127, 6\n",
      "6128, 1\n",
      "6129, 5\n",
      "6130, 10\n",
      "6131, 7\n",
      "6132, 15\n",
      "6133, 11\n",
      "6134, 5\n",
      "6135, 7\n",
      "6136, 9\n",
      "6137, 10\n",
      "6138, 1\n",
      "6139, 7\n",
      "6140, 10\n",
      "6141, 7\n",
      "6142, 13\n",
      "6143, 3\n",
      "6144, 9\n",
      "6145, 7\n",
      "6146, 9\n",
      "6147, 18\n",
      "6148, 11\n",
      "6149, 9\n",
      "6150, 12\n",
      "6151, 3\n",
      "6152, 8\n",
      "6153, 3\n",
      "6154, 4\n",
      "6155, 17\n",
      "6156, 11\n",
      "6157, 7\n",
      "6158, 9\n",
      "6159, 10\n",
      "6160, 12\n",
      "6161, 11\n",
      "6162, 13\n",
      "6163, 8\n",
      "6164, 14\n",
      "6165, 9\n",
      "6166, 6\n",
      "6167, 2\n",
      "6168, 0\n",
      "6169, 7\n",
      "6170, 14\n",
      "6171, 10\n",
      "6172, 3\n",
      "6173, 11\n",
      "6174, 5\n",
      "6175, 11\n",
      "6176, 11\n",
      "6177, 11\n",
      "6178, 14\n",
      "6179, 13\n",
      "6180, 14\n",
      "6181, 10\n",
      "6182, 3\n",
      "6183, 6\n",
      "6184, 7\n",
      "6185, 9\n",
      "6186, 14\n",
      "6187, 14\n",
      "6188, 10\n",
      "6189, 2\n",
      "6190, 10\n",
      "6191, 6\n",
      "6192, 10\n",
      "6193, 8\n",
      "6194, 13\n",
      "6195, 4\n",
      "6196, 14\n",
      "6197, 1\n",
      "6198, 12\n",
      "6199, 13\n",
      "6200, 12\n",
      "6201, 7\n",
      "6202, 15\n",
      "6203, 5\n",
      "6204, 5\n",
      "6205, 5\n",
      "6206, 9\n",
      "6207, 5\n",
      "6208, 14\n",
      "6209, 11\n",
      "6210, 12\n",
      "6211, 12\n",
      "6212, 11\n",
      "6213, 5\n",
      "6214, 9\n",
      "6215, 2\n",
      "6216, 13\n",
      "6217, 15\n",
      "6218, 4\n",
      "6219, 10\n",
      "6220, 10\n",
      "6221, 11\n",
      "6222, 13\n",
      "6223, 8\n",
      "6224, 13\n",
      "6225, 8\n",
      "6226, 10\n",
      "6227, 7\n",
      "6228, 12\n",
      "6229, 3\n",
      "6230, 12\n",
      "6231, 6\n",
      "6232, 9\n",
      "6233, 11\n",
      "6234, 8\n",
      "6235, 16\n",
      "6236, 8\n",
      "6237, 5\n",
      "6238, 1\n",
      "6239, 15\n",
      "6240, 13\n",
      "6241, 16\n",
      "6242, 3\n",
      "6243, 18\n",
      "6244, 10\n",
      "6245, 5\n",
      "6246, 3\n",
      "6247, 9\n",
      "6248, 12\n",
      "6249, 5\n",
      "6250, 3\n",
      "6251, 9\n",
      "6252, 10\n",
      "6253, 6\n",
      "6254, 8\n",
      "6255, 9\n",
      "6256, 8\n",
      "6257, 7\n",
      "6258, 14\n",
      "6259, 11\n",
      "6260, 8\n",
      "6261, 13\n",
      "6262, 12\n",
      "6263, 10\n",
      "6264, 5\n",
      "6265, 4\n",
      "6266, 15\n",
      "6267, 16\n",
      "6268, 9\n",
      "6269, 15\n",
      "6270, 10\n",
      "6271, 15\n",
      "6272, 5\n",
      "6273, 6\n",
      "6274, 6\n",
      "6275, 15\n",
      "6276, 1\n",
      "6277, 8\n",
      "6278, 8\n",
      "6279, 8\n",
      "6280, 6\n",
      "6281, 12\n",
      "6282, 7\n",
      "6283, 1\n",
      "6284, 13\n",
      "6285, 14\n",
      "6286, 6\n",
      "6287, 11\n",
      "6288, 8\n",
      "6289, 9\n",
      "6290, 13\n",
      "6291, 5\n",
      "6292, 14\n",
      "6293, 16\n",
      "6294, 12\n",
      "6295, 9\n",
      "6296, 6\n",
      "6297, 4\n",
      "6298, 8\n",
      "6299, 8\n",
      "6300, 7\n",
      "6301, 8\n",
      "6302, 8\n",
      "6303, 8\n",
      "6304, 10\n",
      "6305, 3\n",
      "6306, 10\n",
      "6307, 5\n",
      "6308, 16\n",
      "6309, 17\n",
      "6310, 11\n",
      "6311, 9\n",
      "6312, 17\n",
      "6313, 13\n",
      "6314, 11\n",
      "6315, 10\n",
      "6316, 7\n",
      "6317, 6\n",
      "6318, 14\n",
      "6319, 9\n",
      "6320, 15\n",
      "6321, 9\n",
      "6322, 16\n",
      "6323, 7\n",
      "6324, 11\n",
      "6325, 0\n",
      "6326, 14\n",
      "6327, 14\n",
      "6328, 8\n",
      "6329, 15\n",
      "6330, 14\n",
      "6331, 8\n",
      "6332, 13\n",
      "6333, 15\n",
      "6334, 15\n",
      "6335, 7\n",
      "6336, 6\n",
      "6337, 6\n",
      "6338, 7\n",
      "6339, 11\n",
      "6340, 2\n",
      "6341, 11\n",
      "6342, 12\n",
      "6343, 3\n",
      "6344, 17\n",
      "6345, 3\n",
      "6346, 8\n",
      "6347, 8\n",
      "6348, 9\n",
      "6349, 14\n",
      "6350, 10\n",
      "6351, 4\n",
      "6352, 4\n",
      "6353, 9\n",
      "6354, 15\n",
      "6355, 10\n",
      "6356, 12\n",
      "6357, 17\n",
      "6358, 5\n",
      "6359, 5\n",
      "6360, 12\n",
      "6361, 7\n",
      "6362, 9\n",
      "6363, 17\n",
      "6364, 0\n",
      "6365, 8\n",
      "6366, 2\n",
      "6367, 11\n",
      "6368, 11\n",
      "6369, 5\n",
      "6370, 6\n",
      "6371, 11\n",
      "6372, 7\n",
      "6373, 12\n",
      "6374, 8\n",
      "6375, 7\n",
      "6376, 8\n",
      "6377, 15\n",
      "6378, 4\n",
      "6379, 1\n",
      "6380, 14\n",
      "6381, 6\n",
      "6382, 13\n",
      "6383, 0\n",
      "6384, 16\n",
      "6385, 13\n",
      "6386, 9\n",
      "6387, 10\n",
      "6388, 9\n",
      "6389, 4\n",
      "6390, 14\n",
      "6391, 7\n",
      "6392, 7\n",
      "6393, 0\n",
      "6394, 16\n",
      "6395, 10\n",
      "6396, 5\n",
      "6397, 3\n",
      "6398, 12\n",
      "6399, 12\n",
      "6400, 15\n",
      "6401, 10\n",
      "6402, 12\n",
      "6403, 8\n",
      "6404, 12\n",
      "6405, 4\n",
      "6406, 11\n",
      "6407, 18\n",
      "6408, 8\n",
      "6409, 2\n",
      "6410, 7\n",
      "6411, 7\n",
      "6412, 2\n",
      "6413, 12\n",
      "6414, 2\n",
      "6415, 11\n",
      "6416, 12\n",
      "6417, 5\n",
      "6418, 11\n",
      "6419, 7\n",
      "6420, 5\n",
      "6421, 16\n",
      "6422, 2\n",
      "6423, 9\n",
      "6424, 8\n",
      "6425, 7\n",
      "6426, 14\n",
      "6427, 0\n",
      "6428, 14\n",
      "6429, 15\n",
      "6430, 3\n",
      "6431, 17\n",
      "6432, 12\n",
      "6433, 12\n",
      "6434, 9\n",
      "6435, 9\n",
      "6436, 15\n",
      "6437, 9\n",
      "6438, 3\n",
      "6439, 12\n",
      "6440, 8\n",
      "6441, 13\n",
      "6442, 4\n",
      "6443, 13\n",
      "6444, 6\n",
      "6445, 5\n",
      "6446, 15\n",
      "6447, 3\n",
      "6448, 1\n",
      "6449, 7\n",
      "6450, 9\n",
      "6451, 12\n",
      "6452, 4\n",
      "6453, 14\n",
      "6454, 12\n",
      "6455, 11\n",
      "6456, 6\n",
      "6457, 14\n",
      "6458, 5\n",
      "6459, 8\n",
      "6460, 6\n",
      "6461, 6\n",
      "6462, 7\n",
      "6463, 7\n",
      "6464, 14\n",
      "6465, 3\n",
      "6466, 10\n",
      "6467, 12\n",
      "6468, 11\n",
      "6469, 5\n",
      "6470, 11\n",
      "6471, 13\n",
      "6472, 8\n",
      "6473, 4\n",
      "6474, 2\n",
      "6475, 3\n",
      "6476, 9\n",
      "6477, 13\n",
      "6478, 16\n",
      "6479, 15\n",
      "6480, 13\n",
      "6481, 1\n",
      "6482, 5\n",
      "6483, 9\n",
      "6484, 9\n",
      "6485, 7\n",
      "6486, 12\n",
      "6487, 8\n",
      "6488, 6\n",
      "6489, 8\n",
      "6490, 18\n",
      "6491, 5\n",
      "6492, 8\n",
      "6493, 8\n",
      "6494, 14\n",
      "6495, 15\n",
      "6496, 5\n",
      "6497, 6\n",
      "6498, 6\n",
      "6499, 12\n",
      "6500, 18\n",
      "6501, 10\n",
      "6502, 9\n",
      "6503, 8\n",
      "6504, 2\n",
      "6505, 10\n",
      "6506, 12\n",
      "6507, 9\n",
      "6508, 10\n",
      "6509, 8\n",
      "6510, 1\n",
      "6511, 10\n",
      "6512, 13\n",
      "6513, 14\n",
      "6514, 8\n",
      "6515, 15\n",
      "6516, 9\n",
      "6517, 13\n",
      "6518, 14\n",
      "6519, 9\n",
      "6520, 10\n",
      "6521, 9\n",
      "6522, 3\n",
      "6523, 11\n",
      "6524, 10\n",
      "6525, 9\n",
      "6526, 9\n",
      "6527, 18\n",
      "6528, 12\n",
      "6529, 15\n",
      "6530, 14\n",
      "6531, 9\n",
      "6532, 13\n",
      "6533, 9\n",
      "6534, 7\n",
      "6535, 8\n",
      "6536, 6\n",
      "6537, 8\n",
      "6538, 6\n",
      "6539, 8\n",
      "6540, 7\n",
      "6541, 10\n",
      "6542, 5\n",
      "6543, 2\n",
      "6544, 12\n",
      "6545, 9\n",
      "6546, 16\n",
      "6547, 6\n",
      "6548, 9\n",
      "6549, 14\n",
      "6550, 11\n",
      "6551, 15\n",
      "6552, 9\n",
      "6553, 15\n",
      "6554, 2\n",
      "6555, 9\n",
      "6556, 3\n",
      "6557, 9\n",
      "6558, 3\n",
      "6559, 10\n",
      "6560, 5\n",
      "6561, 9\n",
      "6562, 12\n",
      "6563, 9\n",
      "6564, 7\n",
      "6565, 6\n",
      "6566, 9\n",
      "6567, 13\n",
      "6568, 0\n",
      "6569, 11\n",
      "6570, 6\n",
      "6571, 13\n",
      "6572, 3\n",
      "6573, 1\n",
      "6574, 11\n",
      "6575, 12\n",
      "6576, 5\n",
      "6577, 14\n",
      "6578, 14\n",
      "6579, 16\n",
      "6580, 1\n",
      "6581, 1\n",
      "6582, 7\n",
      "6583, 9\n",
      "6584, 8\n",
      "6585, 10\n",
      "6586, 8\n",
      "6587, 2\n",
      "6588, 11\n",
      "6589, 2\n",
      "6590, 1\n",
      "6591, 5\n",
      "6592, 8\n",
      "6593, 10\n",
      "6594, 14\n",
      "6595, 0\n",
      "6596, 10\n",
      "6597, 13\n",
      "6598, 6\n",
      "6599, 4\n",
      "6600, 8\n",
      "6601, 14\n",
      "6602, 12\n",
      "6603, 5\n",
      "6604, 11\n",
      "6605, 14\n",
      "6606, 7\n",
      "6607, 13\n",
      "6608, 10\n",
      "6609, 16\n",
      "6610, 18\n",
      "6611, 5\n",
      "6612, 16\n",
      "6613, 16\n",
      "6614, 4\n",
      "6615, 15\n",
      "6616, 5\n",
      "6617, 10\n",
      "6618, 8\n",
      "6619, 7\n",
      "6620, 14\n",
      "6621, 11\n",
      "6622, 5\n",
      "6623, 11\n",
      "6624, 8\n",
      "6625, 0\n",
      "6626, 3\n",
      "6627, 7\n",
      "6628, 10\n",
      "6629, 15\n",
      "6630, 9\n",
      "6631, 6\n",
      "6632, 12\n",
      "6633, 6\n",
      "6634, 9\n",
      "6635, 12\n",
      "6636, 6\n",
      "6637, 3\n",
      "6638, 10\n",
      "6639, 8\n",
      "6640, 9\n",
      "6641, 9\n",
      "6642, 3\n",
      "6643, 8\n",
      "6644, 9\n",
      "6645, 8\n",
      "6646, 5\n",
      "6647, 3\n",
      "6648, 14\n",
      "6649, 12\n",
      "6650, 0\n",
      "6651, 4\n",
      "6652, 10\n",
      "6653, 4\n",
      "6654, 13\n",
      "6655, 9\n",
      "6656, 11\n",
      "6657, 10\n",
      "6658, 13\n",
      "6659, 12\n",
      "6660, 13\n",
      "6661, 8\n",
      "6662, 3\n",
      "6663, 9\n",
      "6664, 6\n",
      "6665, 3\n",
      "6666, 1\n",
      "6667, 12\n",
      "6668, 5\n",
      "6669, 6\n",
      "6670, 13\n",
      "6671, 10\n",
      "6672, 8\n",
      "6673, 12\n",
      "6674, 7\n",
      "6675, 5\n",
      "6676, 16\n",
      "6677, 10\n",
      "6678, 15\n",
      "6679, 3\n",
      "6680, 14\n",
      "6681, 10\n",
      "6682, 1\n",
      "6683, 9\n",
      "6684, 8\n",
      "6685, 13\n",
      "6686, 9\n",
      "6687, 9\n",
      "6688, 7\n",
      "6689, 12\n",
      "6690, 3\n",
      "6691, 8\n",
      "6692, 9\n",
      "6693, 9\n",
      "6694, 7\n",
      "6695, 13\n",
      "6696, 7\n",
      "6697, 10\n",
      "6698, 5\n",
      "6699, 4\n",
      "6700, 9\n",
      "6701, 7\n",
      "6702, 7\n",
      "6703, 1\n",
      "6704, 12\n",
      "6705, 4\n",
      "6706, 4\n",
      "6707, 10\n",
      "6708, 13\n",
      "6709, 16\n",
      "6710, 5\n",
      "6711, 4\n",
      "6712, 6\n",
      "6713, 15\n",
      "6714, 6\n",
      "6715, 7\n",
      "6716, 11\n",
      "6717, 4\n",
      "6718, 6\n",
      "6719, 10\n",
      "6720, 12\n",
      "6721, 14\n",
      "6722, 6\n",
      "6723, 3\n",
      "6724, 10\n",
      "6725, 3\n",
      "6726, 13\n",
      "6727, 7\n",
      "6728, 5\n",
      "6729, 5\n",
      "6730, 9\n",
      "6731, 8\n",
      "6732, 6\n",
      "6733, 8\n",
      "6734, 11\n",
      "6735, 4\n",
      "6736, 5\n",
      "6737, 11\n",
      "6738, 2\n",
      "6739, 12\n",
      "6740, 10\n",
      "6741, 3\n",
      "6742, 11\n",
      "6743, 15\n",
      "6744, 9\n",
      "6745, 7\n",
      "6746, 17\n",
      "6747, 15\n",
      "6748, 14\n",
      "6749, 7\n",
      "6750, 2\n",
      "6751, 10\n",
      "6752, 13\n",
      "6753, 16\n",
      "6754, 4\n",
      "6755, 9\n",
      "6756, 11\n",
      "6757, 12\n",
      "6758, 2\n",
      "6759, 10\n",
      "6760, 4\n",
      "6761, 6\n",
      "6762, 14\n",
      "6763, 6\n",
      "6764, 12\n",
      "6765, 15\n",
      "6766, 6\n",
      "6767, 12\n",
      "6768, 12\n",
      "6769, 2\n",
      "6770, 2\n",
      "6771, 4\n",
      "6772, 4\n",
      "6773, 5\n",
      "6774, 12\n",
      "6775, 3\n",
      "6776, 10\n",
      "6777, 10\n",
      "6778, 3\n",
      "6779, 12\n",
      "6780, 6\n",
      "6781, 5\n",
      "6782, 14\n",
      "6783, 8\n",
      "6784, 5\n",
      "6785, 17\n",
      "6786, 8\n",
      "6787, 11\n",
      "6788, 16\n",
      "6789, 11\n",
      "6790, 11\n",
      "6791, 13\n",
      "6792, 6\n",
      "6793, 4\n",
      "6794, 5\n",
      "6795, 13\n",
      "6796, 3\n",
      "6797, 8\n",
      "6798, 17\n",
      "6799, 0\n",
      "6800, 7\n",
      "6801, 8\n",
      "6802, 6\n",
      "6803, 7\n",
      "6804, 16\n",
      "6805, 8\n",
      "6806, 4\n",
      "6807, 3\n",
      "6808, 10\n",
      "6809, 12\n",
      "6810, 14\n",
      "6811, 13\n",
      "6812, 13\n",
      "6813, 3\n",
      "6814, 9\n",
      "6815, 11\n",
      "6816, 12\n",
      "6817, 7\n",
      "6818, 14\n",
      "6819, 13\n",
      "6820, 4\n",
      "6821, 6\n",
      "6822, 10\n",
      "6823, 8\n",
      "6824, 5\n",
      "6825, 9\n",
      "6826, 5\n",
      "6827, 7\n",
      "6828, 8\n",
      "6829, 11\n",
      "6830, 6\n",
      "6831, 11\n",
      "6832, 7\n",
      "6833, 4\n",
      "6834, 12\n",
      "6835, 7\n",
      "6836, 5\n",
      "6837, 8\n",
      "6838, 10\n",
      "6839, 13\n",
      "6840, 3\n",
      "6841, 13\n",
      "6842, 13\n",
      "6843, 8\n",
      "6844, 9\n",
      "6845, 7\n",
      "6846, 6\n",
      "6847, 14\n",
      "6848, 9\n",
      "6849, 5\n",
      "6850, 9\n",
      "6851, 4\n",
      "6852, 6\n",
      "6853, 17\n",
      "6854, 11\n",
      "6855, 4\n",
      "6856, 11\n",
      "6857, 13\n",
      "6858, 10\n",
      "6859, 10\n",
      "6860, 14\n",
      "6861, 8\n",
      "6862, 10\n",
      "6863, 11\n",
      "6864, 1\n",
      "6865, 12\n",
      "6866, 11\n",
      "6867, 5\n",
      "6868, 9\n",
      "6869, 6\n",
      "6870, 2\n",
      "6871, 2\n",
      "6872, 0\n",
      "6873, 8\n",
      "6874, 3\n",
      "6875, 9\n",
      "6876, 4\n",
      "6877, 14\n",
      "6878, 13\n",
      "6879, 7\n",
      "6880, 15\n",
      "6881, 18\n",
      "6882, 10\n",
      "6883, 4\n",
      "6884, 11\n",
      "6885, 14\n",
      "6886, 12\n",
      "6887, 17\n",
      "6888, 15\n",
      "6889, 12\n",
      "6890, 2\n",
      "6891, 4\n",
      "6892, 16\n",
      "6893, 16\n",
      "6894, 12\n",
      "6895, 11\n",
      "6896, 15\n",
      "6897, 11\n",
      "6898, 10\n",
      "6899, 10\n",
      "6900, 10\n",
      "6901, 7\n",
      "6902, 3\n",
      "6903, 12\n",
      "6904, 17\n",
      "6905, 4\n",
      "6906, 12\n",
      "6907, 10\n",
      "6908, 11\n",
      "6909, 12\n",
      "6910, 7\n",
      "6911, 5\n",
      "6912, 9\n",
      "6913, 5\n",
      "6914, 7\n",
      "6915, 9\n",
      "6916, 2\n",
      "6917, 7\n",
      "6918, 14\n",
      "6919, 6\n",
      "6920, 4\n",
      "6921, 17\n",
      "6922, 2\n",
      "6923, 7\n",
      "6924, 9\n",
      "6925, 7\n",
      "6926, 11\n",
      "6927, 8\n",
      "6928, 10\n",
      "6929, 10\n",
      "6930, 6\n",
      "6931, 13\n",
      "6932, 13\n",
      "6933, 9\n",
      "6934, 5\n",
      "6935, 5\n",
      "6936, 11\n",
      "6937, 12\n",
      "6938, 9\n",
      "6939, 5\n",
      "6940, 2\n",
      "6941, 9\n",
      "6942, 6\n",
      "6943, 12\n",
      "6944, 5\n",
      "6945, 4\n",
      "6946, 3\n",
      "6947, 8\n",
      "6948, 1\n",
      "6949, 11\n",
      "6950, 6\n",
      "6951, 14\n",
      "6952, 8\n",
      "6953, 6\n",
      "6954, 12\n",
      "6955, 14\n",
      "6956, 13\n",
      "6957, 6\n",
      "6958, 6\n",
      "6959, 6\n",
      "6960, 11\n",
      "6961, 9\n",
      "6962, 3\n",
      "6963, 6\n",
      "6964, 8\n",
      "6965, 8\n",
      "6966, 9\n",
      "6967, 1\n",
      "6968, 10\n",
      "6969, 5\n",
      "6970, 2\n",
      "6971, 12\n",
      "6972, 9\n",
      "6973, 9\n",
      "6974, 10\n",
      "6975, 12\n",
      "6976, 15\n",
      "6977, 5\n",
      "6978, 8\n",
      "6979, 11\n",
      "6980, 9\n",
      "6981, 5\n",
      "6982, 11\n",
      "6983, 16\n",
      "6984, 7\n",
      "6985, 8\n",
      "6986, 15\n",
      "6987, 10\n",
      "6988, 13\n",
      "6989, 15\n",
      "6990, 12\n",
      "6991, 11\n",
      "6992, 16\n",
      "6993, 9\n",
      "6994, 18\n",
      "6995, 17\n",
      "6996, 6\n",
      "6997, 9\n",
      "6998, 3\n",
      "6999, 4\n",
      "7000, 16\n",
      "7001, 12\n",
      "7002, 9\n",
      "7003, 3\n",
      "7004, 2\n",
      "7005, 2\n",
      "7006, 12\n",
      "7007, 11\n",
      "7008, 15\n",
      "7009, 6\n",
      "7010, 5\n",
      "7011, 6\n",
      "7012, 8\n",
      "7013, 13\n",
      "7014, 2\n",
      "7015, 5\n",
      "7016, 7\n",
      "7017, 14\n",
      "7018, 3\n",
      "7019, 11\n",
      "7020, 12\n",
      "7021, 2\n",
      "7022, 13\n",
      "7023, 8\n",
      "7024, 12\n",
      "7025, 9\n",
      "7026, 13\n",
      "7027, 7\n",
      "7028, 13\n",
      "7029, 7\n",
      "7030, 8\n",
      "7031, 1\n",
      "7032, 10\n",
      "7033, 15\n",
      "7034, 9\n",
      "7035, 16\n",
      "7036, 7\n",
      "7037, 4\n",
      "7038, 13\n",
      "7039, 11\n",
      "7040, 9\n",
      "7041, 3\n",
      "7042, 10\n",
      "7043, 11\n",
      "7044, 11\n",
      "7045, 9\n",
      "7046, 10\n",
      "7047, 8\n",
      "7048, 8\n",
      "7049, 11\n",
      "7050, 16\n",
      "7051, 3\n",
      "7052, 10\n",
      "7053, 3\n",
      "7054, 11\n",
      "7055, 9\n",
      "7056, 6\n",
      "7057, 10\n",
      "7058, 10\n",
      "7059, 6\n",
      "7060, 4\n",
      "7061, 12\n",
      "7062, 13\n",
      "7063, 8\n",
      "7064, 9\n",
      "7065, 12\n",
      "7066, 12\n",
      "7067, 11\n",
      "7068, 17\n",
      "7069, 11\n",
      "7070, 6\n",
      "7071, 9\n",
      "7072, 17\n",
      "7073, 11\n",
      "7074, 11\n",
      "7075, 11\n",
      "7076, 12\n",
      "7077, 16\n",
      "7078, 12\n",
      "7079, 14\n",
      "7080, 6\n",
      "7081, 7\n",
      "7082, 11\n",
      "7083, 5\n",
      "7084, 16\n",
      "7085, 13\n",
      "7086, 8\n",
      "7087, 6\n",
      "7088, 8\n",
      "7089, 12\n",
      "7090, 5\n",
      "7091, 16\n",
      "7092, 7\n",
      "7093, 16\n",
      "7094, 13\n",
      "7095, 16\n",
      "7096, 12\n",
      "7097, 13\n",
      "7098, 7\n",
      "7099, 9\n",
      "7100, 5\n",
      "7101, 9\n",
      "7102, 12\n",
      "7103, 6\n",
      "7104, 14\n",
      "7105, 9\n",
      "7106, 11\n",
      "7107, 12\n",
      "7108, 9\n",
      "7109, 12\n",
      "7110, 14\n",
      "7111, 15\n",
      "7112, 2\n",
      "7113, 5\n",
      "7114, 6\n",
      "7115, 3\n",
      "7116, 11\n",
      "7117, 8\n",
      "7118, 11\n",
      "7119, 7\n",
      "7120, 13\n",
      "7121, 14\n",
      "7122, 14\n",
      "7123, 13\n",
      "7124, 9\n",
      "7125, 5\n",
      "7126, 5\n",
      "7127, 4\n",
      "7128, 4\n",
      "7129, 10\n",
      "7130, 12\n",
      "7131, 18\n",
      "7132, 5\n",
      "7133, 3\n",
      "7134, 11\n",
      "7135, 15\n",
      "7136, 8\n",
      "7137, 7\n",
      "7138, 6\n",
      "7139, 6\n",
      "7140, 6\n",
      "7141, 12\n",
      "7142, 10\n",
      "7143, 10\n",
      "7144, 16\n",
      "7145, 11\n",
      "7146, 6\n",
      "7147, 3\n",
      "7148, 10\n",
      "7149, 10\n",
      "7150, 5\n",
      "7151, 15\n",
      "7152, 5\n",
      "7153, 9\n",
      "7154, 13\n",
      "7155, 13\n",
      "7156, 17\n",
      "7157, 6\n",
      "7158, 10\n",
      "7159, 17\n",
      "7160, 13\n",
      "7161, 6\n",
      "7162, 4\n",
      "7163, 15\n",
      "7164, 9\n",
      "7165, 7\n",
      "7166, 6\n",
      "7167, 4\n",
      "7168, 12\n",
      "7169, 15\n",
      "7170, 10\n",
      "7171, 13\n",
      "7172, 9\n",
      "7173, 17\n",
      "7174, 6\n",
      "7175, 15\n",
      "7176, 13\n",
      "7177, 14\n",
      "7178, 8\n",
      "7179, 6\n",
      "7180, 5\n",
      "7181, 12\n",
      "7182, 1\n",
      "7183, 13\n",
      "7184, 5\n",
      "7185, 14\n",
      "7186, 10\n",
      "7187, 10\n",
      "7188, 9\n",
      "7189, 10\n",
      "7190, 10\n",
      "7191, 13\n",
      "7192, 8\n",
      "7193, 6\n",
      "7194, 10\n",
      "7195, 7\n",
      "7196, 18\n",
      "7197, 9\n",
      "7198, 5\n",
      "7199, 10\n",
      "7200, 7\n",
      "7201, 8\n",
      "7202, 11\n",
      "7203, 9\n",
      "7204, 14\n",
      "7205, 5\n",
      "7206, 13\n",
      "7207, 6\n",
      "7208, 11\n",
      "7209, 11\n",
      "7210, 18\n",
      "7211, 8\n",
      "7212, 10\n",
      "7213, 2\n",
      "7214, 2\n",
      "7215, 7\n",
      "7216, 3\n",
      "7217, 4\n",
      "7218, 5\n",
      "7219, 7\n",
      "7220, 8\n",
      "7221, 14\n",
      "7222, 0\n",
      "7223, 5\n",
      "7224, 4\n",
      "7225, 8\n",
      "7226, 9\n",
      "7227, 2\n",
      "7228, 11\n",
      "7229, 9\n",
      "7230, 14\n",
      "7231, 12\n",
      "7232, 15\n",
      "7233, 9\n",
      "7234, 10\n",
      "7235, 16\n",
      "7236, 4\n",
      "7237, 8\n",
      "7238, 11\n",
      "7239, 12\n",
      "7240, 4\n",
      "7241, 8\n",
      "7242, 7\n",
      "7243, 6\n",
      "7244, 7\n",
      "7245, 14\n",
      "7246, 5\n",
      "7247, 10\n",
      "7248, 10\n",
      "7249, 12\n",
      "7250, 10\n",
      "7251, 9\n",
      "7252, 9\n",
      "7253, 0\n",
      "7254, 4\n",
      "7255, 10\n",
      "7256, 14\n",
      "7257, 0\n",
      "7258, 10\n",
      "7259, 16\n",
      "7260, 5\n",
      "7261, 12\n",
      "7262, 1\n",
      "7263, 5\n",
      "7264, 7\n",
      "7265, 16\n",
      "7266, 13\n",
      "7267, 12\n",
      "7268, 1\n",
      "7269, 8\n",
      "7270, 9\n",
      "7271, 3\n",
      "7272, 7\n",
      "7273, 9\n",
      "7274, 12\n",
      "7275, 7\n",
      "7276, 4\n",
      "7277, 7\n",
      "7278, 2\n",
      "7279, 4\n",
      "7280, 7\n",
      "7281, 10\n",
      "7282, 13\n",
      "7283, 7\n",
      "7284, 14\n",
      "7285, 7\n",
      "7286, 13\n",
      "7287, 6\n",
      "7288, 18\n",
      "7289, 4\n",
      "7290, 8\n",
      "7291, 16\n",
      "7292, 17\n",
      "7293, 1\n",
      "7294, 14\n",
      "7295, 7\n",
      "7296, 10\n",
      "7297, 10\n",
      "7298, 7\n",
      "7299, 10\n",
      "7300, 8\n",
      "7301, 12\n",
      "7302, 10\n",
      "7303, 13\n",
      "7304, 17\n",
      "7305, 10\n",
      "7306, 12\n",
      "7307, 15\n",
      "7308, 14\n",
      "7309, 13\n",
      "7310, 9\n",
      "7311, 14\n",
      "7312, 10\n",
      "7313, 12\n",
      "7314, 11\n",
      "7315, 15\n",
      "7316, 2\n",
      "7317, 4\n",
      "7318, 13\n",
      "7319, 9\n",
      "7320, 7\n",
      "7321, 1\n",
      "7322, 7\n",
      "7323, 1\n",
      "7324, 15\n",
      "7325, 8\n",
      "7326, 1\n",
      "7327, 10\n",
      "7328, 4\n",
      "7329, 5\n",
      "7330, 9\n",
      "7331, 12\n",
      "7332, 9\n",
      "7333, 5\n",
      "7334, 12\n",
      "7335, 14\n",
      "7336, 12\n",
      "7337, 9\n",
      "7338, 7\n",
      "7339, 7\n",
      "7340, 5\n",
      "7341, 1\n",
      "7342, 16\n",
      "7343, 14\n",
      "7344, 13\n",
      "7345, 12\n",
      "7346, 4\n",
      "7347, 6\n",
      "7348, 4\n",
      "7349, 5\n",
      "7350, 6\n",
      "7351, 13\n",
      "7352, 10\n",
      "7353, 11\n",
      "7354, 10\n",
      "7355, 12\n",
      "7356, 8\n",
      "7357, 15\n",
      "7358, 3\n",
      "7359, 3\n",
      "7360, 4\n",
      "7361, 16\n",
      "7362, 3\n",
      "7363, 6\n",
      "7364, 12\n",
      "7365, 6\n",
      "7366, 10\n",
      "7367, 12\n",
      "7368, 6\n",
      "7369, 6\n",
      "7370, 9\n",
      "7371, 16\n",
      "7372, 6\n",
      "7373, 4\n",
      "7374, 13\n",
      "7375, 5\n",
      "7376, 6\n",
      "7377, 3\n",
      "7378, 7\n",
      "7379, 6\n",
      "7380, 8\n",
      "7381, 10\n",
      "7382, 7\n",
      "7383, 4\n",
      "7384, 15\n",
      "7385, 16\n",
      "7386, 4\n",
      "7387, 12\n",
      "7388, 12\n",
      "7389, 6\n",
      "7390, 9\n",
      "7391, 13\n",
      "7392, 7\n",
      "7393, 15\n",
      "7394, 14\n",
      "7395, 9\n",
      "7396, 9\n",
      "7397, 11\n",
      "7398, 4\n",
      "7399, 13\n",
      "7400, 13\n",
      "7401, 12\n",
      "7402, 6\n",
      "7403, 13\n",
      "7404, 13\n",
      "7405, 9\n",
      "7406, 4\n",
      "7407, 6\n",
      "7408, 8\n",
      "7409, 9\n",
      "7410, 9\n",
      "7411, 10\n",
      "7412, 10\n",
      "7413, 4\n",
      "7414, 10\n",
      "7415, 8\n",
      "7416, 8\n",
      "7417, 7\n",
      "7418, 9\n",
      "7419, 17\n",
      "7420, 4\n",
      "7421, 14\n",
      "7422, 12\n",
      "7423, 9\n",
      "7424, 14\n",
      "7425, 12\n",
      "7426, 16\n",
      "7427, 7\n",
      "7428, 17\n",
      "7429, 12\n",
      "7430, 5\n",
      "7431, 3\n",
      "7432, 8\n",
      "7433, 5\n",
      "7434, 7\n",
      "7435, 8\n",
      "7436, 2\n",
      "7437, 12\n",
      "7438, 6\n",
      "7439, 5\n",
      "7440, 5\n",
      "7441, 8\n",
      "7442, 9\n",
      "7443, 13\n",
      "7444, 8\n",
      "7445, 7\n",
      "7446, 15\n",
      "7447, 3\n",
      "7448, 16\n",
      "7449, 8\n",
      "7450, 5\n",
      "7451, 12\n",
      "7452, 10\n",
      "7453, 16\n",
      "7454, 11\n",
      "7455, 12\n",
      "7456, 10\n",
      "7457, 10\n",
      "7458, 8\n",
      "7459, 13\n",
      "7460, 5\n",
      "7461, 7\n",
      "7462, 14\n",
      "7463, 12\n",
      "7464, 14\n",
      "7465, 12\n",
      "7466, 14\n",
      "7467, 8\n",
      "7468, 6\n",
      "7469, 16\n",
      "7470, 5\n",
      "7471, 2\n",
      "7472, 9\n",
      "7473, 14\n",
      "7474, 12\n",
      "7475, 13\n",
      "7476, 2\n",
      "7477, 15\n",
      "7478, 15\n",
      "7479, 13\n",
      "7480, 6\n",
      "7481, 7\n",
      "7482, 7\n",
      "7483, 5\n",
      "7484, 7\n",
      "7485, 8\n",
      "7486, 1\n",
      "7487, 16\n",
      "7488, 10\n",
      "7489, 4\n",
      "7490, 12\n",
      "7491, 13\n",
      "7492, 5\n",
      "7493, 13\n",
      "7494, 6\n",
      "7495, 2\n",
      "7496, 7\n",
      "7497, 10\n",
      "7498, 8\n",
      "7499, 10\n",
      "7500, 2\n",
      "7501, 6\n",
      "7502, 14\n",
      "7503, 7\n",
      "7504, 14\n",
      "7505, 7\n",
      "7506, 18\n",
      "7507, 11\n",
      "7508, 11\n",
      "7509, 0\n",
      "7510, 4\n",
      "7511, 10\n",
      "7512, 8\n",
      "7513, 17\n",
      "7514, 6\n",
      "7515, 13\n",
      "7516, 12\n",
      "7517, 8\n",
      "7518, 6\n",
      "7519, 13\n",
      "7520, 6\n",
      "7521, 14\n",
      "7522, 3\n",
      "7523, 6\n",
      "7524, 9\n",
      "7525, 8\n",
      "7526, 10\n",
      "7527, 6\n",
      "7528, 9\n",
      "7529, 6\n",
      "7530, 9\n",
      "7531, 6\n",
      "7532, 10\n",
      "7533, 6\n",
      "7534, 1\n",
      "7535, 6\n",
      "7536, 15\n",
      "7537, 9\n",
      "7538, 7\n",
      "7539, 11\n",
      "7540, 16\n",
      "7541, 15\n",
      "7542, 11\n",
      "7543, 6\n",
      "7544, 14\n",
      "7545, 5\n",
      "7546, 9\n",
      "7547, 8\n",
      "7548, 1\n",
      "7549, 11\n",
      "7550, 6\n",
      "7551, 8\n",
      "7552, 7\n",
      "7553, 8\n",
      "7554, 6\n",
      "7555, 10\n",
      "7556, 9\n",
      "7557, 6\n",
      "7558, 12\n",
      "7559, 13\n",
      "7560, 11\n",
      "7561, 13\n",
      "7562, 15\n",
      "7563, 16\n",
      "7564, 5\n",
      "7565, 11\n",
      "7566, 11\n",
      "7567, 11\n",
      "7568, 3\n",
      "7569, 11\n",
      "7570, 5\n",
      "7571, 12\n",
      "7572, 15\n",
      "7573, 14\n",
      "7574, 5\n",
      "7575, 4\n",
      "7576, 6\n",
      "7577, 9\n",
      "7578, 6\n",
      "7579, 7\n",
      "7580, 11\n",
      "7581, 10\n",
      "7582, 9\n",
      "7583, 9\n",
      "7584, 9\n",
      "7585, 12\n",
      "7586, 13\n",
      "7587, 7\n",
      "7588, 10\n",
      "7589, 11\n",
      "7590, 4\n",
      "7591, 12\n",
      "7592, 13\n",
      "7593, 14\n",
      "7594, 9\n",
      "7595, 4\n",
      "7596, 3\n",
      "7597, 2\n",
      "7598, 13\n",
      "7599, 6\n",
      "7600, 13\n",
      "7601, 12\n",
      "7602, 4\n",
      "7603, 3\n",
      "7604, 4\n",
      "7605, 12\n",
      "7606, 5\n",
      "7607, 8\n",
      "7608, 5\n",
      "7609, 6\n",
      "7610, 6\n",
      "7611, 6\n",
      "7612, 7\n",
      "7613, 7\n",
      "7614, 11\n",
      "7615, 9\n",
      "7616, 8\n",
      "7617, 5\n",
      "7618, 8\n",
      "7619, 0\n",
      "7620, 16\n",
      "7621, 4\n",
      "7622, 0\n",
      "7623, 15\n",
      "7624, 6\n",
      "7625, 8\n",
      "7626, 11\n",
      "7627, 8\n",
      "7628, 9\n",
      "7629, 12\n",
      "7630, 15\n",
      "7631, 7\n",
      "7632, 8\n",
      "7633, 5\n",
      "7634, 5\n",
      "7635, 2\n",
      "7636, 5\n",
      "7637, 6\n",
      "7638, 4\n",
      "7639, 13\n",
      "7640, 10\n",
      "7641, 8\n",
      "7642, 6\n",
      "7643, 12\n",
      "7644, 9\n",
      "7645, 3\n",
      "7646, 7\n",
      "7647, 11\n",
      "7648, 8\n",
      "7649, 1\n",
      "7650, 7\n",
      "7651, 16\n",
      "7652, 9\n",
      "7653, 14\n",
      "7654, 2\n",
      "7655, 8\n",
      "7656, 7\n",
      "7657, 10\n",
      "7658, 13\n",
      "7659, 4\n",
      "7660, 14\n",
      "7661, 14\n",
      "7662, 6\n",
      "7663, 7\n",
      "7664, 13\n",
      "7665, 7\n",
      "7666, 0\n",
      "7667, 5\n",
      "7668, 11\n",
      "7669, 4\n",
      "7670, 7\n",
      "7671, 8\n",
      "7672, 3\n",
      "7673, 9\n",
      "7674, 10\n",
      "7675, 2\n",
      "7676, 9\n",
      "7677, 8\n",
      "7678, 9\n",
      "7679, 13\n",
      "7680, 12\n",
      "7681, 10\n",
      "7682, 13\n",
      "7683, 7\n",
      "7684, 7\n",
      "7685, 9\n",
      "7686, 13\n",
      "7687, 13\n",
      "7688, 0\n",
      "7689, 9\n",
      "7690, 12\n",
      "7691, 14\n",
      "7692, 9\n",
      "7693, 10\n",
      "7694, 5\n",
      "7695, 1\n",
      "7696, 6\n",
      "7697, 4\n",
      "7698, 7\n",
      "7699, 13\n",
      "7700, 5\n",
      "7701, 15\n",
      "7702, 8\n",
      "7703, 5\n",
      "7704, 10\n",
      "7705, 7\n",
      "7706, 14\n",
      "7707, 5\n",
      "7708, 2\n",
      "7709, 4\n",
      "7710, 10\n",
      "7711, 6\n",
      "7712, 10\n",
      "7713, 11\n",
      "7714, 4\n",
      "7715, 11\n",
      "7716, 13\n",
      "7717, 5\n",
      "7718, 14\n",
      "7719, 9\n",
      "7720, 9\n",
      "7721, 7\n",
      "7722, 14\n",
      "7723, 5\n",
      "7724, 8\n",
      "7725, 10\n",
      "7726, 12\n",
      "7727, 8\n",
      "7728, 14\n",
      "7729, 11\n",
      "7730, 5\n",
      "7731, 12\n",
      "7732, 4\n",
      "7733, 12\n",
      "7734, 7\n",
      "7735, 13\n",
      "7736, 9\n",
      "7737, 11\n",
      "7738, 15\n",
      "7739, 3\n",
      "7740, 9\n",
      "7741, 4\n",
      "7742, 17\n",
      "7743, 9\n",
      "7744, 4\n",
      "7745, 7\n",
      "7746, 17\n",
      "7747, 2\n",
      "7748, 12\n",
      "7749, 7\n",
      "7750, 10\n",
      "7751, 7\n",
      "7752, 14\n",
      "7753, 7\n",
      "7754, 10\n",
      "7755, 12\n",
      "7756, 10\n",
      "7757, 8\n",
      "7758, 17\n",
      "7759, 4\n",
      "7760, 12\n",
      "7761, 8\n",
      "7762, 15\n",
      "7763, 9\n",
      "7764, 17\n",
      "7765, 8\n",
      "7766, 11\n",
      "7767, 15\n",
      "7768, 9\n",
      "7769, 7\n",
      "7770, 15\n",
      "7771, 6\n",
      "7772, 10\n",
      "7773, 6\n",
      "7774, 3\n",
      "7775, 13\n",
      "7776, 17\n",
      "7777, 15\n",
      "7778, 6\n",
      "7779, 13\n",
      "7780, 2\n",
      "7781, 7\n",
      "7782, 11\n",
      "7783, 11\n",
      "7784, 7\n",
      "7785, 5\n",
      "7786, 3\n",
      "7787, 1\n",
      "7788, 11\n",
      "7789, 14\n",
      "7790, 13\n",
      "7791, 10\n",
      "7792, 1\n",
      "7793, 8\n",
      "7794, 7\n",
      "7795, 4\n",
      "7796, 9\n",
      "7797, 12\n",
      "7798, 11\n",
      "7799, 3\n",
      "7800, 15\n",
      "7801, 12\n",
      "7802, 8\n",
      "7803, 7\n",
      "7804, 3\n",
      "7805, 11\n",
      "7806, 15\n",
      "7807, 7\n",
      "7808, 12\n",
      "7809, 11\n",
      "7810, 8\n",
      "7811, 1\n",
      "7812, 4\n",
      "7813, 12\n",
      "7814, 10\n",
      "7815, 15\n",
      "7816, 14\n",
      "7817, 3\n",
      "7818, 9\n",
      "7819, 11\n",
      "7820, 5\n",
      "7821, 4\n",
      "7822, 12\n",
      "7823, 6\n",
      "7824, 11\n",
      "7825, 4\n",
      "7826, 13\n",
      "7827, 5\n",
      "7828, 6\n",
      "7829, 9\n",
      "7830, 3\n",
      "7831, 8\n",
      "7832, 12\n",
      "7833, 9\n",
      "7834, 8\n",
      "7835, 6\n",
      "7836, 14\n",
      "7837, 14\n",
      "7838, 14\n",
      "7839, 11\n",
      "7840, 16\n",
      "7841, 15\n",
      "7842, 10\n",
      "7843, 9\n",
      "7844, 3\n",
      "7845, 4\n",
      "7846, 9\n",
      "7847, 4\n",
      "7848, 8\n",
      "7849, 6\n",
      "7850, 13\n",
      "7851, 9\n",
      "7852, 13\n",
      "7853, 8\n",
      "7854, 13\n",
      "7855, 10\n",
      "7856, 13\n",
      "7857, 7\n",
      "7858, 7\n",
      "7859, 7\n",
      "7860, 13\n",
      "7861, 2\n",
      "7862, 14\n",
      "7863, 6\n",
      "7864, 4\n",
      "7865, 8\n",
      "7866, 9\n",
      "7867, 9\n",
      "7868, 12\n",
      "7869, 2\n",
      "7870, 12\n",
      "7871, 14\n",
      "7872, 10\n",
      "7873, 6\n",
      "7874, 16\n",
      "7875, 2\n",
      "7876, 15\n",
      "7877, 8\n",
      "7878, 10\n",
      "7879, 11\n",
      "7880, 10\n",
      "7881, 3\n",
      "7882, 10\n",
      "7883, 17\n",
      "7884, 6\n",
      "7885, 1\n",
      "7886, 6\n",
      "7887, 8\n",
      "7888, 15\n",
      "7889, 7\n",
      "7890, 11\n",
      "7891, 9\n",
      "7892, 9\n",
      "7893, 8\n",
      "7894, 5\n",
      "7895, 15\n",
      "7896, 2\n",
      "7897, 13\n",
      "7898, 7\n",
      "7899, 10\n",
      "7900, 7\n",
      "7901, 13\n",
      "7902, 7\n",
      "7903, 0\n",
      "7904, 2\n",
      "7905, 7\n",
      "7906, 8\n",
      "7907, 7\n",
      "7908, 15\n",
      "7909, 10\n",
      "7910, 7\n",
      "7911, 15\n",
      "7912, 16\n",
      "7913, 7\n",
      "7914, 11\n",
      "7915, 1\n",
      "7916, 4\n",
      "7917, 16\n",
      "7918, 6\n",
      "7919, 0\n",
      "7920, 15\n",
      "7921, 7\n",
      "7922, 7\n",
      "7923, 12\n",
      "7924, 13\n",
      "7925, 11\n",
      "7926, 6\n",
      "7927, 9\n",
      "7928, 5\n",
      "7929, 7\n",
      "7930, 11\n",
      "7931, 9\n",
      "7932, 1\n",
      "7933, 8\n",
      "7934, 2\n",
      "7935, 12\n",
      "7936, 12\n",
      "7937, 12\n",
      "7938, 6\n",
      "7939, 12\n",
      "7940, 2\n",
      "7941, 14\n",
      "7942, 9\n",
      "7943, 11\n",
      "7944, 1\n",
      "7945, 7\n",
      "7946, 12\n",
      "7947, 7\n",
      "7948, 11\n",
      "7949, 9\n",
      "7950, 6\n",
      "7951, 15\n",
      "7952, 14\n",
      "7953, 1\n",
      "7954, 11\n",
      "7955, 3\n",
      "7956, 4\n",
      "7957, 5\n",
      "7958, 7\n",
      "7959, 11\n",
      "7960, 12\n",
      "7961, 15\n",
      "7962, 13\n",
      "7963, 6\n",
      "7964, 9\n",
      "7965, 6\n",
      "7966, 2\n",
      "7967, 10\n",
      "7968, 3\n",
      "7969, 11\n",
      "7970, 4\n",
      "7971, 12\n",
      "7972, 4\n",
      "7973, 6\n",
      "7974, 7\n",
      "7975, 6\n",
      "7976, 12\n",
      "7977, 11\n",
      "7978, 2\n",
      "7979, 11\n",
      "7980, 10\n",
      "7981, 5\n",
      "7982, 12\n",
      "7983, 13\n",
      "7984, 12\n",
      "7985, 5\n",
      "7986, 4\n",
      "7987, 10\n",
      "7988, 7\n",
      "7989, 11\n",
      "7990, 7\n",
      "7991, 11\n",
      "7992, 6\n",
      "7993, 3\n",
      "7994, 10\n",
      "7995, 16\n",
      "7996, 13\n",
      "7997, 7\n",
      "7998, 12\n",
      "7999, 6\n",
      "8000, 11\n",
      "8001, 7\n",
      "8002, 4\n",
      "8003, 8\n",
      "8004, 3\n",
      "8005, 17\n",
      "8006, 8\n",
      "8007, 7\n",
      "8008, 10\n",
      "8009, 7\n",
      "8010, 2\n",
      "8011, 15\n",
      "8012, 9\n",
      "8013, 7\n",
      "8014, 2\n",
      "8015, 12\n",
      "8016, 3\n",
      "8017, 13\n",
      "8018, 10\n",
      "8019, 9\n",
      "8020, 7\n",
      "8021, 6\n",
      "8022, 11\n",
      "8023, 7\n",
      "8024, 10\n",
      "8025, 3\n",
      "8026, 7\n",
      "8027, 10\n",
      "8028, 11\n",
      "8029, 17\n",
      "8030, 8\n",
      "8031, 8\n",
      "8032, 7\n",
      "8033, 11\n",
      "8034, 10\n",
      "8035, 9\n",
      "8036, 6\n",
      "8037, 3\n",
      "8038, 5\n",
      "8039, 16\n",
      "8040, 14\n",
      "8041, 4\n",
      "8042, 2\n",
      "8043, 4\n",
      "8044, 7\n",
      "8045, 1\n",
      "8046, 7\n",
      "8047, 18\n",
      "8048, 7\n",
      "8049, 11\n",
      "8050, 5\n",
      "8051, 1\n",
      "8052, 7\n",
      "8053, 7\n",
      "8054, 14\n",
      "8055, 12\n",
      "8056, 13\n",
      "8057, 9\n",
      "8058, 11\n",
      "8059, 10\n",
      "8060, 7\n",
      "8061, 7\n",
      "8062, 14\n",
      "8063, 13\n",
      "8064, 13\n",
      "8065, 5\n",
      "8066, 11\n",
      "8067, 14\n",
      "8068, 7\n",
      "8069, 14\n",
      "8070, 6\n",
      "8071, 13\n",
      "8072, 1\n",
      "8073, 12\n",
      "8074, 11\n",
      "8075, 8\n",
      "8076, 13\n",
      "8077, 7\n",
      "8078, 2\n",
      "8079, 10\n",
      "8080, 6\n",
      "8081, 6\n",
      "8082, 11\n",
      "8083, 11\n",
      "8084, 6\n",
      "8085, 12\n",
      "8086, 2\n",
      "8087, 7\n",
      "8088, 11\n",
      "8089, 6\n",
      "8090, 17\n",
      "8091, 8\n",
      "8092, 7\n",
      "8093, 18\n",
      "8094, 5\n",
      "8095, 13\n",
      "8096, 9\n",
      "8097, 11\n",
      "8098, 13\n",
      "8099, 10\n",
      "8100, 5\n",
      "8101, 7\n",
      "8102, 15\n",
      "8103, 10\n",
      "8104, 8\n",
      "8105, 7\n",
      "8106, 13\n",
      "8107, 6\n",
      "8108, 14\n",
      "8109, 11\n",
      "8110, 5\n",
      "8111, 17\n",
      "8112, 7\n",
      "8113, 17\n",
      "8114, 16\n",
      "8115, 7\n",
      "8116, 4\n",
      "8117, 13\n",
      "8118, 6\n",
      "8119, 14\n",
      "8120, 6\n",
      "8121, 6\n",
      "8122, 11\n",
      "8123, 10\n",
      "8124, 7\n",
      "8125, 8\n",
      "8126, 9\n",
      "8127, 12\n",
      "8128, 14\n",
      "8129, 7\n",
      "8130, 15\n",
      "8131, 4\n",
      "8132, 7\n",
      "8133, 7\n",
      "8134, 13\n",
      "8135, 9\n",
      "8136, 15\n",
      "8137, 0\n",
      "8138, 10\n",
      "8139, 5\n",
      "8140, 9\n",
      "8141, 11\n",
      "8142, 5\n",
      "8143, 11\n",
      "8144, 4\n",
      "8145, 7\n",
      "8146, 12\n",
      "8147, 12\n",
      "8148, 7\n",
      "8149, 17\n",
      "8150, 1\n",
      "8151, 12\n",
      "8152, 7\n",
      "8153, 6\n",
      "8154, 8\n",
      "8155, 3\n",
      "8156, 7\n",
      "8157, 11\n",
      "8158, 16\n",
      "8159, 14\n",
      "8160, 16\n",
      "8161, 13\n",
      "8162, 16\n",
      "8163, 11\n",
      "8164, 5\n",
      "8165, 7\n",
      "8166, 15\n",
      "8167, 14\n",
      "8168, 8\n",
      "8169, 7\n",
      "8170, 11\n",
      "8171, 7\n",
      "8172, 7\n",
      "8173, 17\n",
      "8174, 5\n",
      "8175, 7\n",
      "8176, 4\n",
      "8177, 4\n",
      "8178, 14\n",
      "8179, 9\n",
      "8180, 6\n",
      "8181, 11\n",
      "8182, 7\n",
      "8183, 9\n",
      "8184, 3\n",
      "8185, 8\n",
      "8186, 5\n",
      "8187, 7\n",
      "8188, 17\n",
      "8189, 7\n",
      "8190, 11\n",
      "8191, 12\n",
      "8192, 13\n",
      "8193, 8\n",
      "8194, 0\n",
      "8195, 15\n",
      "8196, 9\n",
      "8197, 13\n",
      "8198, 5\n",
      "8199, 9\n",
      "8200, 1\n",
      "8201, 1\n",
      "8202, 4\n",
      "8203, 3\n",
      "8204, 11\n",
      "8205, 9\n",
      "8206, 10\n",
      "8207, 8\n",
      "8208, 14\n",
      "8209, 6\n",
      "8210, 9\n",
      "8211, 3\n",
      "8212, 14\n",
      "8213, 6\n",
      "8214, 12\n",
      "8215, 15\n",
      "8216, 9\n",
      "8217, 9\n",
      "8218, 6\n",
      "8219, 13\n",
      "8220, 11\n",
      "8221, 6\n",
      "8222, 14\n",
      "8223, 11\n",
      "8224, 1\n",
      "8225, 12\n",
      "8226, 5\n",
      "8227, 3\n",
      "8228, 4\n",
      "8229, 8\n",
      "8230, 10\n",
      "8231, 9\n",
      "8232, 17\n",
      "8233, 12\n",
      "8234, 3\n",
      "8235, 2\n",
      "8236, 7\n",
      "8237, 3\n",
      "8238, 10\n",
      "8239, 14\n",
      "8240, 11\n",
      "8241, 14\n",
      "8242, 1\n",
      "8243, 8\n",
      "8244, 10\n",
      "8245, 11\n",
      "8246, 1\n",
      "8247, 11\n",
      "8248, 11\n",
      "8249, 5\n",
      "8250, 15\n",
      "8251, 7\n",
      "8252, 10\n",
      "8253, 5\n",
      "8254, 1\n",
      "8255, 5\n",
      "8256, 16\n",
      "8257, 14\n",
      "8258, 13\n",
      "8259, 7\n",
      "8260, 15\n",
      "8261, 7\n",
      "8262, 2\n",
      "8263, 11\n",
      "8264, 3\n",
      "8265, 4\n",
      "8266, 11\n",
      "8267, 6\n",
      "8268, 9\n",
      "8269, 10\n",
      "8270, 5\n",
      "8271, 2\n",
      "8272, 6\n",
      "8273, 5\n",
      "8274, 0\n",
      "8275, 15\n",
      "8276, 9\n",
      "8277, 8\n",
      "8278, 12\n",
      "8279, 11\n",
      "8280, 7\n",
      "8281, 12\n",
      "8282, 8\n",
      "8283, 10\n",
      "8284, 9\n",
      "8285, 10\n",
      "8286, 5\n",
      "8287, 7\n",
      "8288, 13\n",
      "8289, 10\n",
      "8290, 8\n",
      "8291, 11\n",
      "8292, 10\n",
      "8293, 9\n",
      "8294, 7\n",
      "8295, 2\n",
      "8296, 5\n",
      "8297, 8\n",
      "8298, 16\n",
      "8299, 7\n",
      "8300, 7\n",
      "8301, 6\n",
      "8302, 1\n",
      "8303, 8\n",
      "8304, 15\n",
      "8305, 14\n",
      "8306, 5\n",
      "8307, 3\n",
      "8308, 10\n",
      "8309, 12\n",
      "8310, 14\n",
      "8311, 13\n",
      "8312, 11\n",
      "8313, 6\n",
      "8314, 10\n",
      "8315, 3\n",
      "8316, 9\n",
      "8317, 11\n",
      "8318, 8\n",
      "8319, 4\n",
      "8320, 3\n",
      "8321, 11\n",
      "8322, 10\n",
      "8323, 11\n",
      "8324, 5\n",
      "8325, 11\n",
      "8326, 17\n",
      "8327, 1\n",
      "8328, 9\n",
      "8329, 9\n",
      "8330, 1\n",
      "8331, 1\n",
      "8332, 4\n",
      "8333, 6\n",
      "8334, 12\n",
      "8335, 11\n",
      "8336, 7\n",
      "8337, 13\n",
      "8338, 14\n",
      "8339, 13\n",
      "8340, 11\n",
      "8341, 10\n",
      "8342, 13\n",
      "8343, 15\n",
      "8344, 5\n",
      "8345, 11\n",
      "8346, 15\n",
      "8347, 6\n",
      "8348, 6\n",
      "8349, 15\n",
      "8350, 7\n",
      "8351, 17\n",
      "8352, 9\n",
      "8353, 8\n",
      "8354, 6\n",
      "8355, 12\n",
      "8356, 7\n",
      "8357, 7\n",
      "8358, 3\n",
      "8359, 12\n",
      "8360, 4\n",
      "8361, 3\n",
      "8362, 7\n",
      "8363, 10\n",
      "8364, 3\n",
      "8365, 14\n",
      "8366, 8\n",
      "8367, 8\n",
      "8368, 12\n",
      "8369, 10\n",
      "8370, 10\n",
      "8371, 6\n",
      "8372, 8\n",
      "8373, 10\n",
      "8374, 7\n",
      "8375, 14\n",
      "8376, 4\n",
      "8377, 10\n",
      "8378, 13\n",
      "8379, 8\n",
      "8380, 9\n",
      "8381, 9\n",
      "8382, 14\n",
      "8383, 0\n",
      "8384, 1\n",
      "8385, 3\n",
      "8386, 4\n",
      "8387, 12\n",
      "8388, 11\n",
      "8389, 8\n",
      "8390, 7\n",
      "8391, 3\n",
      "8392, 7\n",
      "8393, 11\n",
      "8394, 6\n",
      "8395, 3\n",
      "8396, 14\n",
      "8397, 9\n",
      "8398, 15\n",
      "8399, 9\n",
      "8400, 9\n",
      "8401, 14\n",
      "8402, 12\n",
      "8403, 12\n",
      "8404, 17\n",
      "8405, 8\n",
      "8406, 9\n",
      "8407, 8\n",
      "8408, 12\n",
      "8409, 11\n",
      "8410, 8\n",
      "8411, 14\n",
      "8412, 12\n",
      "8413, 10\n",
      "8414, 11\n",
      "8415, 13\n",
      "8416, 11\n",
      "8417, 13\n",
      "8418, 6\n",
      "8419, 7\n",
      "8420, 7\n",
      "8421, 10\n",
      "8422, 16\n",
      "8423, 14\n",
      "8424, 9\n",
      "8425, 7\n",
      "8426, 15\n",
      "8427, 10\n",
      "8428, 10\n",
      "8429, 9\n",
      "8430, 3\n",
      "8431, 7\n",
      "8432, 9\n",
      "8433, 8\n",
      "8434, 10\n",
      "8435, 14\n",
      "8436, 13\n",
      "8437, 16\n",
      "8438, 14\n",
      "8439, 10\n",
      "8440, 8\n",
      "8441, 11\n",
      "8442, 10\n",
      "8443, 10\n",
      "8444, 10\n",
      "8445, 3\n",
      "8446, 3\n",
      "8447, 4\n",
      "8448, 11\n",
      "8449, 6\n",
      "8450, 17\n",
      "8451, 8\n",
      "8452, 13\n",
      "8453, 8\n",
      "8454, 8\n",
      "8455, 11\n",
      "8456, 13\n",
      "8457, 5\n",
      "8458, 9\n",
      "8459, 11\n",
      "8460, 3\n",
      "8461, 5\n",
      "8462, 2\n",
      "8463, 1\n",
      "8464, 10\n",
      "8465, 16\n",
      "8466, 5\n",
      "8467, 18\n",
      "8468, 9\n",
      "8469, 16\n",
      "8470, 7\n",
      "8471, 6\n",
      "8472, 9\n",
      "8473, 3\n",
      "8474, 7\n",
      "8475, 14\n",
      "8476, 9\n",
      "8477, 6\n",
      "8478, 13\n",
      "8479, 10\n",
      "8480, 8\n",
      "8481, 13\n",
      "8482, 6\n",
      "8483, 14\n",
      "8484, 8\n",
      "8485, 7\n",
      "8486, 17\n",
      "8487, 11\n",
      "8488, 11\n",
      "8489, 8\n",
      "8490, 11\n",
      "8491, 17\n",
      "8492, 3\n",
      "8493, 0\n",
      "8494, 5\n",
      "8495, 13\n",
      "8496, 8\n",
      "8497, 5\n",
      "8498, 2\n",
      "8499, 14\n",
      "8500, 8\n",
      "8501, 13\n",
      "8502, 9\n",
      "8503, 8\n",
      "8504, 14\n",
      "8505, 16\n",
      "8506, 14\n",
      "8507, 3\n",
      "8508, 7\n",
      "8509, 2\n",
      "8510, 8\n",
      "8511, 11\n",
      "8512, 10\n",
      "8513, 5\n",
      "8514, 10\n",
      "8515, 2\n",
      "8516, 6\n",
      "8517, 4\n",
      "8518, 7\n",
      "8519, 1\n",
      "8520, 8\n",
      "8521, 14\n",
      "8522, 7\n",
      "8523, 7\n",
      "8524, 5\n",
      "8525, 12\n",
      "8526, 14\n",
      "8527, 12\n",
      "8528, 6\n",
      "8529, 11\n",
      "8530, 5\n",
      "8531, 1\n",
      "8532, 13\n",
      "8533, 4\n",
      "8534, 1\n",
      "8535, 12\n",
      "8536, 8\n",
      "8537, 12\n",
      "8538, 0\n",
      "8539, 9\n",
      "8540, 15\n",
      "8541, 7\n",
      "8542, 11\n",
      "8543, 8\n",
      "8544, 7\n",
      "8545, 12\n",
      "8546, 11\n",
      "8547, 7\n",
      "8548, 4\n",
      "8549, 13\n",
      "8550, 4\n",
      "8551, 11\n",
      "8552, 15\n",
      "8553, 11\n",
      "8554, 8\n",
      "8555, 0\n",
      "8556, 4\n",
      "8557, 8\n",
      "8558, 16\n",
      "8559, 6\n",
      "8560, 5\n",
      "8561, 10\n",
      "8562, 10\n",
      "8563, 5\n",
      "8564, 13\n",
      "8565, 9\n",
      "8566, 1\n",
      "8567, 6\n",
      "8568, 6\n",
      "8569, 1\n",
      "8570, 9\n",
      "8571, 11\n",
      "8572, 5\n",
      "8573, 5\n",
      "8574, 13\n",
      "8575, 15\n",
      "8576, 8\n",
      "8577, 5\n",
      "8578, 13\n",
      "8579, 11\n",
      "8580, 2\n",
      "8581, 11\n",
      "8582, 8\n",
      "8583, 6\n",
      "8584, 4\n",
      "8585, 6\n",
      "8586, 12\n",
      "8587, 12\n",
      "8588, 2\n",
      "8589, 14\n",
      "8590, 8\n",
      "8591, 9\n",
      "8592, 7\n",
      "8593, 10\n",
      "8594, 12\n",
      "8595, 8\n",
      "8596, 2\n",
      "8597, 9\n",
      "8598, 6\n",
      "8599, 2\n",
      "8600, 12\n",
      "8601, 10\n",
      "8602, 4\n",
      "8603, 5\n",
      "8604, 10\n",
      "8605, 5\n",
      "8606, 15\n",
      "8607, 10\n",
      "8608, 4\n",
      "8609, 18\n",
      "8610, 11\n",
      "8611, 8\n",
      "8612, 13\n",
      "8613, 8\n",
      "8614, 3\n",
      "8615, 10\n",
      "8616, 3\n",
      "8617, 5\n",
      "8618, 13\n",
      "8619, 5\n",
      "8620, 17\n",
      "8621, 13\n",
      "8622, 6\n",
      "8623, 11\n",
      "8624, 8\n",
      "8625, 8\n",
      "8626, 7\n",
      "8627, 5\n",
      "8628, 8\n",
      "8629, 10\n",
      "8630, 12\n",
      "8631, 7\n",
      "8632, 15\n",
      "8633, 17\n",
      "8634, 4\n",
      "8635, 10\n",
      "8636, 12\n",
      "8637, 2\n",
      "8638, 8\n",
      "8639, 5\n",
      "8640, 7\n",
      "8641, 3\n",
      "8642, 1\n",
      "8643, 10\n",
      "8644, 7\n",
      "8645, 10\n",
      "8646, 6\n",
      "8647, 15\n",
      "8648, 13\n",
      "8649, 14\n",
      "8650, 6\n",
      "8651, 15\n",
      "8652, 4\n",
      "8653, 9\n",
      "8654, 6\n",
      "8655, 10\n",
      "8656, 4\n",
      "8657, 3\n",
      "8658, 3\n",
      "8659, 13\n",
      "8660, 8\n",
      "8661, 12\n",
      "8662, 17\n",
      "8663, 5\n",
      "8664, 13\n",
      "8665, 9\n",
      "8666, 10\n",
      "8667, 15\n",
      "8668, 10\n",
      "8669, 10\n",
      "8670, 9\n",
      "8671, 12\n",
      "8672, 10\n",
      "8673, 7\n",
      "8674, 11\n",
      "8675, 8\n",
      "8676, 7\n",
      "8677, 4\n",
      "8678, 4\n",
      "8679, 7\n",
      "8680, 7\n",
      "8681, 7\n",
      "8682, 13\n",
      "8683, 10\n",
      "8684, 13\n",
      "8685, 9\n",
      "8686, 10\n",
      "8687, 9\n",
      "8688, 8\n",
      "8689, 4\n",
      "8690, 0\n",
      "8691, 2\n",
      "8692, 12\n",
      "8693, 7\n",
      "8694, 11\n",
      "8695, 9\n",
      "8696, 6\n",
      "8697, 9\n",
      "8698, 15\n",
      "8699, 2\n",
      "8700, 13\n",
      "8701, 10\n",
      "8702, 9\n",
      "8703, 10\n",
      "8704, 1\n",
      "8705, 13\n",
      "8706, 3\n",
      "8707, 17\n",
      "8708, 10\n",
      "8709, 4\n",
      "8710, 9\n",
      "8711, 2\n",
      "8712, 3\n",
      "8713, 11\n",
      "8714, 7\n",
      "8715, 4\n",
      "8716, 3\n",
      "8717, 4\n",
      "8718, 11\n",
      "8719, 10\n",
      "8720, 8\n",
      "8721, 11\n",
      "8722, 16\n",
      "8723, 15\n",
      "8724, 3\n",
      "8725, 12\n",
      "8726, 4\n",
      "8727, 15\n",
      "8728, 10\n",
      "8729, 13\n",
      "8730, 7\n",
      "8731, 7\n",
      "8732, 14\n",
      "8733, 12\n",
      "8734, 14\n",
      "8735, 9\n",
      "8736, 12\n",
      "8737, 4\n",
      "8738, 3\n",
      "8739, 15\n",
      "8740, 9\n",
      "8741, 4\n",
      "8742, 7\n",
      "8743, 15\n",
      "8744, 4\n",
      "8745, 6\n",
      "8746, 12\n",
      "8747, 12\n",
      "8748, 5\n",
      "8749, 9\n",
      "8750, 3\n",
      "8751, 6\n",
      "8752, 6\n",
      "8753, 9\n",
      "8754, 4\n",
      "8755, 9\n",
      "8756, 18\n",
      "8757, 15\n",
      "8758, 7\n",
      "8759, 0\n",
      "8760, 1\n",
      "8761, 4\n",
      "8762, 6\n",
      "8763, 15\n",
      "8764, 8\n",
      "8765, 13\n",
      "8766, 9\n",
      "8767, 6\n",
      "8768, 11\n",
      "8769, 3\n",
      "8770, 13\n",
      "8771, 11\n",
      "8772, 2\n",
      "8773, 11\n",
      "8774, 15\n",
      "8775, 10\n",
      "8776, 16\n",
      "8777, 11\n",
      "8778, 9\n",
      "8779, 11\n",
      "8780, 14\n",
      "8781, 11\n",
      "8782, 7\n",
      "8783, 3\n",
      "8784, 13\n",
      "8785, 13\n",
      "8786, 7\n",
      "8787, 12\n",
      "8788, 12\n",
      "8789, 15\n",
      "8790, 10\n",
      "8791, 8\n",
      "8792, 10\n",
      "8793, 5\n",
      "8794, 10\n",
      "8795, 5\n",
      "8796, 17\n",
      "8797, 11\n",
      "8798, 7\n",
      "8799, 14\n",
      "8800, 1\n",
      "8801, 3\n",
      "8802, 7\n",
      "8803, 10\n",
      "8804, 4\n",
      "8805, 3\n",
      "8806, 7\n",
      "8807, 9\n",
      "8808, 4\n",
      "8809, 7\n",
      "8810, 1\n",
      "8811, 8\n",
      "8812, 12\n",
      "8813, 9\n",
      "8814, 12\n",
      "8815, 10\n",
      "8816, 14\n",
      "8817, 8\n",
      "8818, 10\n",
      "8819, 4\n",
      "8820, 14\n",
      "8821, 7\n",
      "8822, 15\n",
      "8823, 8\n",
      "8824, 13\n",
      "8825, 14\n",
      "8826, 7\n",
      "8827, 14\n",
      "8828, 6\n",
      "8829, 3\n",
      "8830, 1\n",
      "8831, 5\n",
      "8832, 11\n",
      "8833, 13\n",
      "8834, 3\n",
      "8835, 14\n",
      "8836, 11\n",
      "8837, 6\n",
      "8838, 4\n",
      "8839, 2\n",
      "8840, 10\n",
      "8841, 4\n",
      "8842, 13\n",
      "8843, 7\n",
      "8844, 2\n",
      "8845, 8\n",
      "8846, 11\n",
      "8847, 4\n",
      "8848, 15\n",
      "8849, 8\n",
      "8850, 11\n",
      "8851, 7\n",
      "8852, 10\n",
      "8853, 10\n",
      "8854, 10\n",
      "8855, 12\n",
      "8856, 3\n",
      "8857, 3\n",
      "8858, 2\n",
      "8859, 7\n",
      "8860, 4\n",
      "8861, 5\n",
      "8862, 10\n",
      "8863, 4\n",
      "8864, 1\n",
      "8865, 5\n",
      "8866, 11\n",
      "8867, 9\n",
      "8868, 9\n",
      "8869, 7\n",
      "8870, 5\n",
      "8871, 3\n",
      "8872, 2\n",
      "8873, 8\n",
      "8874, 7\n",
      "8875, 11\n",
      "8876, 13\n",
      "8877, 3\n",
      "8878, 12\n",
      "8879, 15\n",
      "8880, 9\n",
      "8881, 11\n",
      "8882, 9\n",
      "8883, 9\n",
      "8884, 8\n",
      "8885, 3\n",
      "8886, 5\n",
      "8887, 9\n",
      "8888, 10\n",
      "8889, 3\n",
      "8890, 16\n",
      "8891, 6\n",
      "8892, 13\n",
      "8893, 11\n",
      "8894, 6\n",
      "8895, 3\n",
      "8896, 16\n",
      "8897, 9\n",
      "8898, 11\n",
      "8899, 15\n",
      "8900, 5\n",
      "8901, 8\n",
      "8902, 10\n",
      "8903, 7\n",
      "8904, 3\n",
      "8905, 5\n",
      "8906, 11\n",
      "8907, 10\n",
      "8908, 6\n",
      "8909, 8\n",
      "8910, 9\n",
      "8911, 1\n",
      "8912, 5\n",
      "8913, 4\n",
      "8914, 9\n",
      "8915, 4\n",
      "8916, 11\n",
      "8917, 10\n",
      "8918, 8\n",
      "8919, 12\n",
      "8920, 13\n",
      "8921, 12\n",
      "8922, 12\n",
      "8923, 7\n",
      "8924, 5\n",
      "8925, 4\n",
      "8926, 8\n",
      "8927, 3\n",
      "8928, 8\n",
      "8929, 2\n",
      "8930, 7\n",
      "8931, 7\n",
      "8932, 10\n",
      "8933, 12\n",
      "8934, 2\n",
      "8935, 4\n",
      "8936, 2\n",
      "8937, 6\n",
      "8938, 11\n",
      "8939, 6\n",
      "8940, 6\n",
      "8941, 7\n",
      "8942, 11\n",
      "8943, 8\n",
      "8944, 6\n",
      "8945, 5\n",
      "8946, 12\n",
      "8947, 0\n",
      "8948, 5\n",
      "8949, 11\n",
      "8950, 5\n",
      "8951, 9\n",
      "8952, 7\n",
      "8953, 5\n",
      "8954, 14\n",
      "8955, 8\n",
      "8956, 4\n",
      "8957, 2\n",
      "8958, 11\n",
      "8959, 8\n",
      "8960, 10\n",
      "8961, 12\n",
      "8962, 8\n",
      "8963, 3\n",
      "8964, 9\n",
      "8965, 3\n",
      "8966, 14\n",
      "8967, 3\n",
      "8968, 10\n",
      "8969, 10\n",
      "8970, 12\n",
      "8971, 10\n",
      "8972, 4\n",
      "8973, 8\n",
      "8974, 11\n",
      "8975, 10\n",
      "8976, 6\n",
      "8977, 12\n",
      "8978, 16\n",
      "8979, 10\n",
      "8980, 7\n",
      "8981, 10\n",
      "8982, 12\n",
      "8983, 4\n",
      "8984, 11\n",
      "8985, 13\n",
      "8986, 11\n",
      "8987, 13\n",
      "8988, 11\n",
      "8989, 12\n",
      "8990, 7\n",
      "8991, 6\n",
      "8992, 3\n",
      "8993, 15\n",
      "8994, 4\n",
      "8995, 10\n",
      "8996, 15\n",
      "8997, 10\n",
      "8998, 4\n",
      "8999, 0\n",
      "9000, 17\n",
      "9001, 6\n",
      "9002, 9\n",
      "9003, 16\n",
      "9004, 12\n",
      "9005, 11\n",
      "9006, 7\n",
      "9007, 8\n",
      "9008, 13\n",
      "9009, 6\n",
      "9010, 8\n",
      "9011, 16\n",
      "9012, 10\n",
      "9013, 8\n",
      "9014, 14\n",
      "9015, 7\n",
      "9016, 13\n",
      "9017, 13\n",
      "9018, 4\n",
      "9019, 5\n",
      "9020, 10\n",
      "9021, 14\n",
      "9022, 6\n",
      "9023, 15\n",
      "9024, 16\n",
      "9025, 8\n",
      "9026, 12\n",
      "9027, 7\n",
      "9028, 9\n",
      "9029, 9\n",
      "9030, 15\n",
      "9031, 12\n",
      "9032, 7\n",
      "9033, 5\n",
      "9034, 9\n",
      "9035, 14\n",
      "9036, 7\n",
      "9037, 9\n",
      "9038, 7\n",
      "9039, 5\n",
      "9040, 11\n",
      "9041, 17\n",
      "9042, 5\n",
      "9043, 11\n",
      "9044, 0\n",
      "9045, 9\n",
      "9046, 13\n",
      "9047, 12\n",
      "9048, 9\n",
      "9049, 15\n",
      "9050, 8\n",
      "9051, 7\n",
      "9052, 7\n",
      "9053, 14\n",
      "9054, 8\n",
      "9055, 11\n",
      "9056, 7\n",
      "9057, 4\n",
      "9058, 6\n",
      "9059, 8\n",
      "9060, 9\n",
      "9061, 8\n",
      "9062, 3\n",
      "9063, 13\n",
      "9064, 11\n",
      "9065, 12\n",
      "9066, 6\n",
      "9067, 9\n",
      "9068, 3\n",
      "9069, 10\n",
      "9070, 7\n",
      "9071, 4\n",
      "9072, 7\n",
      "9073, 0\n",
      "9074, 18\n",
      "9075, 10\n",
      "9076, 8\n",
      "9077, 1\n",
      "9078, 11\n",
      "9079, 15\n",
      "9080, 0\n",
      "9081, 14\n",
      "9082, 9\n",
      "9083, 5\n",
      "9084, 10\n",
      "9085, 7\n",
      "9086, 16\n",
      "9087, 4\n",
      "9088, 8\n",
      "9089, 0\n",
      "9090, 6\n",
      "9091, 10\n",
      "9092, 7\n",
      "9093, 15\n",
      "9094, 12\n",
      "9095, 5\n",
      "9096, 10\n",
      "9097, 10\n",
      "9098, 15\n",
      "9099, 10\n",
      "9100, 10\n",
      "9101, 9\n",
      "9102, 10\n",
      "9103, 10\n",
      "9104, 9\n",
      "9105, 11\n",
      "9106, 12\n",
      "9107, 12\n",
      "9108, 13\n",
      "9109, 6\n",
      "9110, 16\n",
      "9111, 11\n",
      "9112, 10\n",
      "9113, 8\n",
      "9114, 8\n",
      "9115, 12\n",
      "9116, 7\n",
      "9117, 14\n",
      "9118, 11\n",
      "9119, 3\n",
      "9120, 12\n",
      "9121, 9\n",
      "9122, 10\n",
      "9123, 18\n",
      "9124, 11\n",
      "9125, 16\n",
      "9126, 8\n",
      "9127, 14\n",
      "9128, 9\n",
      "9129, 7\n",
      "9130, 16\n",
      "9131, 8\n",
      "9132, 12\n",
      "9133, 8\n",
      "9134, 9\n",
      "9135, 6\n",
      "9136, 6\n",
      "9137, 16\n",
      "9138, 9\n",
      "9139, 11\n",
      "9140, 9\n",
      "9141, 5\n",
      "9142, 18\n",
      "9143, 10\n",
      "9144, 10\n",
      "9145, 12\n",
      "9146, 5\n",
      "9147, 7\n",
      "9148, 14\n",
      "9149, 10\n",
      "9150, 10\n",
      "9151, 15\n",
      "9152, 8\n",
      "9153, 9\n",
      "9154, 5\n",
      "9155, 6\n",
      "9156, 12\n",
      "9157, 4\n",
      "9158, 5\n",
      "9159, 7\n",
      "9160, 2\n",
      "9161, 8\n",
      "9162, 7\n",
      "9163, 3\n",
      "9164, 3\n",
      "9165, 13\n",
      "9166, 8\n",
      "9167, 6\n",
      "9168, 7\n",
      "9169, 14\n",
      "9170, 9\n",
      "9171, 5\n",
      "9172, 12\n",
      "9173, 8\n",
      "9174, 8\n",
      "9175, 17\n",
      "9176, 7\n",
      "9177, 5\n",
      "9178, 9\n",
      "9179, 10\n",
      "9180, 7\n",
      "9181, 10\n",
      "9182, 11\n",
      "9183, 17\n",
      "9184, 13\n",
      "9185, 8\n",
      "9186, 12\n",
      "9187, 10\n",
      "9188, 5\n",
      "9189, 2\n",
      "9190, 5\n",
      "9191, 4\n",
      "9192, 16\n",
      "9193, 16\n",
      "9194, 4\n",
      "9195, 3\n",
      "9196, 14\n",
      "9197, 15\n",
      "9198, 17\n",
      "9199, 9\n",
      "9200, 14\n",
      "9201, 10\n",
      "9202, 11\n",
      "9203, 5\n",
      "9204, 9\n",
      "9205, 8\n",
      "9206, 16\n",
      "9207, 2\n",
      "9208, 11\n",
      "9209, 15\n",
      "9210, 7\n",
      "9211, 18\n",
      "9212, 2\n",
      "9213, 8\n",
      "9214, 9\n",
      "9215, 0\n",
      "9216, 11\n",
      "9217, 8\n",
      "9218, 0\n",
      "9219, 9\n",
      "9220, 17\n",
      "9221, 1\n",
      "9222, 2\n",
      "9223, 8\n",
      "9224, 13\n",
      "9225, 14\n",
      "9226, 6\n",
      "9227, 4\n",
      "9228, 8\n",
      "9229, 17\n",
      "9230, 10\n",
      "9231, 1\n",
      "9232, 12\n",
      "9233, 14\n",
      "9234, 14\n",
      "9235, 10\n",
      "9236, 13\n",
      "9237, 9\n",
      "9238, 14\n",
      "9239, 16\n",
      "9240, 8\n",
      "9241, 5\n",
      "9242, 5\n",
      "9243, 5\n",
      "9244, 1\n",
      "9245, 8\n",
      "9246, 9\n",
      "9247, 12\n",
      "9248, 9\n",
      "9249, 11\n",
      "9250, 10\n",
      "9251, 8\n",
      "9252, 14\n",
      "9253, 8\n",
      "9254, 7\n",
      "9255, 11\n",
      "9256, 9\n",
      "9257, 13\n",
      "9258, 4\n",
      "9259, 10\n",
      "9260, 9\n",
      "9261, 7\n",
      "9262, 11\n",
      "9263, 7\n",
      "9264, 6\n",
      "9265, 10\n",
      "9266, 11\n",
      "9267, 18\n",
      "9268, 8\n",
      "9269, 12\n",
      "9270, 8\n",
      "9271, 10\n",
      "9272, 1\n",
      "9273, 12\n",
      "9274, 6\n",
      "9275, 7\n",
      "9276, 10\n",
      "9277, 11\n",
      "9278, 14\n",
      "9279, 2\n",
      "9280, 10\n",
      "9281, 12\n",
      "9282, 6\n",
      "9283, 9\n",
      "9284, 11\n",
      "9285, 17\n",
      "9286, 4\n",
      "9287, 2\n",
      "9288, 7\n",
      "9289, 5\n",
      "9290, 13\n",
      "9291, 5\n",
      "9292, 12\n",
      "9293, 9\n",
      "9294, 12\n",
      "9295, 11\n",
      "9296, 3\n",
      "9297, 10\n",
      "9298, 9\n",
      "9299, 11\n",
      "9300, 10\n",
      "9301, 5\n",
      "9302, 13\n",
      "9303, 4\n",
      "9304, 13\n",
      "9305, 9\n",
      "9306, 7\n",
      "9307, 13\n",
      "9308, 4\n",
      "9309, 14\n",
      "9310, 12\n",
      "9311, 4\n",
      "9312, 18\n",
      "9313, 4\n",
      "9314, 16\n",
      "9315, 6\n",
      "9316, 7\n",
      "9317, 16\n",
      "9318, 11\n",
      "9319, 12\n",
      "9320, 11\n",
      "9321, 8\n",
      "9322, 4\n",
      "9323, 13\n",
      "9324, 15\n",
      "9325, 9\n",
      "9326, 3\n",
      "9327, 6\n",
      "9328, 3\n",
      "9329, 12\n",
      "9330, 11\n",
      "9331, 9\n",
      "9332, 6\n",
      "9333, 10\n",
      "9334, 7\n",
      "9335, 14\n",
      "9336, 4\n",
      "9337, 5\n",
      "9338, 12\n",
      "9339, 9\n",
      "9340, 8\n",
      "9341, 4\n",
      "9342, 9\n",
      "9343, 12\n",
      "9344, 15\n",
      "9345, 2\n",
      "9346, 6\n",
      "9347, 5\n",
      "9348, 10\n",
      "9349, 14\n",
      "9350, 15\n",
      "9351, 9\n",
      "9352, 13\n",
      "9353, 13\n",
      "9354, 9\n",
      "9355, 13\n",
      "9356, 5\n",
      "9357, 15\n",
      "9358, 12\n",
      "9359, 13\n",
      "9360, 2\n",
      "9361, 9\n",
      "9362, 14\n",
      "9363, 6\n",
      "9364, 12\n",
      "9365, 12\n",
      "9366, 8\n",
      "9367, 9\n",
      "9368, 9\n",
      "9369, 9\n",
      "9370, 13\n",
      "9371, 7\n",
      "9372, 13\n",
      "9373, 9\n",
      "9374, 11\n",
      "9375, 6\n",
      "9376, 14\n",
      "9377, 9\n",
      "9378, 9\n",
      "9379, 11\n",
      "9380, 15\n",
      "9381, 9\n",
      "9382, 7\n",
      "9383, 7\n",
      "9384, 16\n",
      "9385, 8\n",
      "9386, 8\n",
      "9387, 8\n",
      "9388, 7\n",
      "9389, 6\n",
      "9390, 6\n",
      "9391, 9\n",
      "9392, 5\n",
      "9393, 4\n",
      "9394, 9\n",
      "9395, 10\n",
      "9396, 10\n",
      "9397, 1\n",
      "9398, 0\n",
      "9399, 9\n",
      "9400, 13\n",
      "9401, 14\n",
      "9402, 7\n",
      "9403, 8\n",
      "9404, 15\n",
      "9405, 15\n",
      "9406, 8\n",
      "9407, 13\n",
      "9408, 10\n",
      "9409, 5\n",
      "9410, 8\n",
      "9411, 3\n",
      "9412, 17\n",
      "9413, 15\n",
      "9414, 14\n",
      "9415, 15\n",
      "9416, 8\n",
      "9417, 14\n",
      "9418, 10\n",
      "9419, 16\n",
      "9420, 9\n",
      "9421, 12\n",
      "9422, 9\n",
      "9423, 8\n",
      "9424, 7\n",
      "9425, 1\n",
      "9426, 10\n",
      "9427, 10\n",
      "9428, 3\n",
      "9429, 6\n",
      "9430, 13\n",
      "9431, 12\n",
      "9432, 12\n",
      "9433, 6\n",
      "9434, 13\n",
      "9435, 13\n",
      "9436, 1\n",
      "9437, 7\n",
      "9438, 6\n",
      "9439, 11\n",
      "9440, 1\n",
      "9441, 8\n",
      "9442, 9\n",
      "9443, 13\n",
      "9444, 8\n",
      "9445, 7\n",
      "9446, 3\n",
      "9447, 10\n",
      "9448, 9\n",
      "9449, 14\n",
      "9450, 3\n",
      "9451, 11\n",
      "9452, 15\n",
      "9453, 5\n",
      "9454, 15\n",
      "9455, 1\n",
      "9456, 12\n",
      "9457, 12\n",
      "9458, 12\n",
      "9459, 0\n",
      "9460, 13\n",
      "9461, 15\n",
      "9462, 4\n",
      "9463, 7\n",
      "9464, 1\n",
      "9465, 1\n",
      "9466, 0\n",
      "9467, 16\n",
      "9468, 8\n",
      "9469, 9\n",
      "9470, 10\n",
      "9471, 7\n",
      "9472, 10\n",
      "9473, 9\n",
      "9474, 6\n",
      "9475, 4\n",
      "9476, 5\n",
      "9477, 12\n",
      "9478, 4\n",
      "9479, 16\n",
      "9480, 0\n",
      "9481, 7\n",
      "9482, 14\n",
      "9483, 5\n",
      "9484, 12\n",
      "9485, 7\n",
      "9486, 8\n",
      "9487, 10\n",
      "9488, 8\n",
      "9489, 10\n",
      "9490, 5\n",
      "9491, 7\n",
      "9492, 12\n",
      "9493, 12\n",
      "9494, 9\n",
      "9495, 16\n",
      "9496, 5\n",
      "9497, 9\n",
      "9498, 1\n",
      "9499, 2\n",
      "9500, 2\n",
      "9501, 6\n",
      "9502, 9\n",
      "9503, 5\n",
      "9504, 10\n",
      "9505, 8\n",
      "9506, 6\n",
      "9507, 3\n",
      "9508, 3\n",
      "9509, 9\n",
      "9510, 7\n",
      "9511, 9\n",
      "9512, 9\n",
      "9513, 6\n",
      "9514, 4\n",
      "9515, 9\n",
      "9516, 14\n",
      "9517, 7\n",
      "9518, 9\n",
      "9519, 10\n",
      "9520, 5\n",
      "9521, 10\n",
      "9522, 11\n",
      "9523, 10\n",
      "9524, 9\n",
      "9525, 7\n",
      "9526, 8\n",
      "9527, 14\n",
      "9528, 10\n",
      "9529, 7\n",
      "9530, 11\n",
      "9531, 15\n",
      "9532, 1\n",
      "9533, 1\n",
      "9534, 15\n",
      "9535, 3\n",
      "9536, 9\n",
      "9537, 12\n",
      "9538, 8\n",
      "9539, 5\n",
      "9540, 16\n",
      "9541, 14\n",
      "9542, 6\n",
      "9543, 15\n",
      "9544, 7\n",
      "9545, 5\n",
      "9546, 8\n",
      "9547, 8\n",
      "9548, 14\n",
      "9549, 6\n",
      "9550, 16\n",
      "9551, 18\n",
      "9552, 2\n",
      "9553, 7\n",
      "9554, 16\n",
      "9555, 12\n",
      "9556, 8\n",
      "9557, 11\n",
      "9558, 11\n",
      "9559, 12\n",
      "9560, 12\n",
      "9561, 4\n",
      "9562, 9\n",
      "9563, 5\n",
      "9564, 10\n",
      "9565, 7\n",
      "9566, 14\n",
      "9567, 1\n",
      "9568, 12\n",
      "9569, 5\n",
      "9570, 5\n",
      "9571, 9\n",
      "9572, 8\n",
      "9573, 14\n",
      "9574, 12\n",
      "9575, 14\n",
      "9576, 6\n",
      "9577, 13\n",
      "9578, 1\n",
      "9579, 3\n",
      "9580, 12\n",
      "9581, 3\n",
      "9582, 6\n",
      "9583, 7\n",
      "9584, 3\n",
      "9585, 14\n",
      "9586, 10\n",
      "9587, 11\n",
      "9588, 1\n",
      "9589, 10\n",
      "9590, 8\n",
      "9591, 7\n",
      "9592, 16\n",
      "9593, 8\n",
      "9594, 13\n",
      "9595, 11\n",
      "9596, 7\n",
      "9597, 13\n",
      "9598, 13\n",
      "9599, 17\n",
      "9600, 10\n",
      "9601, 14\n",
      "9602, 10\n",
      "9603, 13\n",
      "9604, 13\n",
      "9605, 10\n",
      "9606, 6\n",
      "9607, 8\n",
      "9608, 9\n",
      "9609, 15\n",
      "9610, 7\n",
      "9611, 5\n",
      "9612, 9\n",
      "9613, 11\n",
      "9614, 0\n",
      "9615, 9\n",
      "9616, 7\n",
      "9617, 13\n",
      "9618, 8\n",
      "9619, 7\n",
      "9620, 9\n",
      "9621, 8\n",
      "9622, 18\n",
      "9623, 8\n",
      "9624, 9\n",
      "9625, 2\n",
      "9626, 9\n",
      "9627, 5\n",
      "9628, 8\n",
      "9629, 6\n",
      "9630, 10\n",
      "9631, 18\n",
      "9632, 8\n",
      "9633, 9\n",
      "9634, 7\n",
      "9635, 10\n",
      "9636, 9\n",
      "9637, 8\n",
      "9638, 6\n",
      "9639, 10\n",
      "9640, 8\n",
      "9641, 8\n",
      "9642, 8\n",
      "9643, 13\n",
      "9644, 15\n",
      "9645, 11\n",
      "9646, 16\n",
      "9647, 12\n",
      "9648, 3\n",
      "9649, 11\n",
      "9650, 17\n",
      "9651, 10\n",
      "9652, 7\n",
      "9653, 15\n",
      "9654, 6\n",
      "9655, 3\n",
      "9656, 5\n",
      "9657, 10\n",
      "9658, 11\n",
      "9659, 4\n",
      "9660, 16\n",
      "9661, 2\n",
      "9662, 4\n",
      "9663, 14\n",
      "9664, 6\n",
      "9665, 5\n",
      "9666, 18\n",
      "9667, 9\n",
      "9668, 10\n",
      "9669, 8\n",
      "9670, 15\n",
      "9671, 8\n",
      "9672, 8\n",
      "9673, 15\n",
      "9674, 8\n",
      "9675, 12\n",
      "9676, 7\n",
      "9677, 9\n",
      "9678, 9\n",
      "9679, 7\n",
      "9680, 11\n",
      "9681, 17\n",
      "9682, 6\n",
      "9683, 7\n",
      "9684, 11\n",
      "9685, 10\n",
      "9686, 12\n",
      "9687, 11\n",
      "9688, 3\n",
      "9689, 11\n",
      "9690, 10\n",
      "9691, 9\n",
      "9692, 5\n",
      "9693, 15\n",
      "9694, 16\n",
      "9695, 2\n",
      "9696, 17\n",
      "9697, 15\n",
      "9698, 6\n",
      "9699, 6\n",
      "9700, 6\n",
      "9701, 12\n",
      "9702, 10\n",
      "9703, 7\n",
      "9704, 15\n",
      "9705, 11\n",
      "9706, 16\n",
      "9707, 17\n",
      "9708, 16\n",
      "9709, 5\n",
      "9710, 1\n",
      "9711, 12\n",
      "9712, 9\n",
      "9713, 9\n",
      "9714, 10\n",
      "9715, 3\n",
      "9716, 11\n",
      "9717, 12\n",
      "9718, 14\n",
      "9719, 3\n",
      "9720, 4\n",
      "9721, 4\n",
      "9722, 7\n",
      "9723, 12\n",
      "9724, 8\n",
      "9725, 7\n",
      "9726, 7\n",
      "9727, 9\n",
      "9728, 3\n",
      "9729, 11\n",
      "9730, 4\n",
      "9731, 8\n",
      "9732, 17\n",
      "9733, 14\n",
      "9734, 11\n",
      "9735, 8\n",
      "9736, 14\n",
      "9737, 11\n",
      "9738, 0\n",
      "9739, 6\n",
      "9740, 9\n",
      "9741, 11\n",
      "9742, 2\n",
      "9743, 6\n",
      "9744, 12\n",
      "9745, 9\n",
      "9746, 10\n",
      "9747, 9\n",
      "9748, 9\n",
      "9749, 6\n",
      "9750, 9\n",
      "9751, 8\n",
      "9752, 7\n",
      "9753, 8\n",
      "9754, 12\n",
      "9755, 9\n",
      "9756, 12\n",
      "9757, 9\n",
      "9758, 10\n",
      "9759, 8\n",
      "9760, 10\n",
      "9761, 7\n",
      "9762, 18\n",
      "9763, 13\n",
      "9764, 10\n",
      "9765, 14\n",
      "9766, 7\n",
      "9767, 7\n",
      "9768, 15\n",
      "9769, 10\n",
      "9770, 8\n",
      "9771, 7\n",
      "9772, 0\n",
      "9773, 3\n",
      "9774, 9\n",
      "9775, 12\n",
      "9776, 9\n",
      "9777, 6\n",
      "9778, 9\n",
      "9779, 4\n",
      "9780, 3\n",
      "9781, 6\n",
      "9782, 10\n",
      "9783, 0\n",
      "9784, 7\n",
      "9785, 11\n",
      "9786, 8\n",
      "9787, 16\n",
      "9788, 13\n",
      "9789, 1\n",
      "9790, 6\n",
      "9791, 12\n",
      "9792, 6\n",
      "9793, 6\n",
      "9794, 8\n",
      "9795, 12\n",
      "9796, 1\n",
      "9797, 3\n",
      "9798, 12\n",
      "9799, 10\n",
      "9800, 7\n",
      "9801, 8\n",
      "9802, 7\n",
      "9803, 16\n",
      "9804, 9\n",
      "9805, 9\n",
      "9806, 4\n",
      "9807, 13\n",
      "9808, 13\n",
      "9809, 6\n",
      "9810, 4\n",
      "9811, 11\n",
      "9812, 15\n",
      "9813, 17\n",
      "9814, 10\n",
      "9815, 9\n",
      "9816, 18\n",
      "9817, 8\n",
      "9818, 5\n",
      "9819, 8\n",
      "9820, 13\n",
      "9821, 16\n",
      "9822, 9\n",
      "9823, 10\n",
      "9824, 2\n",
      "9825, 6\n",
      "9826, 3\n",
      "9827, 12\n",
      "9828, 16\n",
      "9829, 1\n",
      "9830, 2\n",
      "9831, 4\n",
      "9832, 10\n",
      "9833, 5\n",
      "9834, 8\n",
      "9835, 7\n",
      "9836, 8\n",
      "9837, 9\n",
      "9838, 9\n",
      "9839, 9\n",
      "9840, 14\n",
      "9841, 8\n",
      "9842, 9\n",
      "9843, 11\n",
      "9844, 9\n",
      "9845, 14\n",
      "9846, 15\n",
      "9847, 17\n",
      "9848, 6\n",
      "9849, 6\n",
      "9850, 8\n",
      "9851, 9\n",
      "9852, 15\n",
      "9853, 8\n",
      "9854, 14\n",
      "9855, 17\n",
      "9856, 16\n",
      "9857, 13\n",
      "9858, 14\n",
      "9859, 5\n",
      "9860, 1\n",
      "9861, 0\n",
      "9862, 4\n",
      "9863, 15\n",
      "9864, 7\n",
      "9865, 9\n",
      "9866, 16\n",
      "9867, 11\n",
      "9868, 8\n",
      "9869, 6\n",
      "9870, 13\n",
      "9871, 3\n",
      "9872, 3\n",
      "9873, 6\n",
      "9874, 12\n",
      "9875, 13\n",
      "9876, 12\n",
      "9877, 12\n",
      "9878, 14\n",
      "9879, 6\n",
      "9880, 13\n",
      "9881, 9\n",
      "9882, 1\n",
      "9883, 8\n",
      "9884, 9\n",
      "9885, 11\n",
      "9886, 7\n",
      "9887, 8\n",
      "9888, 4\n",
      "9889, 6\n",
      "9890, 10\n",
      "9891, 11\n",
      "9892, 5\n",
      "9893, 5\n",
      "9894, 3\n",
      "9895, 5\n",
      "9896, 12\n",
      "9897, 4\n",
      "9898, 10\n",
      "9899, 4\n",
      "9900, 5\n",
      "9901, 13\n",
      "9902, 6\n",
      "9903, 10\n",
      "9904, 14\n",
      "9905, 14\n",
      "9906, 10\n",
      "9907, 10\n",
      "9908, 10\n",
      "9909, 10\n",
      "9910, 15\n",
      "9911, 12\n",
      "9912, 11\n",
      "9913, 8\n",
      "9914, 10\n",
      "9915, 4\n",
      "9916, 12\n",
      "9917, 8\n",
      "9918, 15\n",
      "9919, 2\n",
      "9920, 3\n",
      "9921, 13\n",
      "9922, 5\n",
      "9923, 5\n",
      "9924, 6\n",
      "9925, 8\n",
      "9926, 9\n",
      "9927, 13\n",
      "9928, 11\n",
      "9929, 13\n",
      "9930, 10\n",
      "9931, 5\n",
      "9932, 7\n",
      "9933, 12\n",
      "9934, 1\n",
      "9935, 7\n",
      "9936, 14\n",
      "9937, 3\n",
      "9938, 14\n",
      "9939, 5\n",
      "9940, 5\n",
      "9941, 7\n",
      "9942, 8\n",
      "9943, 8\n",
      "9944, 12\n",
      "9945, 10\n",
      "9946, 12\n",
      "9947, 11\n",
      "9948, 5\n",
      "9949, 11\n",
      "9950, 12\n",
      "9951, 8\n",
      "9952, 6\n",
      "9953, 9\n",
      "9954, 7\n",
      "9955, 17\n",
      "9956, 12\n",
      "9957, 4\n",
      "9958, 16\n",
      "9959, 3\n",
      "9960, 8\n",
      "9961, 15\n",
      "9962, 9\n",
      "9963, 9\n",
      "9964, 8\n",
      "9965, 17\n",
      "9966, 10\n",
      "9967, 4\n",
      "9968, 8\n",
      "9969, 7\n",
      "9970, 7\n",
      "9971, 12\n",
      "9972, 16\n",
      "9973, 9\n",
      "9974, 8\n",
      "9975, 5\n",
      "9976, 12\n",
      "9977, 6\n",
      "9978, 13\n",
      "9979, 5\n",
      "9980, 11\n",
      "9981, 4\n",
      "9982, 2\n",
      "9983, 16\n",
      "9984, 8\n",
      "9985, 7\n",
      "9986, 11\n",
      "9987, 14\n",
      "9988, 9\n",
      "9989, 0\n",
      "9990, 7\n",
      "9991, 5\n",
      "9992, 6\n",
      "9993, 2\n",
      "9994, 16\n",
      "9995, 9\n",
      "9996, 14\n",
      "9997, 1\n",
      "9998, 7\n",
      "9999, 9\n"
     ]
    }
   ],
   "source": [
    "y_final =np.argmax(y_pred, axis=1)\n",
    "for_submission(y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5546ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   0\n",
       "0         0  12\n",
       "1         1   2\n",
       "2         2  17\n",
       "3         3  13\n",
       "4         4   7\n",
       "...     ...  ..\n",
       "9995   9995   9\n",
       "9996   9996  14\n",
       "9997   9997   1\n",
       "9998   9998   7\n",
       "9999   9999   9\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y = pd.DataFrame(y_final).reset_index()\n",
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d86b4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.columns = ['Index', 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d69480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.to_csv('pd-submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28e35450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 1559</th>\n",
       "      <th>Feature 1560</th>\n",
       "      <th>Feature 1561</th>\n",
       "      <th>Feature 1562</th>\n",
       "      <th>Feature 1563</th>\n",
       "      <th>Feature 1564</th>\n",
       "      <th>Feature 1565</th>\n",
       "      <th>Feature 1566</th>\n",
       "      <th>Feature 1567</th>\n",
       "      <th>Feature 1568</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.955389e-23</td>\n",
       "      <td>-4.232597e-23</td>\n",
       "      <td>-1.371348e-23</td>\n",
       "      <td>-4.941302e-24</td>\n",
       "      <td>4.701897e-24</td>\n",
       "      <td>9.137646e-24</td>\n",
       "      <td>-5.964309e-25</td>\n",
       "      <td>-8.037856e-27</td>\n",
       "      <td>1.607571e-26</td>\n",
       "      <td>1.896144e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.713258e-20</td>\n",
       "      <td>-3.072854e-20</td>\n",
       "      <td>1.208471e-20</td>\n",
       "      <td>8.119634e-22</td>\n",
       "      <td>-4.124326e-21</td>\n",
       "      <td>-2.351743e-22</td>\n",
       "      <td>-1.139683e-23</td>\n",
       "      <td>-1.730485e-24</td>\n",
       "      <td>-1.088523e-24</td>\n",
       "      <td>-1.192788e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.737605e-19</td>\n",
       "      <td>1.010960e-17</td>\n",
       "      <td>1.299321e-20</td>\n",
       "      <td>1.007092e-20</td>\n",
       "      <td>-1.007821e-20</td>\n",
       "      <td>2.289849e-21</td>\n",
       "      <td>-8.811264e-22</td>\n",
       "      <td>2.288049e-22</td>\n",
       "      <td>-6.056319e-23</td>\n",
       "      <td>-1.302198e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.688333e-22</td>\n",
       "      <td>1.262406e-22</td>\n",
       "      <td>-1.204514e-23</td>\n",
       "      <td>-9.310054e-24</td>\n",
       "      <td>-1.898251e-24</td>\n",
       "      <td>-1.192600e-25</td>\n",
       "      <td>-2.870280e-26</td>\n",
       "      <td>-2.612264e-27</td>\n",
       "      <td>-7.700169e-27</td>\n",
       "      <td>-3.745563e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.748979e-21</td>\n",
       "      <td>-1.613074e-21</td>\n",
       "      <td>-3.539335e-21</td>\n",
       "      <td>-6.962758e-20</td>\n",
       "      <td>1.694034e-19</td>\n",
       "      <td>-3.988890e-20</td>\n",
       "      <td>-5.779639e-22</td>\n",
       "      <td>5.424119e-21</td>\n",
       "      <td>1.102504e-22</td>\n",
       "      <td>-2.005880e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.176424e-21</td>\n",
       "      <td>2.125517e-22</td>\n",
       "      <td>-5.571208e-23</td>\n",
       "      <td>1.215935e-22</td>\n",
       "      <td>1.939962e-22</td>\n",
       "      <td>-1.638395e-22</td>\n",
       "      <td>-3.236651e-24</td>\n",
       "      <td>4.809522e-25</td>\n",
       "      <td>-1.347239e-25</td>\n",
       "      <td>5.794320e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.372621e-20</td>\n",
       "      <td>6.099703e-21</td>\n",
       "      <td>-8.780294e-22</td>\n",
       "      <td>-6.306931e-22</td>\n",
       "      <td>-1.059037e-21</td>\n",
       "      <td>6.598977e-23</td>\n",
       "      <td>5.641922e-23</td>\n",
       "      <td>1.521738e-23</td>\n",
       "      <td>5.845244e-25</td>\n",
       "      <td>2.289112e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.796364e-20</td>\n",
       "      <td>-1.969505e-20</td>\n",
       "      <td>-1.698103e-22</td>\n",
       "      <td>2.043203e-22</td>\n",
       "      <td>5.397814e-23</td>\n",
       "      <td>-3.642104e-23</td>\n",
       "      <td>-5.222338e-23</td>\n",
       "      <td>-8.629898e-24</td>\n",
       "      <td>1.129773e-24</td>\n",
       "      <td>-2.509890e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536667e-20</td>\n",
       "      <td>-5.036675e-21</td>\n",
       "      <td>2.582385e-22</td>\n",
       "      <td>1.224506e-22</td>\n",
       "      <td>3.189655e-23</td>\n",
       "      <td>-7.812957e-24</td>\n",
       "      <td>-2.556415e-24</td>\n",
       "      <td>2.959303e-25</td>\n",
       "      <td>1.060729e-25</td>\n",
       "      <td>1.069585e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.705075e-20</td>\n",
       "      <td>5.533117e-21</td>\n",
       "      <td>-7.200016e-22</td>\n",
       "      <td>1.472278e-22</td>\n",
       "      <td>-1.492252e-23</td>\n",
       "      <td>-9.910375e-24</td>\n",
       "      <td>-9.901138e-24</td>\n",
       "      <td>-2.287262e-24</td>\n",
       "      <td>-9.313975e-25</td>\n",
       "      <td>-4.494966e-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1568 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  Feature 6  \\\n",
       "0           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "9995        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9996        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9997        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9998        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9999        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "      Feature 7  Feature 8  Feature 9  Feature 10  ...  Feature 1559  \\\n",
       "0           0.0        0.0        0.0         0.0  ...  1.955389e-23   \n",
       "1           0.0        0.0        0.0         0.0  ... -1.713258e-20   \n",
       "2           0.0        0.0        0.0         0.0  ... -7.737605e-19   \n",
       "3           0.0        0.0        0.0         0.0  ...  1.688333e-22   \n",
       "4           0.0        0.0        0.0         0.0  ... -5.748979e-21   \n",
       "...         ...        ...        ...         ...  ...           ...   \n",
       "9995        0.0        0.0        0.0         0.0  ...  2.176424e-21   \n",
       "9996        0.0        0.0        0.0         0.0  ...  8.372621e-20   \n",
       "9997        0.0        0.0        0.0         0.0  ...  1.796364e-20   \n",
       "9998        0.0        0.0        0.0         0.0  ...  1.536667e-20   \n",
       "9999        0.0        0.0        0.0         0.0  ... -3.705075e-20   \n",
       "\n",
       "      Feature 1560  Feature 1561  Feature 1562  Feature 1563  Feature 1564  \\\n",
       "0    -4.232597e-23 -1.371348e-23 -4.941302e-24  4.701897e-24  9.137646e-24   \n",
       "1    -3.072854e-20  1.208471e-20  8.119634e-22 -4.124326e-21 -2.351743e-22   \n",
       "2     1.010960e-17  1.299321e-20  1.007092e-20 -1.007821e-20  2.289849e-21   \n",
       "3     1.262406e-22 -1.204514e-23 -9.310054e-24 -1.898251e-24 -1.192600e-25   \n",
       "4    -1.613074e-21 -3.539335e-21 -6.962758e-20  1.694034e-19 -3.988890e-20   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "9995  2.125517e-22 -5.571208e-23  1.215935e-22  1.939962e-22 -1.638395e-22   \n",
       "9996  6.099703e-21 -8.780294e-22 -6.306931e-22 -1.059037e-21  6.598977e-23   \n",
       "9997 -1.969505e-20 -1.698103e-22  2.043203e-22  5.397814e-23 -3.642104e-23   \n",
       "9998 -5.036675e-21  2.582385e-22  1.224506e-22  3.189655e-23 -7.812957e-24   \n",
       "9999  5.533117e-21 -7.200016e-22  1.472278e-22 -1.492252e-23 -9.910375e-24   \n",
       "\n",
       "      Feature 1565  Feature 1566  Feature 1567  Feature 1568  \n",
       "0    -5.964309e-25 -8.037856e-27  1.607571e-26  1.896144e-27  \n",
       "1    -1.139683e-23 -1.730485e-24 -1.088523e-24 -1.192788e-25  \n",
       "2    -8.811264e-22  2.288049e-22 -6.056319e-23 -1.302198e-23  \n",
       "3    -2.870280e-26 -2.612264e-27 -7.700169e-27 -3.745563e-27  \n",
       "4    -5.779639e-22  5.424119e-21  1.102504e-22 -2.005880e-22  \n",
       "...            ...           ...           ...           ...  \n",
       "9995 -3.236651e-24  4.809522e-25 -1.347239e-25  5.794320e-26  \n",
       "9996  5.641922e-23  1.521738e-23  5.845244e-25  2.289112e-25  \n",
       "9997 -5.222338e-23 -8.629898e-24  1.129773e-24 -2.509890e-26  \n",
       "9998 -2.556415e-24  2.959303e-25  1.060729e-25  1.069585e-25  \n",
       "9999 -9.901138e-24 -2.287262e-24 -9.313975e-25 -4.494966e-25  \n",
       "\n",
       "[10000 rows x 1568 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_test = df_test.iloc[:,:-1]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35a0193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.values.reshape(-1,28,56,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28896fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95d69cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d7521d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14,  7, 10, ..., 10,  4,  6])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61d5c7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   0\n",
       "0         0  14\n",
       "1         1   7\n",
       "2         2  10\n",
       "3         3   7\n",
       "4         4   5\n",
       "...     ...  ..\n",
       "9995   9995   7\n",
       "9996   9996  12\n",
       "9997   9997  10\n",
       "9998   9998   4\n",
       "9999   9999   6\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y = pd.DataFrame(y_pred).reset_index()\n",
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "232065c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.columns = ['Index', 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b58d72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.to_csv('pd-submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b027c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212c40b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c256e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b79e012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ede4ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 1560</th>\n",
       "      <th>Feature 1561</th>\n",
       "      <th>Feature 1562</th>\n",
       "      <th>Feature 1563</th>\n",
       "      <th>Feature 1564</th>\n",
       "      <th>Feature 1565</th>\n",
       "      <th>Feature 1566</th>\n",
       "      <th>Feature 1567</th>\n",
       "      <th>Feature 1568</th>\n",
       "      <th>Unnamed: 1568</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.854928e-19</td>\n",
       "      <td>-1.329011e-20</td>\n",
       "      <td>4.204335e-21</td>\n",
       "      <td>4.428740e-21</td>\n",
       "      <td>4.461340e-23</td>\n",
       "      <td>2.376798e-24</td>\n",
       "      <td>-7.807106e-24</td>\n",
       "      <td>2.379322e-24</td>\n",
       "      <td>-5.582096e-26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.118652e-20</td>\n",
       "      <td>4.062297e-21</td>\n",
       "      <td>-7.743107e-21</td>\n",
       "      <td>8.638654e-22</td>\n",
       "      <td>-1.006311e-21</td>\n",
       "      <td>-2.267525e-22</td>\n",
       "      <td>-5.867730e-23</td>\n",
       "      <td>4.858047e-24</td>\n",
       "      <td>-4.595498e-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.619224e-20</td>\n",
       "      <td>-3.590984e-20</td>\n",
       "      <td>-2.717642e-20</td>\n",
       "      <td>1.923565e-20</td>\n",
       "      <td>-2.244442e-21</td>\n",
       "      <td>-4.244237e-24</td>\n",
       "      <td>-3.599564e-23</td>\n",
       "      <td>7.471194e-24</td>\n",
       "      <td>-3.815300e-24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.346105e-19</td>\n",
       "      <td>-6.278001e-19</td>\n",
       "      <td>-5.786255e-19</td>\n",
       "      <td>2.573141e-19</td>\n",
       "      <td>2.385063e-19</td>\n",
       "      <td>6.655487e-20</td>\n",
       "      <td>2.834975e-20</td>\n",
       "      <td>3.356577e-21</td>\n",
       "      <td>1.698628e-21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.494150e-20</td>\n",
       "      <td>-1.187973e-20</td>\n",
       "      <td>-1.450941e-21</td>\n",
       "      <td>8.954877e-22</td>\n",
       "      <td>-2.645088e-22</td>\n",
       "      <td>1.365356e-23</td>\n",
       "      <td>8.062470e-24</td>\n",
       "      <td>-1.235689e-24</td>\n",
       "      <td>1.890073e-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1569 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  Feature 6  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   Feature 7  Feature 8  Feature 9  Feature 10  ...  Feature 1560  \\\n",
       "0        0.0        0.0        0.0         0.0  ...  3.854928e-19   \n",
       "1        0.0        0.0        0.0         0.0  ... -7.118652e-20   \n",
       "2        0.0        0.0        0.0         0.0  ... -4.619224e-20   \n",
       "3        0.0        0.0        0.0         0.0  ... -5.346105e-19   \n",
       "4        0.0        0.0        0.0         0.0  ...  5.494150e-20   \n",
       "\n",
       "   Feature 1561  Feature 1562  Feature 1563  Feature 1564  Feature 1565  \\\n",
       "0 -1.329011e-20  4.204335e-21  4.428740e-21  4.461340e-23  2.376798e-24   \n",
       "1  4.062297e-21 -7.743107e-21  8.638654e-22 -1.006311e-21 -2.267525e-22   \n",
       "2 -3.590984e-20 -2.717642e-20  1.923565e-20 -2.244442e-21 -4.244237e-24   \n",
       "3 -6.278001e-19 -5.786255e-19  2.573141e-19  2.385063e-19  6.655487e-20   \n",
       "4 -1.187973e-20 -1.450941e-21  8.954877e-22 -2.645088e-22  1.365356e-23   \n",
       "\n",
       "   Feature 1566  Feature 1567  Feature 1568  Unnamed: 1568  \n",
       "0 -7.807106e-24  2.379322e-24 -5.582096e-26            NaN  \n",
       "1 -5.867730e-23  4.858047e-24 -4.595498e-25            NaN  \n",
       "2 -3.599564e-23  7.471194e-24 -3.815300e-24            NaN  \n",
       "3  2.834975e-20  3.356577e-21  1.698628e-21            NaN  \n",
       "4  8.062470e-24 -1.235689e-24  1.890073e-25            NaN  \n",
       "\n",
       "[5 rows x 1569 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdada0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Class\n",
       "Index       \n",
       "0          5\n",
       "1          4\n",
       "2          5\n",
       "3          4\n",
       "4          4\n",
       "...      ...\n",
       "49995      9\n",
       "49996     14\n",
       "49997      1\n",
       "49998      7\n",
       "49999      9\n",
       "\n",
       "[50000 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv('data/train_result.csv', index_col=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ecd4d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 1559</th>\n",
       "      <th>Feature 1560</th>\n",
       "      <th>Feature 1561</th>\n",
       "      <th>Feature 1562</th>\n",
       "      <th>Feature 1563</th>\n",
       "      <th>Feature 1564</th>\n",
       "      <th>Feature 1565</th>\n",
       "      <th>Feature 1566</th>\n",
       "      <th>Feature 1567</th>\n",
       "      <th>Feature 1568</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.281934e-19</td>\n",
       "      <td>3.854928e-19</td>\n",
       "      <td>-1.329011e-20</td>\n",
       "      <td>4.204335e-21</td>\n",
       "      <td>4.428740e-21</td>\n",
       "      <td>4.461340e-23</td>\n",
       "      <td>2.376798e-24</td>\n",
       "      <td>-7.807106e-24</td>\n",
       "      <td>2.379322e-24</td>\n",
       "      <td>-5.582096e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.714815e-19</td>\n",
       "      <td>-7.118652e-20</td>\n",
       "      <td>4.062297e-21</td>\n",
       "      <td>-7.743107e-21</td>\n",
       "      <td>8.638654e-22</td>\n",
       "      <td>-1.006311e-21</td>\n",
       "      <td>-2.267525e-22</td>\n",
       "      <td>-5.867730e-23</td>\n",
       "      <td>4.858047e-24</td>\n",
       "      <td>-4.595498e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.968480e-20</td>\n",
       "      <td>-4.619224e-20</td>\n",
       "      <td>-3.590984e-20</td>\n",
       "      <td>-2.717642e-20</td>\n",
       "      <td>1.923565e-20</td>\n",
       "      <td>-2.244442e-21</td>\n",
       "      <td>-4.244237e-24</td>\n",
       "      <td>-3.599564e-23</td>\n",
       "      <td>7.471194e-24</td>\n",
       "      <td>-3.815300e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.256463e-20</td>\n",
       "      <td>-5.346105e-19</td>\n",
       "      <td>-6.278001e-19</td>\n",
       "      <td>-5.786255e-19</td>\n",
       "      <td>2.573141e-19</td>\n",
       "      <td>2.385063e-19</td>\n",
       "      <td>6.655487e-20</td>\n",
       "      <td>2.834975e-20</td>\n",
       "      <td>3.356577e-21</td>\n",
       "      <td>1.698628e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.446271e-19</td>\n",
       "      <td>5.494150e-20</td>\n",
       "      <td>-1.187973e-20</td>\n",
       "      <td>-1.450941e-21</td>\n",
       "      <td>8.954877e-22</td>\n",
       "      <td>-2.645088e-22</td>\n",
       "      <td>1.365356e-23</td>\n",
       "      <td>8.062470e-24</td>\n",
       "      <td>-1.235689e-24</td>\n",
       "      <td>1.890073e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.806037e-19</td>\n",
       "      <td>-9.956413e-22</td>\n",
       "      <td>7.012638e-21</td>\n",
       "      <td>-1.749799e-21</td>\n",
       "      <td>-5.296019e-22</td>\n",
       "      <td>5.324962e-23</td>\n",
       "      <td>-7.651382e-24</td>\n",
       "      <td>-1.189074e-23</td>\n",
       "      <td>-3.929069e-24</td>\n",
       "      <td>1.550829e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.120559e-21</td>\n",
       "      <td>-2.386547e-22</td>\n",
       "      <td>3.369363e-23</td>\n",
       "      <td>1.459011e-23</td>\n",
       "      <td>5.123315e-25</td>\n",
       "      <td>-5.553792e-25</td>\n",
       "      <td>-1.656932e-25</td>\n",
       "      <td>-4.579053e-26</td>\n",
       "      <td>5.280697e-26</td>\n",
       "      <td>1.550841e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.683112e-18</td>\n",
       "      <td>-1.566546e-20</td>\n",
       "      <td>6.858092e-21</td>\n",
       "      <td>1.256228e-21</td>\n",
       "      <td>-3.157088e-22</td>\n",
       "      <td>1.984213e-23</td>\n",
       "      <td>1.134711e-23</td>\n",
       "      <td>-3.192012e-24</td>\n",
       "      <td>1.801697e-25</td>\n",
       "      <td>-1.020857e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.349202e-20</td>\n",
       "      <td>-1.839305e-21</td>\n",
       "      <td>3.174579e-20</td>\n",
       "      <td>7.510705e-21</td>\n",
       "      <td>-1.584091e-21</td>\n",
       "      <td>9.770302e-23</td>\n",
       "      <td>1.247588e-22</td>\n",
       "      <td>5.449431e-24</td>\n",
       "      <td>2.336028e-24</td>\n",
       "      <td>2.577251e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.295327e-17</td>\n",
       "      <td>9.899082e-17</td>\n",
       "      <td>8.549260e-17</td>\n",
       "      <td>1.099950e-18</td>\n",
       "      <td>-8.754949e-19</td>\n",
       "      <td>1.678472e-20</td>\n",
       "      <td>-1.834816e-20</td>\n",
       "      <td>-1.115471e-20</td>\n",
       "      <td>-4.795634e-21</td>\n",
       "      <td>-1.559397e-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1568 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  Feature 6  \\\n",
       "0            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "49995        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "49996        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "49997        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "49998        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "49999        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "       Feature 7  Feature 8  Feature 9  Feature 10  ...  Feature 1559  \\\n",
       "0            0.0        0.0        0.0         0.0  ... -1.281934e-19   \n",
       "1            0.0        0.0        0.0         0.0  ... -4.714815e-19   \n",
       "2            0.0        0.0        0.0         0.0  ... -3.968480e-20   \n",
       "3            0.0        0.0        0.0         0.0  ...  4.256463e-20   \n",
       "4            0.0        0.0        0.0         0.0  ... -9.446271e-19   \n",
       "...          ...        ...        ...         ...  ...           ...   \n",
       "49995        0.0        0.0        0.0         0.0  ... -2.806037e-19   \n",
       "49996        0.0        0.0        0.0         0.0  ...  1.120559e-21   \n",
       "49997        0.0        0.0        0.0         0.0  ...  2.683112e-18   \n",
       "49998        0.0        0.0        0.0         0.0  ...  4.349202e-20   \n",
       "49999        0.0        0.0        0.0         0.0  ...  8.295327e-17   \n",
       "\n",
       "       Feature 1560  Feature 1561  Feature 1562  Feature 1563  Feature 1564  \\\n",
       "0      3.854928e-19 -1.329011e-20  4.204335e-21  4.428740e-21  4.461340e-23   \n",
       "1     -7.118652e-20  4.062297e-21 -7.743107e-21  8.638654e-22 -1.006311e-21   \n",
       "2     -4.619224e-20 -3.590984e-20 -2.717642e-20  1.923565e-20 -2.244442e-21   \n",
       "3     -5.346105e-19 -6.278001e-19 -5.786255e-19  2.573141e-19  2.385063e-19   \n",
       "4      5.494150e-20 -1.187973e-20 -1.450941e-21  8.954877e-22 -2.645088e-22   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "49995 -9.956413e-22  7.012638e-21 -1.749799e-21 -5.296019e-22  5.324962e-23   \n",
       "49996 -2.386547e-22  3.369363e-23  1.459011e-23  5.123315e-25 -5.553792e-25   \n",
       "49997 -1.566546e-20  6.858092e-21  1.256228e-21 -3.157088e-22  1.984213e-23   \n",
       "49998 -1.839305e-21  3.174579e-20  7.510705e-21 -1.584091e-21  9.770302e-23   \n",
       "49999  9.899082e-17  8.549260e-17  1.099950e-18 -8.754949e-19  1.678472e-20   \n",
       "\n",
       "       Feature 1565  Feature 1566  Feature 1567  Feature 1568  \n",
       "0      2.376798e-24 -7.807106e-24  2.379322e-24 -5.582096e-26  \n",
       "1     -2.267525e-22 -5.867730e-23  4.858047e-24 -4.595498e-25  \n",
       "2     -4.244237e-24 -3.599564e-23  7.471194e-24 -3.815300e-24  \n",
       "3      6.655487e-20  2.834975e-20  3.356577e-21  1.698628e-21  \n",
       "4      1.365356e-23  8.062470e-24 -1.235689e-24  1.890073e-25  \n",
       "...             ...           ...           ...           ...  \n",
       "49995 -7.651382e-24 -1.189074e-23 -3.929069e-24  1.550829e-24  \n",
       "49996 -1.656932e-25 -4.579053e-26  5.280697e-26  1.550841e-26  \n",
       "49997  1.134711e-23 -3.192012e-24  1.801697e-25 -1.020857e-26  \n",
       "49998  1.247588e-22  5.449431e-24  2.336028e-24  2.577251e-24  \n",
       "49999 -1.834816e-20 -1.115471e-20 -4.795634e-21 -1.559397e-22  \n",
       "\n",
       "[50000 rows x 1568 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b826662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.37591740e-21],\n",
       "         [ 5.30417960e-22],\n",
       "         [-3.57824900e-24]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.48994830e-21],\n",
       "         [ 6.31696440e-22],\n",
       "         [-3.58053030e-22]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.00505800e-21],\n",
       "         [ 1.07208180e-21],\n",
       "         [-2.05822040e-21]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.86626740e-23],\n",
       "         [-7.54684500e-24],\n",
       "         [-2.40440590e-23]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.71384430e-23],\n",
       "         [-2.84402220e-24],\n",
       "         [ 4.41500800e-25]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-7.80710550e-24],\n",
       "         [ 2.37932200e-24],\n",
       "         [-5.58209600e-26]]],\n",
       "\n",
       "\n",
       "       [[[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 3.27461340e-25],\n",
       "         [ 1.07634440e-25],\n",
       "         [-9.88395400e-26]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-8.87620800e-25],\n",
       "         [-2.92710000e-25],\n",
       "         [-2.16285940e-25]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.21094440e-25],\n",
       "         [-8.62574300e-25],\n",
       "         [-2.89712300e-25]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-1.01158940e-21],\n",
       "         [-3.26014200e-22],\n",
       "         [ 1.12037020e-22]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.61687560e-22],\n",
       "         [ 1.08058660e-23],\n",
       "         [ 2.33908320e-23]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-5.86773040e-23],\n",
       "         [ 4.85804650e-24],\n",
       "         [-4.59549800e-25]]],\n",
       "\n",
       "\n",
       "       [[[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.01568520e-24],\n",
       "         [-2.21912860e-25],\n",
       "         [-1.28033780e-25]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.93806880e-26],\n",
       "         [-1.16200960e-24],\n",
       "         [-6.89255140e-25]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 6.32483370e-23],\n",
       "         [-7.65216870e-25],\n",
       "         [-6.30463350e-25]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 4.40460400e-22],\n",
       "         [ 3.78048100e-22],\n",
       "         [ 1.02063820e-22]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.82695610e-22],\n",
       "         [ 8.89086300e-23],\n",
       "         [ 2.67230670e-23]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.59956400e-23],\n",
       "         [ 7.47119360e-24],\n",
       "         [-3.81529970e-24]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-2.72341040e-26],\n",
       "         [-3.49097880e-27],\n",
       "         [ 4.04444570e-28]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-2.48399260e-26],\n",
       "         [ 3.63561880e-27],\n",
       "         [ 3.83510200e-27]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.50423720e-25],\n",
       "         [ 1.25764650e-26],\n",
       "         [-3.96775370e-28]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.98952120e-23],\n",
       "         [ 1.01063370e-23],\n",
       "         [ 1.32246810e-23]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.15221730e-23],\n",
       "         [ 7.35454100e-24],\n",
       "         [ 3.31382680e-24]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.19201230e-24],\n",
       "         [ 1.80169730e-25],\n",
       "         [-1.02085740e-26]]],\n",
       "\n",
       "\n",
       "       [[[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.32780230e-24],\n",
       "         [ 1.03126220e-24],\n",
       "         [-4.22012600e-26]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.91623280e-24],\n",
       "         [-3.76451400e-24],\n",
       "         [-1.09306650e-24]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-1.13043965e-23],\n",
       "         [ 1.10209680e-24],\n",
       "         [ 2.78564240e-25]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.42552370e-23],\n",
       "         [-9.72694700e-25],\n",
       "         [-3.63002400e-23]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.11643540e-23],\n",
       "         [ 9.59594150e-24],\n",
       "         [-3.78250980e-23]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 5.44943100e-24],\n",
       "         [ 2.33602780e-24],\n",
       "         [ 2.57725080e-24]]],\n",
       "\n",
       "\n",
       "       [[[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.60686140e-26],\n",
       "         [-1.65943130e-26],\n",
       "         [ 1.53454600e-27]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-1.40309690e-24],\n",
       "         [-1.92335910e-25],\n",
       "         [ 2.69408330e-26]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.26709840e-24],\n",
       "         [-6.00235830e-25],\n",
       "         [-1.88249930e-26]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.59503440e-20],\n",
       "         [ 2.23094200e-20],\n",
       "         [-5.94482500e-20]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 5.97874640e-20],\n",
       "         [ 5.78594870e-21],\n",
       "         [ 3.81944540e-20]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-1.11547100e-20],\n",
       "         [-4.79563400e-21],\n",
       "         [-1.55939740e-22]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.values.reshape((-1,28,56,1))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccc95e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5049b10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 56, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30702f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 19)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "666d6809",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c364e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\", input_shape=X.shape[1:]))\n",
    "model.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())    \n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "    \n",
    "model.add(Dense(19,activation=\"softmax\"))\n",
    "    \n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7666232a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 54, 64)        640       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 52, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 26, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 12, 26, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 24, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 22, 128)        147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 4, 11, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 4, 11, 128)       512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 2, 9, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1, 4, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 19)                9747      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,090,515\n",
      "Trainable params: 1,089,619\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef93df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "022fc6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "391/391 [==============================] - 14s 19ms/step - loss: 0.6515 - accuracy: 0.7968\n",
      "Epoch 2/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0756 - accuracy: 0.9764\n",
      "Epoch 3/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0392 - accuracy: 0.9881\n",
      "Epoch 4/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0256 - accuracy: 0.9917\n",
      "Epoch 5/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0210 - accuracy: 0.9933\n",
      "Epoch 6/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0239 - accuracy: 0.9920\n",
      "Epoch 7/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0212 - accuracy: 0.9932\n",
      "Epoch 8/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0186 - accuracy: 0.9947\n",
      "Epoch 9/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0175 - accuracy: 0.9949\n",
      "Epoch 10/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0153 - accuracy: 0.9955\n",
      "Epoch 11/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0160 - accuracy: 0.9956\n",
      "Epoch 12/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0075 - accuracy: 0.9978\n",
      "Epoch 13/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0130 - accuracy: 0.9963\n",
      "Epoch 14/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0149 - accuracy: 0.9960\n",
      "Epoch 15/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0125 - accuracy: 0.9965\n",
      "Epoch 16/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0105 - accuracy: 0.9969\n",
      "Epoch 17/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0072 - accuracy: 0.9979\n",
      "Epoch 18/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0068 - accuracy: 0.9980\n",
      "Epoch 19/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0099 - accuracy: 0.9972\n",
      "Epoch 20/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0082 - accuracy: 0.9973\n",
      "Epoch 21/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0094 - accuracy: 0.9976\n",
      "Epoch 22/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0102 - accuracy: 0.9972\n",
      "Epoch 23/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0067 - accuracy: 0.9981\n",
      "Epoch 24/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0055 - accuracy: 0.9984\n",
      "Epoch 25/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0082 - accuracy: 0.9975\n",
      "Epoch 26/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0063 - accuracy: 0.9984\n",
      "Epoch 27/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0062 - accuracy: 0.9983\n",
      "Epoch 28/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0081 - accuracy: 0.9980\n",
      "Epoch 29/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0040 - accuracy: 0.9988\n",
      "Epoch 30/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 31/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0110 - accuracy: 0.9976\n",
      "Epoch 32/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0062 - accuracy: 0.9984\n",
      "Epoch 33/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0040 - accuracy: 0.9988\n",
      "Epoch 34/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0052 - accuracy: 0.9987\n",
      "Epoch 35/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 36/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 37/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0077 - accuracy: 0.9979\n",
      "Epoch 38/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0057 - accuracy: 0.9984\n",
      "Epoch 39/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0043 - accuracy: 0.9990\n",
      "Epoch 40/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0049 - accuracy: 0.9987\n",
      "Epoch 41/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0035 - accuracy: 0.9992\n",
      "Epoch 42/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0047 - accuracy: 0.9988\n",
      "Epoch 43/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0054 - accuracy: 0.9987\n",
      "Epoch 44/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0059 - accuracy: 0.9987\n",
      "Epoch 45/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0056 - accuracy: 0.9986\n",
      "Epoch 46/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 47/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 48/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0032 - accuracy: 0.9992\n",
      "Epoch 49/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 50/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0067 - accuracy: 0.9986\n",
      "Epoch 51/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 52/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 53/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 54/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 55/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0051 - accuracy: 0.9986\n",
      "Epoch 56/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 57/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0065 - accuracy: 0.9987\n",
      "Epoch 58/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0034 - accuracy: 0.9994\n",
      "Epoch 59/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 60/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0039 - accuracy: 0.9989\n",
      "Epoch 61/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 62/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 63/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 64/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 65/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0038 - accuracy: 0.9991\n",
      "Epoch 66/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 67/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 68/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 69/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0053 - accuracy: 0.9991\n",
      "Epoch 70/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0046 - accuracy: 0.9990\n",
      "Epoch 71/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 72/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 73/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.7099e-04 - accuracy: 0.9998\n",
      "Epoch 74/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 75/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 76/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0047 - accuracy: 0.9990\n",
      "Epoch 77/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "Epoch 78/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 79/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 80/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 81/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0041 - accuracy: 0.9991\n",
      "Epoch 82/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 83/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 84/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 85/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.2770e-04 - accuracy: 0.9998\n",
      "Epoch 86/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0047 - accuracy: 0.9989\n",
      "Epoch 87/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0050 - accuracy: 0.9991\n",
      "Epoch 88/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 89/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 90/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 91/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 92/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 93/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.7311e-04 - accuracy: 0.9999\n",
      "Epoch 94/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 95/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0021 - accuracy: 0.9997\n",
      "Epoch 96/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 97/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 98/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 99/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 100/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0051 - accuracy: 0.9988\n",
      "Epoch 101/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 102/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.5809e-04 - accuracy: 0.9998\n",
      "Epoch 103/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.0276e-04 - accuracy: 0.9999\n",
      "Epoch 104/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.2821e-04 - accuracy: 0.9999\n",
      "Epoch 105/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0036 - accuracy: 0.9993\n",
      "Epoch 106/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0033 - accuracy: 0.9993\n",
      "Epoch 107/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 108/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 109/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 110/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0043 - accuracy: 0.9992\n",
      "Epoch 111/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 112/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.0696e-04 - accuracy: 0.9998\n",
      "Epoch 113/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.8944e-04 - accuracy: 0.9998\n",
      "Epoch 114/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0023 - accuracy: 0.9996\n",
      "Epoch 115/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0057 - accuracy: 0.9990\n",
      "Epoch 116/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0021 - accuracy: 0.9996\n",
      "Epoch 117/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.0382e-04 - accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.4802e-04 - accuracy: 0.9999\n",
      "Epoch 119/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 120/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0041 - accuracy: 0.9992\n",
      "Epoch 121/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 122/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.6787e-04 - accuracy: 0.9997\n",
      "Epoch 123/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.1066e-04 - accuracy: 0.9998\n",
      "Epoch 124/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0035 - accuracy: 0.9993\n",
      "Epoch 125/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0032 - accuracy: 0.9992\n",
      "Epoch 126/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0027 - accuracy: 0.9996\n",
      "Epoch 127/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.9893e-04 - accuracy: 0.9997\n",
      "Epoch 128/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 129/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 130/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.3538e-05 - accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.2190e-04 - accuracy: 0.9999\n",
      "Epoch 132/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 133/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 134/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 135/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 136/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 137/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 138/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.3275e-04 - accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.1737e-04 - accuracy: 0.9998\n",
      "Epoch 140/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 141/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 142/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0043 - accuracy: 0.9991\n",
      "Epoch 143/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 144/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0021 - accuracy: 0.9997\n",
      "Epoch 145/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 146/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 147/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 148/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.8654e-04 - accuracy: 0.9997\n",
      "Epoch 149/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.8330e-04 - accuracy: 0.9998\n",
      "Epoch 150/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.3748e-04 - accuracy: 0.9996\n",
      "Epoch 151/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.8694e-04 - accuracy: 0.9998\n",
      "Epoch 152/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.4284e-05 - accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.0436e-06 - accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 155/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0068 - accuracy: 0.9991\n",
      "Epoch 156/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 7s 18ms/step - loss: 9.6906e-04 - accuracy: 0.9998\n",
      "Epoch 157/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0018 - accuracy: 0.9997\n",
      "Epoch 158/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.5646e-04 - accuracy: 0.9998\n",
      "Epoch 159/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.4458e-04 - accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.8711e-04 - accuracy: 0.9999\n",
      "Epoch 161/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 162/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0046 - accuracy: 0.9992\n",
      "Epoch 163/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 164/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.3288e-04 - accuracy: 0.9999\n",
      "Epoch 165/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.0402e-04 - accuracy: 0.9998\n",
      "Epoch 166/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.9614e-04 - accuracy: 0.9998\n",
      "Epoch 167/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.7477e-04 - accuracy: 0.9999\n",
      "Epoch 168/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0027 - accuracy: 0.9997\n",
      "Epoch 169/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0032 - accuracy: 0.9995\n",
      "Epoch 170/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0025 - accuracy: 0.9996\n",
      "Epoch 171/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.3354e-04 - accuracy: 0.9998\n",
      "Epoch 172/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.6946e-04 - accuracy: 0.9998\n",
      "Epoch 173/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.9129e-04 - accuracy: 0.9999\n",
      "Epoch 174/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 175/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.3147e-04 - accuracy: 0.9999\n",
      "Epoch 176/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.3719e-05 - accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.6292e-04 - accuracy: 0.9999\n",
      "Epoch 178/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0029 - accuracy: 0.9996\n",
      "Epoch 179/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0025 - accuracy: 0.9995\n",
      "Epoch 180/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0025 - accuracy: 0.9996\n",
      "Epoch 181/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 182/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.5443e-04 - accuracy: 0.9999\n",
      "Epoch 183/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.6458e-04 - accuracy: 0.9998\n",
      "Epoch 184/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.6803e-04 - accuracy: 0.9999\n",
      "Epoch 185/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 186/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 187/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 188/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.0251e-04 - accuracy: 0.9998\n",
      "Epoch 189/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.2796e-04 - accuracy: 0.9998\n",
      "Epoch 190/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9999\n",
      "Epoch 191/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 192/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 193/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 194/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.4039e-04 - accuracy: 0.9999\n",
      "Epoch 195/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.9515e-04 - accuracy: 0.9999\n",
      "Epoch 196/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 197/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.8607e-04 - accuracy: 0.9998\n",
      "Epoch 198/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0020 - accuracy: 0.9997\n",
      "Epoch 199/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0034 - accuracy: 0.9995\n",
      "Epoch 200/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.1033e-04 - accuracy: 0.9997\n",
      "Epoch 201/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.5423e-05 - accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0010 - accuracy: 0.9999\n",
      "Epoch 203/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9998\n",
      "Epoch 204/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0054 - accuracy: 0.9992\n",
      "Epoch 205/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 206/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.5068e-04 - accuracy: 0.9999\n",
      "Epoch 207/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.2526e-04 - accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.1563e-05 - accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.9641e-04 - accuracy: 0.9999\n",
      "Epoch 210/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.0765e-05 - accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0037 - accuracy: 0.9995\n",
      "Epoch 212/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0039 - accuracy: 0.9991\n",
      "Epoch 213/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 214/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.6510e-04 - accuracy: 0.9999\n",
      "Epoch 215/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.0969e-04 - accuracy: 0.9999\n",
      "Epoch 216/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.6235e-04 - accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.6403e-04 - accuracy: 0.9999\n",
      "Epoch 218/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.4324e-04 - accuracy: 0.9998\n",
      "Epoch 219/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0019 - accuracy: 0.9997\n",
      "Epoch 220/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0018 - accuracy: 0.9997\n",
      "Epoch 221/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0023 - accuracy: 0.9997\n",
      "Epoch 222/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0023 - accuracy: 0.9997\n",
      "Epoch 223/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.9307e-04 - accuracy: 0.9999\n",
      "Epoch 224/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.9416e-04 - accuracy: 0.9999\n",
      "Epoch 225/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.3220e-04 - accuracy: 0.9997\n",
      "Epoch 226/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0024 - accuracy: 0.9997\n",
      "Epoch 227/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0024 - accuracy: 0.9996\n",
      "Epoch 228/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 229/1000\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 8.1718e-04 - accuracy: 0.9999\n",
      "Epoch 230/1000\n",
      "391/391 [==============================] - 8s 19ms/step - loss: 7.0227e-05 - accuracy: 1.0000\n",
      "Epoch 231/1000\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 1.5386e-04 - accuracy: 0.9999\n",
      "Epoch 232/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 233/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 234/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0020 - accuracy: 0.9997\n",
      "Epoch 235/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.7214e-04 - accuracy: 0.9998\n",
      "Epoch 236/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 237/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.5523e-04 - accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.9476e-05 - accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.8530e-06 - accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.6946e-04 - accuracy: 0.9997\n",
      "Epoch 241/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 242/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.6644e-04 - accuracy: 0.9999\n",
      "Epoch 243/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0021 - accuracy: 0.9998\n",
      "Epoch 244/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 245/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 246/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.0309e-04 - accuracy: 0.9999\n",
      "Epoch 247/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.6651e-04 - accuracy: 0.9999\n",
      "Epoch 248/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0040 - accuracy: 0.9993\n",
      "Epoch 249/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 250/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.5925e-04 - accuracy: 0.9999\n",
      "Epoch 251/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.3866e-04 - accuracy: 1.0000\n",
      "Epoch 252/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.8370e-05 - accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.8999e-06 - accuracy: 1.0000\n",
      "Epoch 254/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.6637e-07 - accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.2699e-07 - accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.5358e-07 - accuracy: 1.0000\n",
      "Epoch 257/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.2189e-06 - accuracy: 1.0000\n",
      "Epoch 258/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.7444e-04 - accuracy: 0.9999\n",
      "Epoch 259/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0074 - accuracy: 0.9990\n",
      "Epoch 260/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 261/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 262/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.1127e-04 - accuracy: 0.9999\n",
      "Epoch 263/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.7061e-04 - accuracy: 0.9998\n",
      "Epoch 264/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.2892e-04 - accuracy: 0.9999\n",
      "Epoch 265/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.1841e-04 - accuracy: 0.9998\n",
      "Epoch 266/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.6858e-04 - accuracy: 0.9999\n",
      "Epoch 267/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.5204e-04 - accuracy: 1.0000\n",
      "Epoch 268/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.5493e-05 - accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.0629e-04 - accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0030 - accuracy: 0.9996\n",
      "Epoch 271/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0018 - accuracy: 0.9997\n",
      "Epoch 272/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.2179e-04 - accuracy: 0.9999\n",
      "Epoch 273/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.4284e-04 - accuracy: 0.9999\n",
      "Epoch 274/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0032 - accuracy: 0.9995\n",
      "Epoch 275/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 276/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9998\n",
      "Epoch 277/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0020 - accuracy: 0.9996\n",
      "Epoch 278/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0016 - accuracy: 0.9998\n",
      "Epoch 279/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.1261e-05 - accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.5654e-04 - accuracy: 0.9999\n",
      "Epoch 281/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 282/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.3951e-04 - accuracy: 0.9999\n",
      "Epoch 283/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.8530e-04 - accuracy: 0.9999\n",
      "Epoch 284/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 285/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.3438e-04 - accuracy: 0.9999\n",
      "Epoch 286/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 287/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9998\n",
      "Epoch 288/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.7036e-04 - accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.9261e-04 - accuracy: 0.9999\n",
      "Epoch 290/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0029 - accuracy: 0.9995\n",
      "Epoch 291/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 292/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9998\n",
      "Epoch 293/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.4827e-04 - accuracy: 0.9998\n",
      "Epoch 294/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.7774e-04 - accuracy: 0.9999\n",
      "Epoch 295/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.5022e-04 - accuracy: 0.9998\n",
      "Epoch 296/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0018 - accuracy: 0.9998\n",
      "Epoch 297/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 298/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.2434e-04 - accuracy: 0.9998\n",
      "Epoch 299/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.8310e-04 - accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.6493e-04 - accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.9513e-05 - accuracy: 0.9999\n",
      "Epoch 302/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 303/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.3117e-04 - accuracy: 0.9999\n",
      "Epoch 304/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.7813e-05 - accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.2384e-05 - accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 307/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0031 - accuracy: 0.9995\n",
      "Epoch 308/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 309/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0023 - accuracy: 0.9998\n",
      "Epoch 310/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.3775e-04 - accuracy: 0.9999\n",
      "Epoch 311/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.8154e-04 - accuracy: 0.9999\n",
      "Epoch 312/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.3681e-04 - accuracy: 0.9999\n",
      "Epoch 313/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0019 - accuracy: 0.9997\n",
      "Epoch 314/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0024 - accuracy: 0.9997\n",
      "Epoch 315/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0020 - accuracy: 0.9997\n",
      "Epoch 316/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 317/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.2682e-04 - accuracy: 0.9999\n",
      "Epoch 318/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.3396e-04 - accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.6385e-07 - accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.5143e-07 - accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.1294e-06 - accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.8035e-06 - accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.6866e-07 - accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.3661e-07 - accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.2403e-07 - accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.5086e-07 - accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.1141e-07 - accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.1453e-07 - accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.2327e-07 - accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.9041e-06 - accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0086 - accuracy: 0.9990\n",
      "Epoch 332/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0035 - accuracy: 0.9995\n",
      "Epoch 333/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.9839e-05 - accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.3662e-04 - accuracy: 0.9999\n",
      "Epoch 335/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 336/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 337/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.2922e-04 - accuracy: 0.9998\n",
      "Epoch 338/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.6588e-04 - accuracy: 0.9998\n",
      "Epoch 339/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.4404e-04 - accuracy: 0.9999\n",
      "Epoch 340/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.9260e-04 - accuracy: 0.9999\n",
      "Epoch 341/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.1522e-04 - accuracy: 0.9999\n",
      "Epoch 343/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0020 - accuracy: 0.9996\n",
      "Epoch 344/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0022 - accuracy: 0.9996\n",
      "Epoch 345/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.8196e-04 - accuracy: 0.9998\n",
      "Epoch 346/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.5815e-04 - accuracy: 0.9998\n",
      "Epoch 347/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.8751e-05 - accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.3913e-04 - accuracy: 0.9999\n",
      "Epoch 349/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.5990e-04 - accuracy: 0.9998\n",
      "Epoch 350/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.4928e-04 - accuracy: 0.9999\n",
      "Epoch 351/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.6602e-04 - accuracy: 0.9998\n",
      "Epoch 352/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9998\n",
      "Epoch 353/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0018 - accuracy: 0.9997\n",
      "Epoch 354/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0018 - accuracy: 0.9998\n",
      "Epoch 355/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.6210e-04 - accuracy: 0.9999\n",
      "Epoch 356/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.0736e-04 - accuracy: 0.9998\n",
      "Epoch 357/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.3766e-04 - accuracy: 0.9999\n",
      "Epoch 358/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.9132e-05 - accuracy: 1.0000\n",
      "Epoch 359/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.3280e-04 - accuracy: 0.9999\n",
      "Epoch 360/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.5306e-04 - accuracy: 0.9999\n",
      "Epoch 361/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.9619e-04 - accuracy: 0.9998\n",
      "Epoch 362/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.9932e-04 - accuracy: 0.9999\n",
      "Epoch 363/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0036 - accuracy: 0.9995\n",
      "Epoch 364/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0021 - accuracy: 0.9997\n",
      "Epoch 365/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 366/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.9924e-04 - accuracy: 0.9998\n",
      "Epoch 367/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 368/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.0192e-04 - accuracy: 0.9999\n",
      "Epoch 369/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.2824e-04 - accuracy: 0.9998\n",
      "Epoch 370/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.9789e-05 - accuracy: 1.0000\n",
      "Epoch 371/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.0852e-05 - accuracy: 1.0000\n",
      "Epoch 372/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.4380e-04 - accuracy: 0.9999\n",
      "Epoch 373/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 374/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0022 - accuracy: 0.9996\n",
      "Epoch 375/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.9953e-04 - accuracy: 0.9999\n",
      "Epoch 376/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.2892e-05 - accuracy: 1.0000\n",
      "Epoch 377/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.5674e-06 - accuracy: 1.0000\n",
      "Epoch 378/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.2287e-06 - accuracy: 1.0000\n",
      "Epoch 379/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.2075e-06 - accuracy: 1.0000\n",
      "Epoch 380/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.5454e-04 - accuracy: 1.0000\n",
      "Epoch 381/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 382/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 383/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 384/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 385/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9999\n",
      "Epoch 386/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.1177e-04 - accuracy: 0.9999\n",
      "Epoch 387/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.1492e-05 - accuracy: 1.0000\n",
      "Epoch 388/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.6768e-06 - accuracy: 1.0000\n",
      "Epoch 389/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.2092e-05 - accuracy: 1.0000\n",
      "Epoch 390/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.9680e-04 - accuracy: 0.9999\n",
      "Epoch 391/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.6799e-04 - accuracy: 0.9998\n",
      "Epoch 392/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0029 - accuracy: 0.9996\n",
      "Epoch 393/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 394/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0021 - accuracy: 0.9998\n",
      "Epoch 395/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.5912e-04 - accuracy: 0.9999\n",
      "Epoch 396/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0018 - accuracy: 0.9998\n",
      "Epoch 397/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.1920e-04 - accuracy: 0.9999\n",
      "Epoch 398/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.7736e-06 - accuracy: 1.0000\n",
      "Epoch 399/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.6439e-06 - accuracy: 1.0000\n",
      "Epoch 400/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.3314e-06 - accuracy: 1.0000\n",
      "Epoch 401/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.4062e-04 - accuracy: 0.9999\n",
      "Epoch 402/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0021 - accuracy: 0.9997\n",
      "Epoch 403/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0024 - accuracy: 0.9996\n",
      "Epoch 404/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0032 - accuracy: 0.9997\n",
      "Epoch 405/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.8183e-04 - accuracy: 0.9999\n",
      "Epoch 406/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.1869e-04 - accuracy: 0.9999\n",
      "Epoch 407/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.4846e-04 - accuracy: 0.9999\n",
      "Epoch 408/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.7881e-05 - accuracy: 1.0000\n",
      "Epoch 409/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.5532e-05 - accuracy: 1.0000\n",
      "Epoch 410/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.5243e-04 - accuracy: 1.0000\n",
      "Epoch 411/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.8699e-04 - accuracy: 0.9999\n",
      "Epoch 412/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.6444e-04 - accuracy: 0.9999\n",
      "Epoch 413/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0027 - accuracy: 0.9997\n",
      "Epoch 414/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 415/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 416/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.6662e-04 - accuracy: 0.9998\n",
      "Epoch 417/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.3437e-04 - accuracy: 0.9999\n",
      "Epoch 418/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.4638e-04 - accuracy: 0.9999\n",
      "Epoch 419/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.8219e-04 - accuracy: 0.9999\n",
      "Epoch 420/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.8381e-05 - accuracy: 1.0000\n",
      "Epoch 421/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.2406e-06 - accuracy: 1.0000\n",
      "Epoch 422/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.1667e-05 - accuracy: 1.0000\n",
      "Epoch 423/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9999\n",
      "Epoch 424/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.1948e-04 - accuracy: 0.9999\n",
      "Epoch 425/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0018 - accuracy: 0.9997\n",
      "Epoch 426/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.8910e-04 - accuracy: 0.9999\n",
      "Epoch 427/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.4035e-04 - accuracy: 0.9999\n",
      "Epoch 428/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 429/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0028 - accuracy: 0.9996\n",
      "Epoch 430/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 431/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.6189e-04 - accuracy: 0.9999\n",
      "Epoch 432/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.7620e-04 - accuracy: 0.9999\n",
      "Epoch 433/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.7107e-04 - accuracy: 0.9998\n",
      "Epoch 434/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.7243e-04 - accuracy: 0.9998\n",
      "Epoch 435/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.4298e-04 - accuracy: 0.9999\n",
      "Epoch 436/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.7276e-05 - accuracy: 1.0000\n",
      "Epoch 437/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.0450e-04 - accuracy: 0.9999\n",
      "Epoch 438/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0022 - accuracy: 0.9996\n",
      "Epoch 439/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.3519e-04 - accuracy: 0.9999\n",
      "Epoch 440/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0016 - accuracy: 0.9998\n",
      "Epoch 441/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 442/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.5169e-05 - accuracy: 1.0000\n",
      "Epoch 443/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.2601e-05 - accuracy: 1.0000\n",
      "Epoch 444/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.2196e-06 - accuracy: 1.0000\n",
      "Epoch 445/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.2247e-06 - accuracy: 1.0000\n",
      "Epoch 446/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.0887e-06 - accuracy: 1.0000\n",
      "Epoch 447/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.4568e-07 - accuracy: 1.0000\n",
      "Epoch 448/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.7076e-07 - accuracy: 1.0000\n",
      "Epoch 449/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.1760e-06 - accuracy: 1.0000\n",
      "Epoch 450/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.6205e-08 - accuracy: 1.0000\n",
      "Epoch 451/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.4921e-09 - accuracy: 1.0000\n",
      "Epoch 452/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.5804e-08 - accuracy: 1.0000\n",
      "Epoch 453/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.7870e-07 - accuracy: 1.0000\n",
      "Epoch 454/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.0013e-08 - accuracy: 1.0000\n",
      "Epoch 455/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0065 - accuracy: 0.9991\n",
      "Epoch 456/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0021 - accuracy: 0.9996\n",
      "Epoch 457/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.1927e-05 - accuracy: 1.0000\n",
      "Epoch 458/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.1335e-04 - accuracy: 1.0000\n",
      "Epoch 459/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0019 - accuracy: 0.9998\n",
      "Epoch 460/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 7s 18ms/step - loss: 2.4397e-06 - accuracy: 1.0000\n",
      "Epoch 461/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.3686e-05 - accuracy: 1.0000\n",
      "Epoch 462/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.8896e-04 - accuracy: 0.9999\n",
      "Epoch 463/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.7248e-04 - accuracy: 0.9999\n",
      "Epoch 464/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0017 - accuracy: 0.9998\n",
      "Epoch 465/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0018 - accuracy: 0.9999\n",
      "Epoch 466/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.6360e-04 - accuracy: 0.9999\n",
      "Epoch 467/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0017 - accuracy: 0.9998\n",
      "Epoch 468/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.9564e-04 - accuracy: 0.9999\n",
      "Epoch 469/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.1286e-04 - accuracy: 0.9999\n",
      "Epoch 470/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.6948e-04 - accuracy: 0.9999\n",
      "Epoch 471/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0013 - accuracy: 0.9999\n",
      "Epoch 472/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.3406e-04 - accuracy: 0.9999\n",
      "Epoch 473/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0010 - accuracy: 0.9999\n",
      "Epoch 474/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.1806e-05 - accuracy: 1.0000\n",
      "Epoch 475/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.2130e-06 - accuracy: 1.0000\n",
      "Epoch 476/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.6245e-05 - accuracy: 1.0000\n",
      "Epoch 477/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0017 - accuracy: 0.9998\n",
      "Epoch 478/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0018 - accuracy: 0.9997\n",
      "Epoch 479/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 480/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.3838e-04 - accuracy: 0.9998\n",
      "Epoch 481/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0023 - accuracy: 0.9998\n",
      "Epoch 482/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.4538e-04 - accuracy: 0.9999\n",
      "Epoch 483/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.0748e-04 - accuracy: 0.9999\n",
      "Epoch 484/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.4091e-04 - accuracy: 1.0000\n",
      "Epoch 485/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.3429e-04 - accuracy: 0.9999\n",
      "Epoch 486/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.4548e-04 - accuracy: 0.9999\n",
      "Epoch 487/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.3270e-05 - accuracy: 1.0000\n",
      "Epoch 488/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.9402e-04 - accuracy: 1.0000\n",
      "Epoch 489/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 490/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 491/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.0527e-04 - accuracy: 0.9997\n",
      "Epoch 492/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.4985e-04 - accuracy: 0.9999\n",
      "Epoch 493/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.8586e-04 - accuracy: 1.0000\n",
      "Epoch 494/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.0246e-04 - accuracy: 0.9999\n",
      "Epoch 495/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.9144e-04 - accuracy: 0.9999\n",
      "Epoch 496/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.6885e-05 - accuracy: 1.0000\n",
      "Epoch 497/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.0452e-04 - accuracy: 0.9999\n",
      "Epoch 498/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.4575e-05 - accuracy: 1.0000\n",
      "Epoch 499/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.0957e-04 - accuracy: 1.0000\n",
      "Epoch 500/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.3922e-06 - accuracy: 1.0000\n",
      "Epoch 501/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.2160e-06 - accuracy: 1.0000\n",
      "Epoch 502/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0034 - accuracy: 0.9996\n",
      "Epoch 503/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.9087e-04 - accuracy: 0.9998\n",
      "Epoch 504/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 505/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.1046e-04 - accuracy: 0.9999\n",
      "Epoch 506/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.1080e-04 - accuracy: 1.0000\n",
      "Epoch 507/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.3399e-07 - accuracy: 1.0000\n",
      "Epoch 508/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9999\n",
      "Epoch 509/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0022 - accuracy: 0.9997\n",
      "Epoch 510/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.8005e-04 - accuracy: 0.9999\n",
      "Epoch 511/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.2907e-05 - accuracy: 1.0000\n",
      "Epoch 512/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.0552e-05 - accuracy: 1.0000\n",
      "Epoch 513/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.0441e-04 - accuracy: 0.9999\n",
      "Epoch 514/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.2491e-04 - accuracy: 0.9999\n",
      "Epoch 515/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.6729e-04 - accuracy: 0.9999\n",
      "Epoch 516/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.5259e-04 - accuracy: 0.9998\n",
      "Epoch 517/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.7528e-04 - accuracy: 0.9999\n",
      "Epoch 518/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.9303e-04 - accuracy: 0.9999\n",
      "Epoch 519/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.8433e-05 - accuracy: 1.0000\n",
      "Epoch 520/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0017 - accuracy: 0.9999\n",
      "Epoch 521/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.3597e-04 - accuracy: 0.9999\n",
      "Epoch 522/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.5350e-04 - accuracy: 0.9999\n",
      "Epoch 523/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 524/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 525/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 526/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.7776e-04 - accuracy: 0.9999\n",
      "Epoch 527/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.0914e-04 - accuracy: 1.0000\n",
      "Epoch 528/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.1678e-05 - accuracy: 1.0000\n",
      "Epoch 529/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0016 - accuracy: 0.9998\n",
      "Epoch 530/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 531/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9999\n",
      "Epoch 532/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.1900e-05 - accuracy: 1.0000\n",
      "Epoch 533/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.5573e-05 - accuracy: 1.0000\n",
      "Epoch 534/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.7846e-07 - accuracy: 1.0000\n",
      "Epoch 535/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.9976e-07 - accuracy: 1.0000\n",
      "Epoch 536/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 7s 18ms/step - loss: 1.8175e-06 - accuracy: 1.0000\n",
      "Epoch 537/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0016 - accuracy: 0.9998\n",
      "Epoch 538/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0017 - accuracy: 0.9998\n",
      "Epoch 539/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 540/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.5308e-04 - accuracy: 0.9999\n",
      "Epoch 541/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 542/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.0845e-05 - accuracy: 1.0000\n",
      "Epoch 543/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.9008e-06 - accuracy: 1.0000\n",
      "Epoch 544/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.8509e-06 - accuracy: 1.0000\n",
      "Epoch 545/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.4566e-07 - accuracy: 1.0000\n",
      "Epoch 546/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.9181e-07 - accuracy: 1.0000\n",
      "Epoch 547/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.1289e-06 - accuracy: 1.0000\n",
      "Epoch 548/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.2378e-07 - accuracy: 1.0000\n",
      "Epoch 549/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.3441e-04 - accuracy: 0.9999\n",
      "Epoch 550/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0052 - accuracy: 0.9996\n",
      "Epoch 551/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0024 - accuracy: 0.9997\n",
      "Epoch 552/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.8342e-04 - accuracy: 0.9999\n",
      "Epoch 553/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.5262e-05 - accuracy: 1.0000\n",
      "Epoch 554/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.0773e-04 - accuracy: 0.9999\n",
      "Epoch 555/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.7370e-04 - accuracy: 1.0000\n",
      "Epoch 556/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.0901e-07 - accuracy: 1.0000\n",
      "Epoch 557/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.6354e-05 - accuracy: 1.0000\n",
      "Epoch 558/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.1957e-04 - accuracy: 1.0000\n",
      "Epoch 559/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 560/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.2073e-04 - accuracy: 1.0000\n",
      "Epoch 561/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.4337e-04 - accuracy: 1.0000\n",
      "Epoch 562/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.9593e-04 - accuracy: 1.0000\n",
      "Epoch 563/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.3896e-04 - accuracy: 1.0000\n",
      "Epoch 564/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.3925e-04 - accuracy: 0.9999\n",
      "Epoch 565/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.2963e-05 - accuracy: 1.0000\n",
      "Epoch 566/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.6021e-05 - accuracy: 1.0000\n",
      "Epoch 567/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0020 - accuracy: 0.9998\n",
      "Epoch 568/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0030 - accuracy: 0.9997\n",
      "Epoch 569/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.0228e-04 - accuracy: 0.9999\n",
      "Epoch 570/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.2887e-05 - accuracy: 1.0000\n",
      "Epoch 571/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.2377e-05 - accuracy: 1.0000\n",
      "Epoch 572/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.0572e-06 - accuracy: 1.0000\n",
      "Epoch 573/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.5689e-06 - accuracy: 1.0000\n",
      "Epoch 574/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.7253e-07 - accuracy: 1.0000\n",
      "Epoch 575/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.4825e-07 - accuracy: 1.0000\n",
      "Epoch 576/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.4334e-07 - accuracy: 1.0000\n",
      "Epoch 577/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.8732e-07 - accuracy: 1.0000\n",
      "Epoch 578/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.5835e-09 - accuracy: 1.0000\n",
      "Epoch 579/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.2075e-08 - accuracy: 1.0000\n",
      "Epoch 580/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.7146e-09 - accuracy: 1.0000\n",
      "Epoch 581/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.1827e-08 - accuracy: 1.0000\n",
      "Epoch 582/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.3375e-09 - accuracy: 1.0000\n",
      "Epoch 583/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.3193e-08 - accuracy: 1.0000\n",
      "Epoch 584/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.4223e-09 - accuracy: 1.0000\n",
      "Epoch 585/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.6728e-07 - accuracy: 1.0000\n",
      "Epoch 586/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.1171e-09 - accuracy: 1.0000\n",
      "Epoch 587/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.6262e-09 - accuracy: 1.0000\n",
      "Epoch 588/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.4428e-09 - accuracy: 1.0000\n",
      "Epoch 589/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.8489e-09 - accuracy: 1.0000\n",
      "Epoch 590/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.3465e-08 - accuracy: 1.0000\n",
      "Epoch 591/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.7450e-08 - accuracy: 1.0000\n",
      "Epoch 592/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.0254e-07 - accuracy: 1.0000\n",
      "Epoch 593/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.0879e-07 - accuracy: 1.0000\n",
      "Epoch 594/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0070 - accuracy: 0.9992\n",
      "Epoch 595/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0023 - accuracy: 0.9998\n",
      "Epoch 596/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 597/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.7796e-04 - accuracy: 1.0000\n",
      "Epoch 598/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.8074e-04 - accuracy: 0.9998\n",
      "Epoch 599/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.0575e-04 - accuracy: 0.9999\n",
      "Epoch 600/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.0048e-04 - accuracy: 0.9999\n",
      "Epoch 601/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.1945e-04 - accuracy: 0.9999\n",
      "Epoch 602/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.6322e-04 - accuracy: 0.9999\n",
      "Epoch 603/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.8810e-04 - accuracy: 0.9999\n",
      "Epoch 604/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.5082e-04 - accuracy: 0.9999\n",
      "Epoch 605/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.6641e-04 - accuracy: 0.9999\n",
      "Epoch 606/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.5799e-04 - accuracy: 0.9999\n",
      "Epoch 607/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9999\n",
      "Epoch 608/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.2011e-04 - accuracy: 0.9998\n",
      "Epoch 609/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.8611e-04 - accuracy: 0.9999\n",
      "Epoch 610/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.7674e-04 - accuracy: 0.9999\n",
      "Epoch 611/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.4661e-04 - accuracy: 0.9999\n",
      "Epoch 612/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.3775e-04 - accuracy: 0.9999\n",
      "Epoch 613/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.7207e-04 - accuracy: 0.9999\n",
      "Epoch 614/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.3950e-04 - accuracy: 0.9999\n",
      "Epoch 615/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9998\n",
      "Epoch 616/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.6627e-04 - accuracy: 0.9998\n",
      "Epoch 617/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0013 - accuracy: 0.9999\n",
      "Epoch 618/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.9569e-04 - accuracy: 0.9999\n",
      "Epoch 619/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.3797e-04 - accuracy: 0.9999\n",
      "Epoch 620/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9999\n",
      "Epoch 621/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0013 - accuracy: 0.9999\n",
      "Epoch 622/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.5779e-06 - accuracy: 1.0000\n",
      "Epoch 623/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.4305e-06 - accuracy: 1.0000\n",
      "Epoch 624/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.7007e-07 - accuracy: 1.0000\n",
      "Epoch 625/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.2384e-07 - accuracy: 1.0000\n",
      "Epoch 626/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.0114e-06 - accuracy: 1.0000\n",
      "Epoch 627/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0035 - accuracy: 0.9999\n",
      "Epoch 628/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.0390e-04 - accuracy: 0.9998\n",
      "Epoch 629/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 630/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0017 - accuracy: 0.9999\n",
      "Epoch 631/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.9839e-04 - accuracy: 1.0000\n",
      "Epoch 632/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.6624e-04 - accuracy: 1.0000\n",
      "Epoch 633/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.3118e-04 - accuracy: 1.0000\n",
      "Epoch 634/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.3653e-04 - accuracy: 1.0000\n",
      "Epoch 635/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.0797e-04 - accuracy: 0.9999\n",
      "Epoch 636/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0017 - accuracy: 0.9999\n",
      "Epoch 637/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.2898e-04 - accuracy: 0.9999\n",
      "Epoch 638/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.7105e-04 - accuracy: 0.9999\n",
      "Epoch 639/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.0539e-04 - accuracy: 0.9999\n",
      "Epoch 640/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.8230e-04 - accuracy: 0.9999\n",
      "Epoch 641/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.5635e-04 - accuracy: 0.9999\n",
      "Epoch 642/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.6956e-04 - accuracy: 0.9999\n",
      "Epoch 643/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.0993e-04 - accuracy: 1.0000\n",
      "Epoch 644/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.9084e-04 - accuracy: 0.9999\n",
      "Epoch 645/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9998\n",
      "Epoch 646/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.3333e-05 - accuracy: 1.0000\n",
      "Epoch 647/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.1264e-04 - accuracy: 0.9999\n",
      "Epoch 648/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.7216e-04 - accuracy: 0.9999\n",
      "Epoch 649/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.3932e-04 - accuracy: 0.9999\n",
      "Epoch 650/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.8840e-04 - accuracy: 1.0000\n",
      "Epoch 651/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.1606e-04 - accuracy: 0.9999\n",
      "Epoch 652/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 653/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0016 - accuracy: 0.9998\n",
      "Epoch 654/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.0210e-04 - accuracy: 0.9999\n",
      "Epoch 655/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.7995e-04 - accuracy: 1.0000\n",
      "Epoch 656/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.8442e-05 - accuracy: 1.0000\n",
      "Epoch 657/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.6010e-08 - accuracy: 1.0000\n",
      "Epoch 658/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.6039e-04 - accuracy: 0.9998\n",
      "Epoch 659/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.5681e-04 - accuracy: 0.9999\n",
      "Epoch 660/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0022 - accuracy: 0.9997\n",
      "Epoch 661/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9999\n",
      "Epoch 662/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.9960e-04 - accuracy: 0.9999\n",
      "Epoch 663/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.7439e-04 - accuracy: 1.0000\n",
      "Epoch 664/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.8040e-04 - accuracy: 1.0000\n",
      "Epoch 665/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.1731e-04 - accuracy: 0.9999\n",
      "Epoch 666/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.6768e-04 - accuracy: 0.9999\n",
      "Epoch 667/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.9974e-04 - accuracy: 1.0000\n",
      "Epoch 668/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.2003e-04 - accuracy: 0.9999\n",
      "Epoch 669/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.1257e-05 - accuracy: 1.0000\n",
      "Epoch 670/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 671/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9998\n",
      "Epoch 672/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.9610e-04 - accuracy: 1.0000\n",
      "Epoch 673/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.9747e-05 - accuracy: 1.0000\n",
      "Epoch 674/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.1766e-04 - accuracy: 1.0000\n",
      "Epoch 675/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.6165e-04 - accuracy: 0.9999\n",
      "Epoch 676/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 677/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 678/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.0466e-04 - accuracy: 0.9999\n",
      "Epoch 679/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.0473e-04 - accuracy: 0.9999\n",
      "Epoch 680/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.4430e-04 - accuracy: 0.9999\n",
      "Epoch 681/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.3316e-05 - accuracy: 1.0000\n",
      "Epoch 682/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.4205e-08 - accuracy: 1.0000\n",
      "Epoch 683/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.6034e-07 - accuracy: 1.0000\n",
      "Epoch 684/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.4659e-08 - accuracy: 1.0000\n",
      "Epoch 685/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.1092e-06 - accuracy: 1.0000\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 7s 18ms/step - loss: 4.9997e-07 - accuracy: 1.0000\n",
      "Epoch 687/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.2914e-07 - accuracy: 1.0000\n",
      "Epoch 688/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.0401e-06 - accuracy: 1.0000\n",
      "Epoch 689/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0025 - accuracy: 0.9997\n",
      "Epoch 690/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9999\n",
      "Epoch 691/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.4800e-05 - accuracy: 1.0000\n",
      "Epoch 692/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.7123e-05 - accuracy: 1.0000\n",
      "Epoch 693/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.2802e-05 - accuracy: 1.0000\n",
      "Epoch 694/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.5759e-05 - accuracy: 1.0000\n",
      "Epoch 695/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.8096e-04 - accuracy: 0.9999\n",
      "Epoch 696/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.2058e-05 - accuracy: 1.0000\n",
      "Epoch 697/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.4951e-05 - accuracy: 0.9999\n",
      "Epoch 698/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.4370e-04 - accuracy: 0.9999\n",
      "Epoch 699/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.8791e-04 - accuracy: 0.9998\n",
      "Epoch 700/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0017 - accuracy: 0.9998\n",
      "Epoch 701/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.7348e-04 - accuracy: 1.0000\n",
      "Epoch 702/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0028 - accuracy: 0.9997\n",
      "Epoch 703/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.8738e-04 - accuracy: 0.9999\n",
      "Epoch 704/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.9584e-04 - accuracy: 0.9999\n",
      "Epoch 705/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.9554e-04 - accuracy: 0.9999\n",
      "Epoch 706/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.6547e-06 - accuracy: 1.0000\n",
      "Epoch 707/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.7223e-04 - accuracy: 0.9999\n",
      "Epoch 708/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.6279e-04 - accuracy: 0.9999\n",
      "Epoch 709/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.2455e-04 - accuracy: 0.9999\n",
      "Epoch 710/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.2408e-04 - accuracy: 1.0000\n",
      "Epoch 711/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.4658e-04 - accuracy: 0.9999\n",
      "Epoch 712/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.9291e-04 - accuracy: 0.9999\n",
      "Epoch 713/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.4158e-04 - accuracy: 1.0000\n",
      "Epoch 714/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.2212e-04 - accuracy: 0.9999\n",
      "Epoch 715/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0023 - accuracy: 0.9998\n",
      "Epoch 716/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 717/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.1850e-05 - accuracy: 1.0000\n",
      "Epoch 718/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.6894e-04 - accuracy: 1.0000\n",
      "Epoch 719/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.7804e-05 - accuracy: 1.0000\n",
      "Epoch 720/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.2620e-04 - accuracy: 1.0000\n",
      "Epoch 721/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.5119e-04 - accuracy: 0.9999\n",
      "Epoch 722/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.0969e-05 - accuracy: 1.0000\n",
      "Epoch 723/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.9793e-08 - accuracy: 1.0000\n",
      "Epoch 724/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.0928e-07 - accuracy: 1.0000\n",
      "Epoch 725/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.4857e-07 - accuracy: 1.0000\n",
      "Epoch 726/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.2264e-07 - accuracy: 1.0000\n",
      "Epoch 727/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.8041e-07 - accuracy: 1.0000\n",
      "Epoch 728/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.9236e-06 - accuracy: 1.0000\n",
      "Epoch 729/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0033 - accuracy: 0.9998\n",
      "Epoch 730/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.1994e-04 - accuracy: 0.9998\n",
      "Epoch 731/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.3943e-04 - accuracy: 0.9999\n",
      "Epoch 732/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.4303e-04 - accuracy: 0.9999\n",
      "Epoch 733/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.1772e-04 - accuracy: 0.9999\n",
      "Epoch 734/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0010 - accuracy: 0.9999\n",
      "Epoch 735/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.0661e-04 - accuracy: 0.9998\n",
      "Epoch 736/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.6272e-04 - accuracy: 0.9999\n",
      "Epoch 737/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.2999e-05 - accuracy: 1.0000\n",
      "Epoch 738/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 739/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.1293e-04 - accuracy: 0.9999\n",
      "Epoch 740/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.3628e-04 - accuracy: 1.0000\n",
      "Epoch 741/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.4499e-08 - accuracy: 1.0000\n",
      "Epoch 742/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.4406e-05 - accuracy: 1.0000\n",
      "Epoch 743/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.3198e-04 - accuracy: 0.9999\n",
      "Epoch 744/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9999\n",
      "Epoch 745/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.0324e-04 - accuracy: 0.9999\n",
      "Epoch 746/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.5767e-05 - accuracy: 1.0000\n",
      "Epoch 747/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.9414e-04 - accuracy: 1.0000\n",
      "Epoch 748/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.1972e-05 - accuracy: 1.0000\n",
      "Epoch 749/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.8206e-07 - accuracy: 1.0000\n",
      "Epoch 750/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.7162e-08 - accuracy: 1.0000\n",
      "Epoch 751/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.4142e-06 - accuracy: 1.0000\n",
      "Epoch 752/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.9527e-06 - accuracy: 1.0000\n",
      "Epoch 753/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0029 - accuracy: 0.9998\n",
      "Epoch 754/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0025 - accuracy: 0.9997\n",
      "Epoch 755/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0017 - accuracy: 0.9998\n",
      "Epoch 756/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.6915e-05 - accuracy: 1.0000\n",
      "Epoch 757/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.1104e-05 - accuracy: 1.0000\n",
      "Epoch 758/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.1238e-05 - accuracy: 1.0000\n",
      "Epoch 759/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.3853e-06 - accuracy: 1.0000\n",
      "Epoch 760/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.6504e-04 - accuracy: 1.0000\n",
      "Epoch 761/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 762/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.9273e-04 - accuracy: 1.0000\n",
      "Epoch 763/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.9320e-04 - accuracy: 1.0000\n",
      "Epoch 764/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9999\n",
      "Epoch 765/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.5674e-04 - accuracy: 0.9999\n",
      "Epoch 766/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0024 - accuracy: 0.9997\n",
      "Epoch 767/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0023 - accuracy: 0.9998\n",
      "Epoch 768/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.2351e-04 - accuracy: 0.9999\n",
      "Epoch 769/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.7515e-04 - accuracy: 0.9999\n",
      "Epoch 770/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.5085e-04 - accuracy: 0.9999\n",
      "Epoch 771/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.7064e-04 - accuracy: 0.9999\n",
      "Epoch 772/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.8778e-04 - accuracy: 0.9999\n",
      "Epoch 773/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9999\n",
      "Epoch 774/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.3203e-04 - accuracy: 1.0000\n",
      "Epoch 775/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.1444e-04 - accuracy: 1.0000\n",
      "Epoch 776/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.3163e-07 - accuracy: 1.0000\n",
      "Epoch 777/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.1740e-07 - accuracy: 1.0000\n",
      "Epoch 778/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.8031e-06 - accuracy: 1.0000\n",
      "Epoch 779/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.0440e-06 - accuracy: 1.0000\n",
      "Epoch 780/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.7145e-09 - accuracy: 1.0000\n",
      "Epoch 781/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.7411e-09 - accuracy: 1.0000\n",
      "Epoch 782/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.4471e-08 - accuracy: 1.0000\n",
      "Epoch 783/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0047 - accuracy: 0.9996\n",
      "Epoch 784/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0028 - accuracy: 0.9997\n",
      "Epoch 785/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.0041e-04 - accuracy: 0.9998\n",
      "Epoch 786/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.4387e-04 - accuracy: 0.9999\n",
      "Epoch 787/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.7071e-04 - accuracy: 1.0000\n",
      "Epoch 788/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.4945e-05 - accuracy: 1.0000\n",
      "Epoch 789/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.0179e-06 - accuracy: 1.0000\n",
      "Epoch 790/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.8703e-07 - accuracy: 1.0000\n",
      "Epoch 791/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.0495e-09 - accuracy: 1.0000\n",
      "Epoch 792/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.0678e-04 - accuracy: 1.0000\n",
      "Epoch 793/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0024 - accuracy: 0.9997\n",
      "Epoch 794/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.0481e-04 - accuracy: 0.9999\n",
      "Epoch 795/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.0010e-04 - accuracy: 0.9999\n",
      "Epoch 796/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.5009e-04 - accuracy: 0.9999\n",
      "Epoch 797/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.9373e-04 - accuracy: 0.9999\n",
      "Epoch 798/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.3448e-04 - accuracy: 0.9999\n",
      "Epoch 799/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0024 - accuracy: 0.9998\n",
      "Epoch 800/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0021 - accuracy: 0.9999\n",
      "Epoch 801/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.8944e-04 - accuracy: 0.9999\n",
      "Epoch 802/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 803/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.4134e-04 - accuracy: 0.9999\n",
      "Epoch 804/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.8538e-05 - accuracy: 1.0000\n",
      "Epoch 805/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.7777e-05 - accuracy: 1.0000\n",
      "Epoch 806/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.9434e-07 - accuracy: 1.0000\n",
      "Epoch 807/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.2169e-08 - accuracy: 1.0000\n",
      "Epoch 808/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.4661e-05 - accuracy: 1.0000\n",
      "Epoch 809/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.0812e-07 - accuracy: 1.0000\n",
      "Epoch 810/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.3117e-08 - accuracy: 1.0000\n",
      "Epoch 811/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.2314e-07 - accuracy: 1.0000\n",
      "Epoch 812/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.7615e-06 - accuracy: 1.0000\n",
      "Epoch 813/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.2704e-10 - accuracy: 1.0000\n",
      "Epoch 814/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.0073e-09 - accuracy: 1.0000\n",
      "Epoch 815/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.8372e-10 - accuracy: 1.0000\n",
      "Epoch 816/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.1243e-09 - accuracy: 1.0000\n",
      "Epoch 817/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.6125e-08 - accuracy: 1.0000\n",
      "Epoch 818/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.7166e-10 - accuracy: 1.0000\n",
      "Epoch 819/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.0994e-10 - accuracy: 1.0000\n",
      "Epoch 820/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.7023e-09 - accuracy: 1.0000\n",
      "Epoch 821/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.5353e-10 - accuracy: 1.0000\n",
      "Epoch 822/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.4067e-10 - accuracy: 1.0000\n",
      "Epoch 823/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.3207e-10 - accuracy: 1.0000\n",
      "Epoch 824/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.3879e-09 - accuracy: 1.0000\n",
      "Epoch 825/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.6928e-10 - accuracy: 1.0000\n",
      "Epoch 826/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.2888e-10 - accuracy: 1.0000\n",
      "Epoch 827/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.3630e-10 - accuracy: 1.0000\n",
      "Epoch 828/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.1975e-10 - accuracy: 1.0000\n",
      "Epoch 829/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.3603e-10 - accuracy: 1.0000\n",
      "Epoch 830/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.2636e-10 - accuracy: 1.0000\n",
      "Epoch 831/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.6318e-08 - accuracy: 1.0000\n",
      "Epoch 832/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.7948e-10 - accuracy: 1.0000\n",
      "Epoch 833/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.0385e-09 - accuracy: 1.0000\n",
      "Epoch 834/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.2673e-09 - accuracy: 1.0000\n",
      "Epoch 835/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.6236e-09 - accuracy: 1.0000\n",
      "Epoch 836/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 7s 18ms/step - loss: 1.6689e-11 - accuracy: 1.0000\n",
      "Epoch 837/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.4611e-10 - accuracy: 1.0000\n",
      "Epoch 838/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.0041e-10 - accuracy: 1.0000\n",
      "Epoch 839/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.5497e-10 - accuracy: 1.0000\n",
      "Epoch 840/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0039 - accuracy: 0.9996\n",
      "Epoch 841/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0030 - accuracy: 0.9996\n",
      "Epoch 842/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.6666e-05 - accuracy: 1.0000\n",
      "Epoch 843/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.3660e-04 - accuracy: 1.0000\n",
      "Epoch 844/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.2509e-04 - accuracy: 1.0000\n",
      "Epoch 845/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.2894e-04 - accuracy: 0.9999\n",
      "Epoch 846/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.9378e-04 - accuracy: 0.9998\n",
      "Epoch 847/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9999\n",
      "Epoch 848/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.4836e-05 - accuracy: 1.0000\n",
      "Epoch 849/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.4958e-04 - accuracy: 0.9999\n",
      "Epoch 850/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.8628e-04 - accuracy: 0.9999\n",
      "Epoch 851/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.6134e-04 - accuracy: 0.9999\n",
      "Epoch 852/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.7546e-05 - accuracy: 1.0000\n",
      "Epoch 853/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.1563e-06 - accuracy: 1.0000\n",
      "Epoch 854/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.4087e-07 - accuracy: 1.0000\n",
      "Epoch 855/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.7721e-05 - accuracy: 1.0000\n",
      "Epoch 856/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.5299e-04 - accuracy: 0.9999\n",
      "Epoch 857/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.7986e-06 - accuracy: 1.0000\n",
      "Epoch 858/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0021 - accuracy: 0.9997\n",
      "Epoch 859/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0025 - accuracy: 0.9997\n",
      "Epoch 860/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.0237e-04 - accuracy: 0.9999\n",
      "Epoch 861/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9999\n",
      "Epoch 862/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.3202e-05 - accuracy: 1.0000\n",
      "Epoch 863/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.4702e-04 - accuracy: 0.9999\n",
      "Epoch 864/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.1467e-04 - accuracy: 1.0000\n",
      "Epoch 865/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.2635e-07 - accuracy: 1.0000\n",
      "Epoch 866/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.0915e-06 - accuracy: 1.0000\n",
      "Epoch 867/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.3629e-08 - accuracy: 1.0000\n",
      "Epoch 868/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.4318e-08 - accuracy: 1.0000\n",
      "Epoch 869/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.4095e-08 - accuracy: 1.0000\n",
      "Epoch 870/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0023 - accuracy: 0.9999\n",
      "Epoch 871/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0020 - accuracy: 0.9998\n",
      "Epoch 872/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.9804e-04 - accuracy: 0.9999\n",
      "Epoch 873/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 874/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9999\n",
      "Epoch 875/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 876/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.7057e-04 - accuracy: 1.0000\n",
      "Epoch 877/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.8286e-04 - accuracy: 0.9999\n",
      "Epoch 878/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.7323e-04 - accuracy: 0.9999\n",
      "Epoch 879/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.8528e-05 - accuracy: 1.0000\n",
      "Epoch 880/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.6034e-06 - accuracy: 1.0000\n",
      "Epoch 881/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.2775e-05 - accuracy: 1.0000\n",
      "Epoch 882/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0013 - accuracy: 0.9999\n",
      "Epoch 883/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.2933e-04 - accuracy: 0.9999\n",
      "Epoch 884/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.3070e-06 - accuracy: 1.0000\n",
      "Epoch 885/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0020 - accuracy: 0.9999\n",
      "Epoch 886/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.2335e-05 - accuracy: 1.0000\n",
      "Epoch 887/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0013 - accuracy: 0.9999\n",
      "Epoch 888/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.6280e-04 - accuracy: 0.9999\n",
      "Epoch 889/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.2664e-05 - accuracy: 1.0000\n",
      "Epoch 890/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.5529e-04 - accuracy: 1.0000\n",
      "Epoch 891/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.3824e-07 - accuracy: 1.0000\n",
      "Epoch 892/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.7805e-06 - accuracy: 1.0000\n",
      "Epoch 893/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.4445e-04 - accuracy: 1.0000\n",
      "Epoch 894/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.0925e-04 - accuracy: 0.9998\n",
      "Epoch 895/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0013 - accuracy: 0.9999\n",
      "Epoch 896/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.6250e-04 - accuracy: 0.9999\n",
      "Epoch 897/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9998\n",
      "Epoch 898/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.4104e-05 - accuracy: 1.0000\n",
      "Epoch 899/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.9648e-04 - accuracy: 0.9999\n",
      "Epoch 900/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.2740e-06 - accuracy: 1.0000\n",
      "Epoch 901/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.1244e-07 - accuracy: 1.0000\n",
      "Epoch 902/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.7813e-05 - accuracy: 1.0000\n",
      "Epoch 903/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.2103e-04 - accuracy: 1.0000\n",
      "Epoch 904/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.0380e-05 - accuracy: 1.0000\n",
      "Epoch 905/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9999\n",
      "Epoch 906/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0032 - accuracy: 0.9997\n",
      "Epoch 907/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9999\n",
      "Epoch 908/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.5167e-04 - accuracy: 0.9999\n",
      "Epoch 909/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.6401e-04 - accuracy: 0.9999\n",
      "Epoch 910/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.1309e-05 - accuracy: 1.0000\n",
      "Epoch 911/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.0270e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 912/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.2776e-07 - accuracy: 1.0000\n",
      "Epoch 913/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.5152e-09 - accuracy: 1.0000\n",
      "Epoch 914/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.4595e-08 - accuracy: 1.0000\n",
      "Epoch 915/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.9296e-04 - accuracy: 1.0000\n",
      "Epoch 916/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.5213e-04 - accuracy: 0.9999\n",
      "Epoch 917/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.2235e-04 - accuracy: 0.9999\n",
      "Epoch 918/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 919/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9999\n",
      "Epoch 920/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.9990e-04 - accuracy: 1.0000\n",
      "Epoch 921/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.0380e-04 - accuracy: 1.0000\n",
      "Epoch 922/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.7549e-04 - accuracy: 0.9999\n",
      "Epoch 923/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.9211e-04 - accuracy: 0.9999\n",
      "Epoch 924/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.0810e-06 - accuracy: 1.0000\n",
      "Epoch 925/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.3245e-05 - accuracy: 1.0000\n",
      "Epoch 926/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.9691e-08 - accuracy: 1.0000\n",
      "Epoch 927/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.0531e-09 - accuracy: 1.0000\n",
      "Epoch 928/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.6427e-09 - accuracy: 1.0000\n",
      "Epoch 929/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.1413e-07 - accuracy: 1.0000\n",
      "Epoch 930/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0018 - accuracy: 0.9999\n",
      "Epoch 931/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 932/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 933/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 934/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.4657e-04 - accuracy: 0.9999\n",
      "Epoch 935/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.9540e-07 - accuracy: 1.0000\n",
      "Epoch 936/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.8066e-06 - accuracy: 1.0000\n",
      "Epoch 937/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.5309e-04 - accuracy: 0.9999\n",
      "Epoch 938/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.7193e-04 - accuracy: 0.9999\n",
      "Epoch 939/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9999\n",
      "Epoch 940/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.7353e-05 - accuracy: 1.0000\n",
      "Epoch 941/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.7477e-07 - accuracy: 1.0000\n",
      "Epoch 942/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.3528e-07 - accuracy: 1.0000\n",
      "Epoch 943/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.9517e-08 - accuracy: 1.0000\n",
      "Epoch 944/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.2855e-08 - accuracy: 1.0000\n",
      "Epoch 945/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0028 - accuracy: 0.9998\n",
      "Epoch 946/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.0303e-04 - accuracy: 1.0000\n",
      "Epoch 947/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.2873e-04 - accuracy: 1.0000\n",
      "Epoch 948/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.3033e-04 - accuracy: 0.9999\n",
      "Epoch 949/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.6051e-05 - accuracy: 1.0000\n",
      "Epoch 950/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0018 - accuracy: 0.9998\n",
      "Epoch 951/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0021 - accuracy: 0.9998\n",
      "Epoch 952/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.6225e-05 - accuracy: 1.0000\n",
      "Epoch 953/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.2184e-05 - accuracy: 1.0000\n",
      "Epoch 954/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.5085e-04 - accuracy: 1.0000\n",
      "Epoch 955/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9999\n",
      "Epoch 956/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.1540e-04 - accuracy: 0.9999\n",
      "Epoch 957/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9999\n",
      "Epoch 958/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.8918e-04 - accuracy: 0.9999\n",
      "Epoch 959/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 9.4979e-04 - accuracy: 0.9999\n",
      "Epoch 960/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.5932e-06 - accuracy: 1.0000\n",
      "Epoch 961/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.2113e-06 - accuracy: 1.0000\n",
      "Epoch 962/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.5902e-06 - accuracy: 1.0000\n",
      "Epoch 963/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.9688e-05 - accuracy: 1.0000\n",
      "Epoch 964/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 4.3947e-04 - accuracy: 0.9999\n",
      "Epoch 965/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.3224e-04 - accuracy: 1.0000\n",
      "Epoch 966/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.6958e-04 - accuracy: 1.0000\n",
      "Epoch 967/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0021 - accuracy: 0.9998\n",
      "Epoch 968/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0033 - accuracy: 0.9998\n",
      "Epoch 969/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9999\n",
      "Epoch 970/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.1252e-07 - accuracy: 1.0000\n",
      "Epoch 971/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 5.9584e-05 - accuracy: 1.0000\n",
      "Epoch 972/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.7670e-04 - accuracy: 0.9999\n",
      "Epoch 973/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.5775e-04 - accuracy: 1.0000\n",
      "Epoch 974/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.2166e-06 - accuracy: 1.0000\n",
      "Epoch 975/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.1119e-06 - accuracy: 1.0000\n",
      "Epoch 976/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.3972e-06 - accuracy: 1.0000\n",
      "Epoch 977/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.8040e-07 - accuracy: 1.0000\n",
      "Epoch 978/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 8.8772e-06 - accuracy: 1.0000\n",
      "Epoch 979/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.0366e-07 - accuracy: 1.0000\n",
      "Epoch 980/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.2045e-04 - accuracy: 1.0000\n",
      "Epoch 981/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.3334e-04 - accuracy: 0.9999\n",
      "Epoch 982/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.5875e-04 - accuracy: 1.0000\n",
      "Epoch 983/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0026 - accuracy: 0.9998\n",
      "Epoch 984/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0015 - accuracy: 0.9998\n",
      "Epoch 985/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.0541e-04 - accuracy: 1.0000\n",
      "Epoch 986/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.1900e-04 - accuracy: 1.0000\n",
      "Epoch 987/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.6411e-06 - accuracy: 1.0000\n",
      "Epoch 988/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.3546e-05 - accuracy: 1.0000\n",
      "Epoch 989/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.2647e-07 - accuracy: 1.0000\n",
      "Epoch 990/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.1498e-05 - accuracy: 1.0000\n",
      "Epoch 991/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0014 - accuracy: 0.9999\n",
      "Epoch 992/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9999\n",
      "Epoch 993/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 7.8513e-04 - accuracy: 0.9999\n",
      "Epoch 994/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 995/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 3.9644e-04 - accuracy: 0.9999\n",
      "Epoch 996/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 1.1163e-06 - accuracy: 1.0000\n",
      "Epoch 997/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.9989e-04 - accuracy: 1.0000\n",
      "Epoch 998/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 6.4194e-05 - accuracy: 1.0000\n",
      "Epoch 999/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0011 - accuracy: 0.9999\n",
      "Epoch 1000/1000\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 2.0099e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2333e64a2e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=128, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c9e0bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 1559</th>\n",
       "      <th>Feature 1560</th>\n",
       "      <th>Feature 1561</th>\n",
       "      <th>Feature 1562</th>\n",
       "      <th>Feature 1563</th>\n",
       "      <th>Feature 1564</th>\n",
       "      <th>Feature 1565</th>\n",
       "      <th>Feature 1566</th>\n",
       "      <th>Feature 1567</th>\n",
       "      <th>Feature 1568</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.955389e-23</td>\n",
       "      <td>-4.232597e-23</td>\n",
       "      <td>-1.371348e-23</td>\n",
       "      <td>-4.941302e-24</td>\n",
       "      <td>4.701897e-24</td>\n",
       "      <td>9.137646e-24</td>\n",
       "      <td>-5.964309e-25</td>\n",
       "      <td>-8.037856e-27</td>\n",
       "      <td>1.607571e-26</td>\n",
       "      <td>1.896144e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.713258e-20</td>\n",
       "      <td>-3.072854e-20</td>\n",
       "      <td>1.208471e-20</td>\n",
       "      <td>8.119634e-22</td>\n",
       "      <td>-4.124326e-21</td>\n",
       "      <td>-2.351743e-22</td>\n",
       "      <td>-1.139683e-23</td>\n",
       "      <td>-1.730485e-24</td>\n",
       "      <td>-1.088523e-24</td>\n",
       "      <td>-1.192788e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.737605e-19</td>\n",
       "      <td>1.010960e-17</td>\n",
       "      <td>1.299321e-20</td>\n",
       "      <td>1.007092e-20</td>\n",
       "      <td>-1.007821e-20</td>\n",
       "      <td>2.289849e-21</td>\n",
       "      <td>-8.811264e-22</td>\n",
       "      <td>2.288049e-22</td>\n",
       "      <td>-6.056319e-23</td>\n",
       "      <td>-1.302198e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.688333e-22</td>\n",
       "      <td>1.262406e-22</td>\n",
       "      <td>-1.204514e-23</td>\n",
       "      <td>-9.310054e-24</td>\n",
       "      <td>-1.898251e-24</td>\n",
       "      <td>-1.192600e-25</td>\n",
       "      <td>-2.870280e-26</td>\n",
       "      <td>-2.612264e-27</td>\n",
       "      <td>-7.700169e-27</td>\n",
       "      <td>-3.745563e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.748979e-21</td>\n",
       "      <td>-1.613074e-21</td>\n",
       "      <td>-3.539335e-21</td>\n",
       "      <td>-6.962758e-20</td>\n",
       "      <td>1.694034e-19</td>\n",
       "      <td>-3.988890e-20</td>\n",
       "      <td>-5.779639e-22</td>\n",
       "      <td>5.424119e-21</td>\n",
       "      <td>1.102504e-22</td>\n",
       "      <td>-2.005880e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.176424e-21</td>\n",
       "      <td>2.125517e-22</td>\n",
       "      <td>-5.571208e-23</td>\n",
       "      <td>1.215935e-22</td>\n",
       "      <td>1.939962e-22</td>\n",
       "      <td>-1.638395e-22</td>\n",
       "      <td>-3.236651e-24</td>\n",
       "      <td>4.809522e-25</td>\n",
       "      <td>-1.347239e-25</td>\n",
       "      <td>5.794320e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.372621e-20</td>\n",
       "      <td>6.099703e-21</td>\n",
       "      <td>-8.780294e-22</td>\n",
       "      <td>-6.306931e-22</td>\n",
       "      <td>-1.059037e-21</td>\n",
       "      <td>6.598977e-23</td>\n",
       "      <td>5.641922e-23</td>\n",
       "      <td>1.521738e-23</td>\n",
       "      <td>5.845244e-25</td>\n",
       "      <td>2.289112e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.796364e-20</td>\n",
       "      <td>-1.969505e-20</td>\n",
       "      <td>-1.698103e-22</td>\n",
       "      <td>2.043203e-22</td>\n",
       "      <td>5.397814e-23</td>\n",
       "      <td>-3.642104e-23</td>\n",
       "      <td>-5.222338e-23</td>\n",
       "      <td>-8.629898e-24</td>\n",
       "      <td>1.129773e-24</td>\n",
       "      <td>-2.509890e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536667e-20</td>\n",
       "      <td>-5.036675e-21</td>\n",
       "      <td>2.582385e-22</td>\n",
       "      <td>1.224506e-22</td>\n",
       "      <td>3.189655e-23</td>\n",
       "      <td>-7.812957e-24</td>\n",
       "      <td>-2.556415e-24</td>\n",
       "      <td>2.959303e-25</td>\n",
       "      <td>1.060729e-25</td>\n",
       "      <td>1.069585e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.705075e-20</td>\n",
       "      <td>5.533117e-21</td>\n",
       "      <td>-7.200016e-22</td>\n",
       "      <td>1.472278e-22</td>\n",
       "      <td>-1.492252e-23</td>\n",
       "      <td>-9.910375e-24</td>\n",
       "      <td>-9.901138e-24</td>\n",
       "      <td>-2.287262e-24</td>\n",
       "      <td>-9.313975e-25</td>\n",
       "      <td>-4.494966e-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1568 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  Feature 6  \\\n",
       "0           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "9995        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9996        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9997        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9998        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9999        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "      Feature 7  Feature 8  Feature 9  Feature 10  ...  Feature 1559  \\\n",
       "0           0.0        0.0        0.0         0.0  ...  1.955389e-23   \n",
       "1           0.0        0.0        0.0         0.0  ... -1.713258e-20   \n",
       "2           0.0        0.0        0.0         0.0  ... -7.737605e-19   \n",
       "3           0.0        0.0        0.0         0.0  ...  1.688333e-22   \n",
       "4           0.0        0.0        0.0         0.0  ... -5.748979e-21   \n",
       "...         ...        ...        ...         ...  ...           ...   \n",
       "9995        0.0        0.0        0.0         0.0  ...  2.176424e-21   \n",
       "9996        0.0        0.0        0.0         0.0  ...  8.372621e-20   \n",
       "9997        0.0        0.0        0.0         0.0  ...  1.796364e-20   \n",
       "9998        0.0        0.0        0.0         0.0  ...  1.536667e-20   \n",
       "9999        0.0        0.0        0.0         0.0  ... -3.705075e-20   \n",
       "\n",
       "      Feature 1560  Feature 1561  Feature 1562  Feature 1563  Feature 1564  \\\n",
       "0    -4.232597e-23 -1.371348e-23 -4.941302e-24  4.701897e-24  9.137646e-24   \n",
       "1    -3.072854e-20  1.208471e-20  8.119634e-22 -4.124326e-21 -2.351743e-22   \n",
       "2     1.010960e-17  1.299321e-20  1.007092e-20 -1.007821e-20  2.289849e-21   \n",
       "3     1.262406e-22 -1.204514e-23 -9.310054e-24 -1.898251e-24 -1.192600e-25   \n",
       "4    -1.613074e-21 -3.539335e-21 -6.962758e-20  1.694034e-19 -3.988890e-20   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "9995  2.125517e-22 -5.571208e-23  1.215935e-22  1.939962e-22 -1.638395e-22   \n",
       "9996  6.099703e-21 -8.780294e-22 -6.306931e-22 -1.059037e-21  6.598977e-23   \n",
       "9997 -1.969505e-20 -1.698103e-22  2.043203e-22  5.397814e-23 -3.642104e-23   \n",
       "9998 -5.036675e-21  2.582385e-22  1.224506e-22  3.189655e-23 -7.812957e-24   \n",
       "9999  5.533117e-21 -7.200016e-22  1.472278e-22 -1.492252e-23 -9.910375e-24   \n",
       "\n",
       "      Feature 1565  Feature 1566  Feature 1567  Feature 1568  \n",
       "0    -5.964309e-25 -8.037856e-27  1.607571e-26  1.896144e-27  \n",
       "1    -1.139683e-23 -1.730485e-24 -1.088523e-24 -1.192788e-25  \n",
       "2    -8.811264e-22  2.288049e-22 -6.056319e-23 -1.302198e-23  \n",
       "3    -2.870280e-26 -2.612264e-27 -7.700169e-27 -3.745563e-27  \n",
       "4    -5.779639e-22  5.424119e-21  1.102504e-22 -2.005880e-22  \n",
       "...            ...           ...           ...           ...  \n",
       "9995 -3.236651e-24  4.809522e-25 -1.347239e-25  5.794320e-26  \n",
       "9996  5.641922e-23  1.521738e-23  5.845244e-25  2.289112e-25  \n",
       "9997 -5.222338e-23 -8.629898e-24  1.129773e-24 -2.509890e-26  \n",
       "9998 -2.556415e-24  2.959303e-25  1.060729e-25  1.069585e-25  \n",
       "9999 -9.901138e-24 -2.287262e-24 -9.313975e-25 -4.494966e-25  \n",
       "\n",
       "[10000 rows x 1568 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_test = df_test.iloc[:,:-1]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34c49477",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.values.reshape(-1,28,56,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b7583ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d28dd900",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f153cec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   0\n",
       "0         0  14\n",
       "1         1   7\n",
       "2         2  10\n",
       "3         3   7\n",
       "4         4   5\n",
       "...     ...  ..\n",
       "9995   9995   7\n",
       "9996   9996  12\n",
       "9997   9997  10\n",
       "9998   9998   4\n",
       "9999   9999   6\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y = pd.DataFrame(y_pred).reset_index()\n",
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed801cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.columns = ['Index', 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66e90134",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.to_csv('pd-cnn-5-submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edefe76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn-c-5-1000-iter\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn-c-5-1000-iter\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('cnn-c-5-1000-iter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def7dda1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7b0ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac6f3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d19cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e910c1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcf56794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 1560</th>\n",
       "      <th>Feature 1561</th>\n",
       "      <th>Feature 1562</th>\n",
       "      <th>Feature 1563</th>\n",
       "      <th>Feature 1564</th>\n",
       "      <th>Feature 1565</th>\n",
       "      <th>Feature 1566</th>\n",
       "      <th>Feature 1567</th>\n",
       "      <th>Feature 1568</th>\n",
       "      <th>Unnamed: 1568</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.854928e-19</td>\n",
       "      <td>-1.329011e-20</td>\n",
       "      <td>4.204335e-21</td>\n",
       "      <td>4.428740e-21</td>\n",
       "      <td>4.461340e-23</td>\n",
       "      <td>2.376798e-24</td>\n",
       "      <td>-7.807106e-24</td>\n",
       "      <td>2.379322e-24</td>\n",
       "      <td>-5.582096e-26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.118652e-20</td>\n",
       "      <td>4.062297e-21</td>\n",
       "      <td>-7.743107e-21</td>\n",
       "      <td>8.638654e-22</td>\n",
       "      <td>-1.006311e-21</td>\n",
       "      <td>-2.267525e-22</td>\n",
       "      <td>-5.867730e-23</td>\n",
       "      <td>4.858047e-24</td>\n",
       "      <td>-4.595498e-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.619224e-20</td>\n",
       "      <td>-3.590984e-20</td>\n",
       "      <td>-2.717642e-20</td>\n",
       "      <td>1.923565e-20</td>\n",
       "      <td>-2.244442e-21</td>\n",
       "      <td>-4.244237e-24</td>\n",
       "      <td>-3.599564e-23</td>\n",
       "      <td>7.471194e-24</td>\n",
       "      <td>-3.815300e-24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.346105e-19</td>\n",
       "      <td>-6.278001e-19</td>\n",
       "      <td>-5.786255e-19</td>\n",
       "      <td>2.573141e-19</td>\n",
       "      <td>2.385063e-19</td>\n",
       "      <td>6.655487e-20</td>\n",
       "      <td>2.834975e-20</td>\n",
       "      <td>3.356577e-21</td>\n",
       "      <td>1.698628e-21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.494150e-20</td>\n",
       "      <td>-1.187973e-20</td>\n",
       "      <td>-1.450941e-21</td>\n",
       "      <td>8.954877e-22</td>\n",
       "      <td>-2.645088e-22</td>\n",
       "      <td>1.365356e-23</td>\n",
       "      <td>8.062470e-24</td>\n",
       "      <td>-1.235689e-24</td>\n",
       "      <td>1.890073e-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1569 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  Feature 6  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   Feature 7  Feature 8  Feature 9  Feature 10  ...  Feature 1560  \\\n",
       "0        0.0        0.0        0.0         0.0  ...  3.854928e-19   \n",
       "1        0.0        0.0        0.0         0.0  ... -7.118652e-20   \n",
       "2        0.0        0.0        0.0         0.0  ... -4.619224e-20   \n",
       "3        0.0        0.0        0.0         0.0  ... -5.346105e-19   \n",
       "4        0.0        0.0        0.0         0.0  ...  5.494150e-20   \n",
       "\n",
       "   Feature 1561  Feature 1562  Feature 1563  Feature 1564  Feature 1565  \\\n",
       "0 -1.329011e-20  4.204335e-21  4.428740e-21  4.461340e-23  2.376798e-24   \n",
       "1  4.062297e-21 -7.743107e-21  8.638654e-22 -1.006311e-21 -2.267525e-22   \n",
       "2 -3.590984e-20 -2.717642e-20  1.923565e-20 -2.244442e-21 -4.244237e-24   \n",
       "3 -6.278001e-19 -5.786255e-19  2.573141e-19  2.385063e-19  6.655487e-20   \n",
       "4 -1.187973e-20 -1.450941e-21  8.954877e-22 -2.645088e-22  1.365356e-23   \n",
       "\n",
       "   Feature 1566  Feature 1567  Feature 1568  Unnamed: 1568  \n",
       "0 -7.807106e-24  2.379322e-24 -5.582096e-26            NaN  \n",
       "1 -5.867730e-23  4.858047e-24 -4.595498e-25            NaN  \n",
       "2 -3.599564e-23  7.471194e-24 -3.815300e-24            NaN  \n",
       "3  2.834975e-20  3.356577e-21  1.698628e-21            NaN  \n",
       "4  8.062470e-24 -1.235689e-24  1.890073e-25            NaN  \n",
       "\n",
       "[5 rows x 1569 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4f70fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Class\n",
       "Index       \n",
       "0          5\n",
       "1          4\n",
       "2          5\n",
       "3          4\n",
       "4          4\n",
       "...      ...\n",
       "49995      9\n",
       "49996     14\n",
       "49997      1\n",
       "49998      7\n",
       "49999      9\n",
       "\n",
       "[50000 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv('data/train_result.csv', index_col=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01b8bbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 1559</th>\n",
       "      <th>Feature 1560</th>\n",
       "      <th>Feature 1561</th>\n",
       "      <th>Feature 1562</th>\n",
       "      <th>Feature 1563</th>\n",
       "      <th>Feature 1564</th>\n",
       "      <th>Feature 1565</th>\n",
       "      <th>Feature 1566</th>\n",
       "      <th>Feature 1567</th>\n",
       "      <th>Feature 1568</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.281934e-19</td>\n",
       "      <td>3.854928e-19</td>\n",
       "      <td>-1.329011e-20</td>\n",
       "      <td>4.204335e-21</td>\n",
       "      <td>4.428740e-21</td>\n",
       "      <td>4.461340e-23</td>\n",
       "      <td>2.376798e-24</td>\n",
       "      <td>-7.807106e-24</td>\n",
       "      <td>2.379322e-24</td>\n",
       "      <td>-5.582096e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.714815e-19</td>\n",
       "      <td>-7.118652e-20</td>\n",
       "      <td>4.062297e-21</td>\n",
       "      <td>-7.743107e-21</td>\n",
       "      <td>8.638654e-22</td>\n",
       "      <td>-1.006311e-21</td>\n",
       "      <td>-2.267525e-22</td>\n",
       "      <td>-5.867730e-23</td>\n",
       "      <td>4.858047e-24</td>\n",
       "      <td>-4.595498e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.968480e-20</td>\n",
       "      <td>-4.619224e-20</td>\n",
       "      <td>-3.590984e-20</td>\n",
       "      <td>-2.717642e-20</td>\n",
       "      <td>1.923565e-20</td>\n",
       "      <td>-2.244442e-21</td>\n",
       "      <td>-4.244237e-24</td>\n",
       "      <td>-3.599564e-23</td>\n",
       "      <td>7.471194e-24</td>\n",
       "      <td>-3.815300e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.256463e-20</td>\n",
       "      <td>-5.346105e-19</td>\n",
       "      <td>-6.278001e-19</td>\n",
       "      <td>-5.786255e-19</td>\n",
       "      <td>2.573141e-19</td>\n",
       "      <td>2.385063e-19</td>\n",
       "      <td>6.655487e-20</td>\n",
       "      <td>2.834975e-20</td>\n",
       "      <td>3.356577e-21</td>\n",
       "      <td>1.698628e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.446271e-19</td>\n",
       "      <td>5.494150e-20</td>\n",
       "      <td>-1.187973e-20</td>\n",
       "      <td>-1.450941e-21</td>\n",
       "      <td>8.954877e-22</td>\n",
       "      <td>-2.645088e-22</td>\n",
       "      <td>1.365356e-23</td>\n",
       "      <td>8.062470e-24</td>\n",
       "      <td>-1.235689e-24</td>\n",
       "      <td>1.890073e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.806037e-19</td>\n",
       "      <td>-9.956413e-22</td>\n",
       "      <td>7.012638e-21</td>\n",
       "      <td>-1.749799e-21</td>\n",
       "      <td>-5.296019e-22</td>\n",
       "      <td>5.324962e-23</td>\n",
       "      <td>-7.651382e-24</td>\n",
       "      <td>-1.189074e-23</td>\n",
       "      <td>-3.929069e-24</td>\n",
       "      <td>1.550829e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.120559e-21</td>\n",
       "      <td>-2.386547e-22</td>\n",
       "      <td>3.369363e-23</td>\n",
       "      <td>1.459011e-23</td>\n",
       "      <td>5.123315e-25</td>\n",
       "      <td>-5.553792e-25</td>\n",
       "      <td>-1.656932e-25</td>\n",
       "      <td>-4.579053e-26</td>\n",
       "      <td>5.280697e-26</td>\n",
       "      <td>1.550841e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.683112e-18</td>\n",
       "      <td>-1.566546e-20</td>\n",
       "      <td>6.858092e-21</td>\n",
       "      <td>1.256228e-21</td>\n",
       "      <td>-3.157088e-22</td>\n",
       "      <td>1.984213e-23</td>\n",
       "      <td>1.134711e-23</td>\n",
       "      <td>-3.192012e-24</td>\n",
       "      <td>1.801697e-25</td>\n",
       "      <td>-1.020857e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.349202e-20</td>\n",
       "      <td>-1.839305e-21</td>\n",
       "      <td>3.174579e-20</td>\n",
       "      <td>7.510705e-21</td>\n",
       "      <td>-1.584091e-21</td>\n",
       "      <td>9.770302e-23</td>\n",
       "      <td>1.247588e-22</td>\n",
       "      <td>5.449431e-24</td>\n",
       "      <td>2.336028e-24</td>\n",
       "      <td>2.577251e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.295327e-17</td>\n",
       "      <td>9.899082e-17</td>\n",
       "      <td>8.549260e-17</td>\n",
       "      <td>1.099950e-18</td>\n",
       "      <td>-8.754949e-19</td>\n",
       "      <td>1.678472e-20</td>\n",
       "      <td>-1.834816e-20</td>\n",
       "      <td>-1.115471e-20</td>\n",
       "      <td>-4.795634e-21</td>\n",
       "      <td>-1.559397e-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1568 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  Feature 6  \\\n",
       "0            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "49995        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "49996        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "49997        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "49998        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "49999        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "       Feature 7  Feature 8  Feature 9  Feature 10  ...  Feature 1559  \\\n",
       "0            0.0        0.0        0.0         0.0  ... -1.281934e-19   \n",
       "1            0.0        0.0        0.0         0.0  ... -4.714815e-19   \n",
       "2            0.0        0.0        0.0         0.0  ... -3.968480e-20   \n",
       "3            0.0        0.0        0.0         0.0  ...  4.256463e-20   \n",
       "4            0.0        0.0        0.0         0.0  ... -9.446271e-19   \n",
       "...          ...        ...        ...         ...  ...           ...   \n",
       "49995        0.0        0.0        0.0         0.0  ... -2.806037e-19   \n",
       "49996        0.0        0.0        0.0         0.0  ...  1.120559e-21   \n",
       "49997        0.0        0.0        0.0         0.0  ...  2.683112e-18   \n",
       "49998        0.0        0.0        0.0         0.0  ...  4.349202e-20   \n",
       "49999        0.0        0.0        0.0         0.0  ...  8.295327e-17   \n",
       "\n",
       "       Feature 1560  Feature 1561  Feature 1562  Feature 1563  Feature 1564  \\\n",
       "0      3.854928e-19 -1.329011e-20  4.204335e-21  4.428740e-21  4.461340e-23   \n",
       "1     -7.118652e-20  4.062297e-21 -7.743107e-21  8.638654e-22 -1.006311e-21   \n",
       "2     -4.619224e-20 -3.590984e-20 -2.717642e-20  1.923565e-20 -2.244442e-21   \n",
       "3     -5.346105e-19 -6.278001e-19 -5.786255e-19  2.573141e-19  2.385063e-19   \n",
       "4      5.494150e-20 -1.187973e-20 -1.450941e-21  8.954877e-22 -2.645088e-22   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "49995 -9.956413e-22  7.012638e-21 -1.749799e-21 -5.296019e-22  5.324962e-23   \n",
       "49996 -2.386547e-22  3.369363e-23  1.459011e-23  5.123315e-25 -5.553792e-25   \n",
       "49997 -1.566546e-20  6.858092e-21  1.256228e-21 -3.157088e-22  1.984213e-23   \n",
       "49998 -1.839305e-21  3.174579e-20  7.510705e-21 -1.584091e-21  9.770302e-23   \n",
       "49999  9.899082e-17  8.549260e-17  1.099950e-18 -8.754949e-19  1.678472e-20   \n",
       "\n",
       "       Feature 1565  Feature 1566  Feature 1567  Feature 1568  \n",
       "0      2.376798e-24 -7.807106e-24  2.379322e-24 -5.582096e-26  \n",
       "1     -2.267525e-22 -5.867730e-23  4.858047e-24 -4.595498e-25  \n",
       "2     -4.244237e-24 -3.599564e-23  7.471194e-24 -3.815300e-24  \n",
       "3      6.655487e-20  2.834975e-20  3.356577e-21  1.698628e-21  \n",
       "4      1.365356e-23  8.062470e-24 -1.235689e-24  1.890073e-25  \n",
       "...             ...           ...           ...           ...  \n",
       "49995 -7.651382e-24 -1.189074e-23 -3.929069e-24  1.550829e-24  \n",
       "49996 -1.656932e-25 -4.579053e-26  5.280697e-26  1.550841e-26  \n",
       "49997  1.134711e-23 -3.192012e-24  1.801697e-25 -1.020857e-26  \n",
       "49998  1.247588e-22  5.449431e-24  2.336028e-24  2.577251e-24  \n",
       "49999 -1.834816e-20 -1.115471e-20 -4.795634e-21 -1.559397e-22  \n",
       "\n",
       "[50000 rows x 1568 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b8edf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c2a585b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 1559</th>\n",
       "      <th>Feature 1560</th>\n",
       "      <th>Feature 1561</th>\n",
       "      <th>Feature 1562</th>\n",
       "      <th>Feature 1563</th>\n",
       "      <th>Feature 1564</th>\n",
       "      <th>Feature 1565</th>\n",
       "      <th>Feature 1566</th>\n",
       "      <th>Feature 1567</th>\n",
       "      <th>Feature 1568</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.281934e-19</td>\n",
       "      <td>3.854928e-19</td>\n",
       "      <td>-1.329011e-20</td>\n",
       "      <td>4.204335e-21</td>\n",
       "      <td>4.428740e-21</td>\n",
       "      <td>4.461340e-23</td>\n",
       "      <td>2.376798e-24</td>\n",
       "      <td>-7.807106e-24</td>\n",
       "      <td>2.379322e-24</td>\n",
       "      <td>-5.582096e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.714815e-19</td>\n",
       "      <td>-7.118652e-20</td>\n",
       "      <td>4.062297e-21</td>\n",
       "      <td>-7.743107e-21</td>\n",
       "      <td>8.638654e-22</td>\n",
       "      <td>-1.006311e-21</td>\n",
       "      <td>-2.267525e-22</td>\n",
       "      <td>-5.867730e-23</td>\n",
       "      <td>4.858047e-24</td>\n",
       "      <td>-4.595498e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.968480e-20</td>\n",
       "      <td>-4.619224e-20</td>\n",
       "      <td>-3.590984e-20</td>\n",
       "      <td>-2.717642e-20</td>\n",
       "      <td>1.923565e-20</td>\n",
       "      <td>-2.244442e-21</td>\n",
       "      <td>-4.244237e-24</td>\n",
       "      <td>-3.599564e-23</td>\n",
       "      <td>7.471194e-24</td>\n",
       "      <td>-3.815300e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.256463e-20</td>\n",
       "      <td>-5.346105e-19</td>\n",
       "      <td>-6.278001e-19</td>\n",
       "      <td>-5.786255e-19</td>\n",
       "      <td>2.573141e-19</td>\n",
       "      <td>2.385063e-19</td>\n",
       "      <td>6.655487e-20</td>\n",
       "      <td>2.834975e-20</td>\n",
       "      <td>3.356577e-21</td>\n",
       "      <td>1.698628e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.446271e-19</td>\n",
       "      <td>5.494150e-20</td>\n",
       "      <td>-1.187973e-20</td>\n",
       "      <td>-1.450941e-21</td>\n",
       "      <td>8.954877e-22</td>\n",
       "      <td>-2.645088e-22</td>\n",
       "      <td>1.365356e-23</td>\n",
       "      <td>8.062470e-24</td>\n",
       "      <td>-1.235689e-24</td>\n",
       "      <td>1.890073e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.806037e-19</td>\n",
       "      <td>-9.956413e-22</td>\n",
       "      <td>7.012638e-21</td>\n",
       "      <td>-1.749799e-21</td>\n",
       "      <td>-5.296019e-22</td>\n",
       "      <td>5.324962e-23</td>\n",
       "      <td>-7.651382e-24</td>\n",
       "      <td>-1.189074e-23</td>\n",
       "      <td>-3.929069e-24</td>\n",
       "      <td>1.550829e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.120559e-21</td>\n",
       "      <td>-2.386547e-22</td>\n",
       "      <td>3.369363e-23</td>\n",
       "      <td>1.459011e-23</td>\n",
       "      <td>5.123315e-25</td>\n",
       "      <td>-5.553792e-25</td>\n",
       "      <td>-1.656932e-25</td>\n",
       "      <td>-4.579053e-26</td>\n",
       "      <td>5.280697e-26</td>\n",
       "      <td>1.550841e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.683112e-18</td>\n",
       "      <td>-1.566546e-20</td>\n",
       "      <td>6.858092e-21</td>\n",
       "      <td>1.256228e-21</td>\n",
       "      <td>-3.157088e-22</td>\n",
       "      <td>1.984213e-23</td>\n",
       "      <td>1.134711e-23</td>\n",
       "      <td>-3.192012e-24</td>\n",
       "      <td>1.801697e-25</td>\n",
       "      <td>-1.020857e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.349202e-20</td>\n",
       "      <td>-1.839305e-21</td>\n",
       "      <td>3.174579e-20</td>\n",
       "      <td>7.510705e-21</td>\n",
       "      <td>-1.584091e-21</td>\n",
       "      <td>9.770302e-23</td>\n",
       "      <td>1.247588e-22</td>\n",
       "      <td>5.449431e-24</td>\n",
       "      <td>2.336028e-24</td>\n",
       "      <td>2.577251e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.295327e-17</td>\n",
       "      <td>9.899082e-17</td>\n",
       "      <td>8.549260e-17</td>\n",
       "      <td>1.099950e-18</td>\n",
       "      <td>-8.754949e-19</td>\n",
       "      <td>1.678472e-20</td>\n",
       "      <td>-1.834816e-20</td>\n",
       "      <td>-1.115471e-20</td>\n",
       "      <td>-4.795634e-21</td>\n",
       "      <td>-1.559397e-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1568 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  Feature 6  \\\n",
       "0            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "49995        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "49996        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "49997        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "49998        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "49999        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "       Feature 7  Feature 8  Feature 9  Feature 10  ...  Feature 1559  \\\n",
       "0            0.0        0.0        0.0         0.0  ... -1.281934e-19   \n",
       "1            0.0        0.0        0.0         0.0  ... -4.714815e-19   \n",
       "2            0.0        0.0        0.0         0.0  ... -3.968480e-20   \n",
       "3            0.0        0.0        0.0         0.0  ...  4.256463e-20   \n",
       "4            0.0        0.0        0.0         0.0  ... -9.446271e-19   \n",
       "...          ...        ...        ...         ...  ...           ...   \n",
       "49995        0.0        0.0        0.0         0.0  ... -2.806037e-19   \n",
       "49996        0.0        0.0        0.0         0.0  ...  1.120559e-21   \n",
       "49997        0.0        0.0        0.0         0.0  ...  2.683112e-18   \n",
       "49998        0.0        0.0        0.0         0.0  ...  4.349202e-20   \n",
       "49999        0.0        0.0        0.0         0.0  ...  8.295327e-17   \n",
       "\n",
       "       Feature 1560  Feature 1561  Feature 1562  Feature 1563  Feature 1564  \\\n",
       "0      3.854928e-19 -1.329011e-20  4.204335e-21  4.428740e-21  4.461340e-23   \n",
       "1     -7.118652e-20  4.062297e-21 -7.743107e-21  8.638654e-22 -1.006311e-21   \n",
       "2     -4.619224e-20 -3.590984e-20 -2.717642e-20  1.923565e-20 -2.244442e-21   \n",
       "3     -5.346105e-19 -6.278001e-19 -5.786255e-19  2.573141e-19  2.385063e-19   \n",
       "4      5.494150e-20 -1.187973e-20 -1.450941e-21  8.954877e-22 -2.645088e-22   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "49995 -9.956413e-22  7.012638e-21 -1.749799e-21 -5.296019e-22  5.324962e-23   \n",
       "49996 -2.386547e-22  3.369363e-23  1.459011e-23  5.123315e-25 -5.553792e-25   \n",
       "49997 -1.566546e-20  6.858092e-21  1.256228e-21 -3.157088e-22  1.984213e-23   \n",
       "49998 -1.839305e-21  3.174579e-20  7.510705e-21 -1.584091e-21  9.770302e-23   \n",
       "49999  9.899082e-17  8.549260e-17  1.099950e-18 -8.754949e-19  1.678472e-20   \n",
       "\n",
       "       Feature 1565  Feature 1566  Feature 1567  Feature 1568  \n",
       "0      2.376798e-24 -7.807106e-24  2.379322e-24 -5.582096e-26  \n",
       "1     -2.267525e-22 -5.867730e-23  4.858047e-24 -4.595498e-25  \n",
       "2     -4.244237e-24 -3.599564e-23  7.471194e-24 -3.815300e-24  \n",
       "3      6.655487e-20  2.834975e-20  3.356577e-21  1.698628e-21  \n",
       "4      1.365356e-23  8.062470e-24 -1.235689e-24  1.890073e-25  \n",
       "...             ...           ...           ...           ...  \n",
       "49995 -7.651382e-24 -1.189074e-23 -3.929069e-24  1.550829e-24  \n",
       "49996 -1.656932e-25 -4.579053e-26  5.280697e-26  1.550841e-26  \n",
       "49997  1.134711e-23 -3.192012e-24  1.801697e-25 -1.020857e-26  \n",
       "49998  1.247588e-22  5.449431e-24  2.336028e-24  2.577251e-24  \n",
       "49999 -1.834816e-20 -1.115471e-20 -4.795634e-21 -1.559397e-22  \n",
       "\n",
       "[50000 rows x 1568 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2f2e3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.37591740e-21],\n",
       "         [ 5.30417960e-22],\n",
       "         [-3.57824900e-24]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.48994830e-21],\n",
       "         [ 6.31696440e-22],\n",
       "         [-3.58053030e-22]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.00505800e-21],\n",
       "         [ 1.07208180e-21],\n",
       "         [-2.05822040e-21]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.86626740e-23],\n",
       "         [-7.54684500e-24],\n",
       "         [-2.40440590e-23]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.71384430e-23],\n",
       "         [-2.84402220e-24],\n",
       "         [ 4.41500800e-25]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-7.80710550e-24],\n",
       "         [ 2.37932200e-24],\n",
       "         [-5.58209600e-26]]],\n",
       "\n",
       "\n",
       "       [[[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 3.27461340e-25],\n",
       "         [ 1.07634440e-25],\n",
       "         [-9.88395400e-26]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-8.87620800e-25],\n",
       "         [-2.92710000e-25],\n",
       "         [-2.16285940e-25]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.21094440e-25],\n",
       "         [-8.62574300e-25],\n",
       "         [-2.89712300e-25]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-1.01158940e-21],\n",
       "         [-3.26014200e-22],\n",
       "         [ 1.12037020e-22]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.61687560e-22],\n",
       "         [ 1.08058660e-23],\n",
       "         [ 2.33908320e-23]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-5.86773040e-23],\n",
       "         [ 4.85804650e-24],\n",
       "         [-4.59549800e-25]]],\n",
       "\n",
       "\n",
       "       [[[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.01568520e-24],\n",
       "         [-2.21912860e-25],\n",
       "         [-1.28033780e-25]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.93806880e-26],\n",
       "         [-1.16200960e-24],\n",
       "         [-6.89255140e-25]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 6.32483370e-23],\n",
       "         [-7.65216870e-25],\n",
       "         [-6.30463350e-25]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 4.40460400e-22],\n",
       "         [ 3.78048100e-22],\n",
       "         [ 1.02063820e-22]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.82695610e-22],\n",
       "         [ 8.89086300e-23],\n",
       "         [ 2.67230670e-23]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.59956400e-23],\n",
       "         [ 7.47119360e-24],\n",
       "         [-3.81529970e-24]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-2.72341040e-26],\n",
       "         [-3.49097880e-27],\n",
       "         [ 4.04444570e-28]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-2.48399260e-26],\n",
       "         [ 3.63561880e-27],\n",
       "         [ 3.83510200e-27]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.50423720e-25],\n",
       "         [ 1.25764650e-26],\n",
       "         [-3.96775370e-28]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.98952120e-23],\n",
       "         [ 1.01063370e-23],\n",
       "         [ 1.32246810e-23]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.15221730e-23],\n",
       "         [ 7.35454100e-24],\n",
       "         [ 3.31382680e-24]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.19201230e-24],\n",
       "         [ 1.80169730e-25],\n",
       "         [-1.02085740e-26]]],\n",
       "\n",
       "\n",
       "       [[[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.32780230e-24],\n",
       "         [ 1.03126220e-24],\n",
       "         [-4.22012600e-26]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.91623280e-24],\n",
       "         [-3.76451400e-24],\n",
       "         [-1.09306650e-24]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-1.13043965e-23],\n",
       "         [ 1.10209680e-24],\n",
       "         [ 2.78564240e-25]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.42552370e-23],\n",
       "         [-9.72694700e-25],\n",
       "         [-3.63002400e-23]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.11643540e-23],\n",
       "         [ 9.59594150e-24],\n",
       "         [-3.78250980e-23]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 5.44943100e-24],\n",
       "         [ 2.33602780e-24],\n",
       "         [ 2.57725080e-24]]],\n",
       "\n",
       "\n",
       "       [[[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.60686140e-26],\n",
       "         [-1.65943130e-26],\n",
       "         [ 1.53454600e-27]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-1.40309690e-24],\n",
       "         [-1.92335910e-25],\n",
       "         [ 2.69408330e-26]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.26709840e-24],\n",
       "         [-6.00235830e-25],\n",
       "         [-1.88249930e-26]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.59503440e-20],\n",
       "         [ 2.23094200e-20],\n",
       "         [-5.94482500e-20]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 5.97874640e-20],\n",
       "         [ 5.78594870e-21],\n",
       "         [ 3.81944540e-20]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-1.11547100e-20],\n",
       "         [-4.79563400e-21],\n",
       "         [-1.55939740e-22]]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.values.reshape((-1,28,56,1))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "053d2fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8ea7231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 56, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f44e89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 19)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2e4efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f54beab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE MORE IMAGES VIA DATA AUGMENTATION\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,  \n",
    "        zoom_range = 0.10,  \n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d1c7a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD CONVOLUTIONAL NEURAL NETWORKS\n",
    "nets = 15\n",
    "model = [0] *nets\n",
    "for j in range(nets):\n",
    "    model[j] = Sequential()\n",
    "\n",
    "    model[j].add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 56, 1)))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Dropout(0.4))\n",
    "\n",
    "    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Dropout(0.4))\n",
    "\n",
    "    model[j].add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Flatten())\n",
    "    model[j].add(Dropout(0.4))\n",
    "    model[j].add(Dense(19, activation='softmax'))\n",
    "    \n",
    "    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "51e3862f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikas\\AppData\\Local\\Temp\\ipykernel_10728\\3199650850.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history[j] = model[j].fit_generator(datagen.flow(X_train2,Y_train2, batch_size=64),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN 1: Epochs=45, Train accuracy=0.97594, Validation accuracy=0.99500\n",
      "CNN 2: Epochs=45, Train accuracy=0.97436, Validation accuracy=0.99240\n",
      "CNN 3: Epochs=45, Train accuracy=0.97447, Validation accuracy=0.99260\n",
      "CNN 4: Epochs=45, Train accuracy=0.97514, Validation accuracy=0.99240\n",
      "CNN 5: Epochs=45, Train accuracy=0.97554, Validation accuracy=0.99420\n",
      "CNN 6: Epochs=45, Train accuracy=0.97639, Validation accuracy=0.99280\n",
      "CNN 7: Epochs=45, Train accuracy=0.97528, Validation accuracy=0.99300\n",
      "CNN 8: Epochs=45, Train accuracy=0.97503, Validation accuracy=0.99200\n",
      "CNN 9: Epochs=45, Train accuracy=0.97626, Validation accuracy=0.99500\n",
      "CNN 10: Epochs=45, Train accuracy=0.97439, Validation accuracy=0.99340\n",
      "CNN 11: Epochs=45, Train accuracy=0.97579, Validation accuracy=0.99340\n",
      "CNN 12: Epochs=45, Train accuracy=0.97450, Validation accuracy=0.99360\n",
      "CNN 13: Epochs=45, Train accuracy=0.97541, Validation accuracy=0.99400\n",
      "CNN 14: Epochs=45, Train accuracy=0.97641, Validation accuracy=0.99500\n",
      "CNN 15: Epochs=45, Train accuracy=0.97541, Validation accuracy=0.99380\n"
     ]
    }
   ],
   "source": [
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
    "# TRAIN NETWORKS\n",
    "history = [0] * nets\n",
    "epochs = 45\n",
    "for j in range(nets):\n",
    "    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X, y, test_size = 0.1)\n",
    "    history[j] = model[j].fit_generator(datagen.flow(X_train2,Y_train2, batch_size=64),\n",
    "        epochs = epochs, steps_per_epoch = X_train2.shape[0]//64,  \n",
    "        validation_data = (X_val2,Y_val2), callbacks=[annealer], verbose=0)\n",
    "    print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n",
    "        j+1,epochs,max(history[j].history['accuracy']),max(history[j].history['val_accuracy']) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d4df60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.callbacks.History at 0x23364575c70>,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = np.zeros( (X_test.shape[0],19) ) \n",
    "for j in range(nets):\n",
    "    results = results + model[j].predict(X_test)\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "submission.to_csv(\"MNIST-CNN-ENSEMBLE.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31154958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 1559</th>\n",
       "      <th>Feature 1560</th>\n",
       "      <th>Feature 1561</th>\n",
       "      <th>Feature 1562</th>\n",
       "      <th>Feature 1563</th>\n",
       "      <th>Feature 1564</th>\n",
       "      <th>Feature 1565</th>\n",
       "      <th>Feature 1566</th>\n",
       "      <th>Feature 1567</th>\n",
       "      <th>Feature 1568</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.955389e-23</td>\n",
       "      <td>-4.232597e-23</td>\n",
       "      <td>-1.371348e-23</td>\n",
       "      <td>-4.941302e-24</td>\n",
       "      <td>4.701897e-24</td>\n",
       "      <td>9.137646e-24</td>\n",
       "      <td>-5.964309e-25</td>\n",
       "      <td>-8.037856e-27</td>\n",
       "      <td>1.607571e-26</td>\n",
       "      <td>1.896144e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.713258e-20</td>\n",
       "      <td>-3.072854e-20</td>\n",
       "      <td>1.208471e-20</td>\n",
       "      <td>8.119634e-22</td>\n",
       "      <td>-4.124326e-21</td>\n",
       "      <td>-2.351743e-22</td>\n",
       "      <td>-1.139683e-23</td>\n",
       "      <td>-1.730485e-24</td>\n",
       "      <td>-1.088523e-24</td>\n",
       "      <td>-1.192788e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.737605e-19</td>\n",
       "      <td>1.010960e-17</td>\n",
       "      <td>1.299321e-20</td>\n",
       "      <td>1.007092e-20</td>\n",
       "      <td>-1.007821e-20</td>\n",
       "      <td>2.289849e-21</td>\n",
       "      <td>-8.811264e-22</td>\n",
       "      <td>2.288049e-22</td>\n",
       "      <td>-6.056319e-23</td>\n",
       "      <td>-1.302198e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.688333e-22</td>\n",
       "      <td>1.262406e-22</td>\n",
       "      <td>-1.204514e-23</td>\n",
       "      <td>-9.310054e-24</td>\n",
       "      <td>-1.898251e-24</td>\n",
       "      <td>-1.192600e-25</td>\n",
       "      <td>-2.870280e-26</td>\n",
       "      <td>-2.612264e-27</td>\n",
       "      <td>-7.700169e-27</td>\n",
       "      <td>-3.745563e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.748979e-21</td>\n",
       "      <td>-1.613074e-21</td>\n",
       "      <td>-3.539335e-21</td>\n",
       "      <td>-6.962758e-20</td>\n",
       "      <td>1.694034e-19</td>\n",
       "      <td>-3.988890e-20</td>\n",
       "      <td>-5.779639e-22</td>\n",
       "      <td>5.424119e-21</td>\n",
       "      <td>1.102504e-22</td>\n",
       "      <td>-2.005880e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.176424e-21</td>\n",
       "      <td>2.125517e-22</td>\n",
       "      <td>-5.571208e-23</td>\n",
       "      <td>1.215935e-22</td>\n",
       "      <td>1.939962e-22</td>\n",
       "      <td>-1.638395e-22</td>\n",
       "      <td>-3.236651e-24</td>\n",
       "      <td>4.809522e-25</td>\n",
       "      <td>-1.347239e-25</td>\n",
       "      <td>5.794320e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.372621e-20</td>\n",
       "      <td>6.099703e-21</td>\n",
       "      <td>-8.780294e-22</td>\n",
       "      <td>-6.306931e-22</td>\n",
       "      <td>-1.059037e-21</td>\n",
       "      <td>6.598977e-23</td>\n",
       "      <td>5.641922e-23</td>\n",
       "      <td>1.521738e-23</td>\n",
       "      <td>5.845244e-25</td>\n",
       "      <td>2.289112e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.796364e-20</td>\n",
       "      <td>-1.969505e-20</td>\n",
       "      <td>-1.698103e-22</td>\n",
       "      <td>2.043203e-22</td>\n",
       "      <td>5.397814e-23</td>\n",
       "      <td>-3.642104e-23</td>\n",
       "      <td>-5.222338e-23</td>\n",
       "      <td>-8.629898e-24</td>\n",
       "      <td>1.129773e-24</td>\n",
       "      <td>-2.509890e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536667e-20</td>\n",
       "      <td>-5.036675e-21</td>\n",
       "      <td>2.582385e-22</td>\n",
       "      <td>1.224506e-22</td>\n",
       "      <td>3.189655e-23</td>\n",
       "      <td>-7.812957e-24</td>\n",
       "      <td>-2.556415e-24</td>\n",
       "      <td>2.959303e-25</td>\n",
       "      <td>1.060729e-25</td>\n",
       "      <td>1.069585e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.705075e-20</td>\n",
       "      <td>5.533117e-21</td>\n",
       "      <td>-7.200016e-22</td>\n",
       "      <td>1.472278e-22</td>\n",
       "      <td>-1.492252e-23</td>\n",
       "      <td>-9.910375e-24</td>\n",
       "      <td>-9.901138e-24</td>\n",
       "      <td>-2.287262e-24</td>\n",
       "      <td>-9.313975e-25</td>\n",
       "      <td>-4.494966e-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1568 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  Feature 6  \\\n",
       "0           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "9995        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9996        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9997        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9998        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9999        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "      Feature 7  Feature 8  Feature 9  Feature 10  ...  Feature 1559  \\\n",
       "0           0.0        0.0        0.0         0.0  ...  1.955389e-23   \n",
       "1           0.0        0.0        0.0         0.0  ... -1.713258e-20   \n",
       "2           0.0        0.0        0.0         0.0  ... -7.737605e-19   \n",
       "3           0.0        0.0        0.0         0.0  ...  1.688333e-22   \n",
       "4           0.0        0.0        0.0         0.0  ... -5.748979e-21   \n",
       "...         ...        ...        ...         ...  ...           ...   \n",
       "9995        0.0        0.0        0.0         0.0  ...  2.176424e-21   \n",
       "9996        0.0        0.0        0.0         0.0  ...  8.372621e-20   \n",
       "9997        0.0        0.0        0.0         0.0  ...  1.796364e-20   \n",
       "9998        0.0        0.0        0.0         0.0  ...  1.536667e-20   \n",
       "9999        0.0        0.0        0.0         0.0  ... -3.705075e-20   \n",
       "\n",
       "      Feature 1560  Feature 1561  Feature 1562  Feature 1563  Feature 1564  \\\n",
       "0    -4.232597e-23 -1.371348e-23 -4.941302e-24  4.701897e-24  9.137646e-24   \n",
       "1    -3.072854e-20  1.208471e-20  8.119634e-22 -4.124326e-21 -2.351743e-22   \n",
       "2     1.010960e-17  1.299321e-20  1.007092e-20 -1.007821e-20  2.289849e-21   \n",
       "3     1.262406e-22 -1.204514e-23 -9.310054e-24 -1.898251e-24 -1.192600e-25   \n",
       "4    -1.613074e-21 -3.539335e-21 -6.962758e-20  1.694034e-19 -3.988890e-20   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "9995  2.125517e-22 -5.571208e-23  1.215935e-22  1.939962e-22 -1.638395e-22   \n",
       "9996  6.099703e-21 -8.780294e-22 -6.306931e-22 -1.059037e-21  6.598977e-23   \n",
       "9997 -1.969505e-20 -1.698103e-22  2.043203e-22  5.397814e-23 -3.642104e-23   \n",
       "9998 -5.036675e-21  2.582385e-22  1.224506e-22  3.189655e-23 -7.812957e-24   \n",
       "9999  5.533117e-21 -7.200016e-22  1.472278e-22 -1.492252e-23 -9.910375e-24   \n",
       "\n",
       "      Feature 1565  Feature 1566  Feature 1567  Feature 1568  \n",
       "0    -5.964309e-25 -8.037856e-27  1.607571e-26  1.896144e-27  \n",
       "1    -1.139683e-23 -1.730485e-24 -1.088523e-24 -1.192788e-25  \n",
       "2    -8.811264e-22  2.288049e-22 -6.056319e-23 -1.302198e-23  \n",
       "3    -2.870280e-26 -2.612264e-27 -7.700169e-27 -3.745563e-27  \n",
       "4    -5.779639e-22  5.424119e-21  1.102504e-22 -2.005880e-22  \n",
       "...            ...           ...           ...           ...  \n",
       "9995 -3.236651e-24  4.809522e-25 -1.347239e-25  5.794320e-26  \n",
       "9996  5.641922e-23  1.521738e-23  5.845244e-25  2.289112e-25  \n",
       "9997 -5.222338e-23 -8.629898e-24  1.129773e-24 -2.509890e-26  \n",
       "9998 -2.556415e-24  2.959303e-25  1.060729e-25  1.069585e-25  \n",
       "9999 -9.901138e-24 -2.287262e-24 -9.313975e-25 -4.494966e-25  \n",
       "\n",
       "[10000 rows x 1568 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_test = df_test.iloc[:,:-1]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91e7bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.values.reshape(-1,28,56,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "93ee4798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5e0d4ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   0\n",
       "0         0  14\n",
       "1         1   7\n",
       "2         2  10\n",
       "3         3   7\n",
       "4         4   5\n",
       "...     ...  ..\n",
       "9995   9995   7\n",
       "9996   9996  12\n",
       "9997   9997  10\n",
       "9998   9998   4\n",
       "9999   9999   6\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = np.zeros( (df_test.shape[0],19) ) \n",
    "for j in range(nets):\n",
    "    results = results + model[j].predict(df_test)\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.DataFrame(results).reset_index()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "62a39d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns = ['Index', 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7be13b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index  Class\n",
       "0         0     14\n",
       "1         1      7\n",
       "2         2     10\n",
       "3         3      7\n",
       "4         4      5\n",
       "...     ...    ...\n",
       "9995   9995      7\n",
       "9996   9996     12\n",
       "9997   9997     10\n",
       "9998   9998      4\n",
       "9999   9999      6\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1195213",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('pd-cnn-ensemble-submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d24d907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/0\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/1\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/2\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/3\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/4\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/5\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/6\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/7\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/8\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/9\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/10\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/11\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/11\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/12\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/12\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/13\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/13\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/14\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble/14\\assets\n"
     ]
    }
   ],
   "source": [
    "for j in range(nets):\n",
    "    model[j].save(f'models/ensemble/{j}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6d9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbad4944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a36ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ca6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1578cd00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34956781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c772943c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 1560</th>\n",
       "      <th>Feature 1561</th>\n",
       "      <th>Feature 1562</th>\n",
       "      <th>Feature 1563</th>\n",
       "      <th>Feature 1564</th>\n",
       "      <th>Feature 1565</th>\n",
       "      <th>Feature 1566</th>\n",
       "      <th>Feature 1567</th>\n",
       "      <th>Feature 1568</th>\n",
       "      <th>Unnamed: 1568</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.854928e-19</td>\n",
       "      <td>-1.329011e-20</td>\n",
       "      <td>4.204335e-21</td>\n",
       "      <td>4.428740e-21</td>\n",
       "      <td>4.461340e-23</td>\n",
       "      <td>2.376798e-24</td>\n",
       "      <td>-7.807106e-24</td>\n",
       "      <td>2.379322e-24</td>\n",
       "      <td>-5.582096e-26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.118652e-20</td>\n",
       "      <td>4.062297e-21</td>\n",
       "      <td>-7.743107e-21</td>\n",
       "      <td>8.638654e-22</td>\n",
       "      <td>-1.006311e-21</td>\n",
       "      <td>-2.267525e-22</td>\n",
       "      <td>-5.867730e-23</td>\n",
       "      <td>4.858047e-24</td>\n",
       "      <td>-4.595498e-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.619224e-20</td>\n",
       "      <td>-3.590984e-20</td>\n",
       "      <td>-2.717642e-20</td>\n",
       "      <td>1.923565e-20</td>\n",
       "      <td>-2.244442e-21</td>\n",
       "      <td>-4.244237e-24</td>\n",
       "      <td>-3.599564e-23</td>\n",
       "      <td>7.471194e-24</td>\n",
       "      <td>-3.815300e-24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.346105e-19</td>\n",
       "      <td>-6.278001e-19</td>\n",
       "      <td>-5.786255e-19</td>\n",
       "      <td>2.573141e-19</td>\n",
       "      <td>2.385063e-19</td>\n",
       "      <td>6.655487e-20</td>\n",
       "      <td>2.834975e-20</td>\n",
       "      <td>3.356577e-21</td>\n",
       "      <td>1.698628e-21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.494150e-20</td>\n",
       "      <td>-1.187973e-20</td>\n",
       "      <td>-1.450941e-21</td>\n",
       "      <td>8.954877e-22</td>\n",
       "      <td>-2.645088e-22</td>\n",
       "      <td>1.365356e-23</td>\n",
       "      <td>8.062470e-24</td>\n",
       "      <td>-1.235689e-24</td>\n",
       "      <td>1.890073e-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1569 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  Feature 6  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   Feature 7  Feature 8  Feature 9  Feature 10  ...  Feature 1560  \\\n",
       "0        0.0        0.0        0.0         0.0  ...  3.854928e-19   \n",
       "1        0.0        0.0        0.0         0.0  ... -7.118652e-20   \n",
       "2        0.0        0.0        0.0         0.0  ... -4.619224e-20   \n",
       "3        0.0        0.0        0.0         0.0  ... -5.346105e-19   \n",
       "4        0.0        0.0        0.0         0.0  ...  5.494150e-20   \n",
       "\n",
       "   Feature 1561  Feature 1562  Feature 1563  Feature 1564  Feature 1565  \\\n",
       "0 -1.329011e-20  4.204335e-21  4.428740e-21  4.461340e-23  2.376798e-24   \n",
       "1  4.062297e-21 -7.743107e-21  8.638654e-22 -1.006311e-21 -2.267525e-22   \n",
       "2 -3.590984e-20 -2.717642e-20  1.923565e-20 -2.244442e-21 -4.244237e-24   \n",
       "3 -6.278001e-19 -5.786255e-19  2.573141e-19  2.385063e-19  6.655487e-20   \n",
       "4 -1.187973e-20 -1.450941e-21  8.954877e-22 -2.645088e-22  1.365356e-23   \n",
       "\n",
       "   Feature 1566  Feature 1567  Feature 1568  Unnamed: 1568  \n",
       "0 -7.807106e-24  2.379322e-24 -5.582096e-26            NaN  \n",
       "1 -5.867730e-23  4.858047e-24 -4.595498e-25            NaN  \n",
       "2 -3.599564e-23  7.471194e-24 -3.815300e-24            NaN  \n",
       "3  2.834975e-20  3.356577e-21  1.698628e-21            NaN  \n",
       "4  8.062470e-24 -1.235689e-24  1.890073e-25            NaN  \n",
       "\n",
       "[5 rows x 1569 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b574950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Class\n",
       "Index       \n",
       "0          5\n",
       "1          4\n",
       "2          5\n",
       "3          4\n",
       "4          4\n",
       "...      ...\n",
       "49995      9\n",
       "49996     14\n",
       "49997      1\n",
       "49998      7\n",
       "49999      9\n",
       "\n",
       "[50000 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv('data/train_result.csv', index_col=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b222f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 1559</th>\n",
       "      <th>Feature 1560</th>\n",
       "      <th>Feature 1561</th>\n",
       "      <th>Feature 1562</th>\n",
       "      <th>Feature 1563</th>\n",
       "      <th>Feature 1564</th>\n",
       "      <th>Feature 1565</th>\n",
       "      <th>Feature 1566</th>\n",
       "      <th>Feature 1567</th>\n",
       "      <th>Feature 1568</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.281934e-19</td>\n",
       "      <td>3.854928e-19</td>\n",
       "      <td>-1.329011e-20</td>\n",
       "      <td>4.204335e-21</td>\n",
       "      <td>4.428740e-21</td>\n",
       "      <td>4.461340e-23</td>\n",
       "      <td>2.376798e-24</td>\n",
       "      <td>-7.807106e-24</td>\n",
       "      <td>2.379322e-24</td>\n",
       "      <td>-5.582096e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.714815e-19</td>\n",
       "      <td>-7.118652e-20</td>\n",
       "      <td>4.062297e-21</td>\n",
       "      <td>-7.743107e-21</td>\n",
       "      <td>8.638654e-22</td>\n",
       "      <td>-1.006311e-21</td>\n",
       "      <td>-2.267525e-22</td>\n",
       "      <td>-5.867730e-23</td>\n",
       "      <td>4.858047e-24</td>\n",
       "      <td>-4.595498e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.968480e-20</td>\n",
       "      <td>-4.619224e-20</td>\n",
       "      <td>-3.590984e-20</td>\n",
       "      <td>-2.717642e-20</td>\n",
       "      <td>1.923565e-20</td>\n",
       "      <td>-2.244442e-21</td>\n",
       "      <td>-4.244237e-24</td>\n",
       "      <td>-3.599564e-23</td>\n",
       "      <td>7.471194e-24</td>\n",
       "      <td>-3.815300e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.256463e-20</td>\n",
       "      <td>-5.346105e-19</td>\n",
       "      <td>-6.278001e-19</td>\n",
       "      <td>-5.786255e-19</td>\n",
       "      <td>2.573141e-19</td>\n",
       "      <td>2.385063e-19</td>\n",
       "      <td>6.655487e-20</td>\n",
       "      <td>2.834975e-20</td>\n",
       "      <td>3.356577e-21</td>\n",
       "      <td>1.698628e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.446271e-19</td>\n",
       "      <td>5.494150e-20</td>\n",
       "      <td>-1.187973e-20</td>\n",
       "      <td>-1.450941e-21</td>\n",
       "      <td>8.954877e-22</td>\n",
       "      <td>-2.645088e-22</td>\n",
       "      <td>1.365356e-23</td>\n",
       "      <td>8.062470e-24</td>\n",
       "      <td>-1.235689e-24</td>\n",
       "      <td>1.890073e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.806037e-19</td>\n",
       "      <td>-9.956413e-22</td>\n",
       "      <td>7.012638e-21</td>\n",
       "      <td>-1.749799e-21</td>\n",
       "      <td>-5.296019e-22</td>\n",
       "      <td>5.324962e-23</td>\n",
       "      <td>-7.651382e-24</td>\n",
       "      <td>-1.189074e-23</td>\n",
       "      <td>-3.929069e-24</td>\n",
       "      <td>1.550829e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.120559e-21</td>\n",
       "      <td>-2.386547e-22</td>\n",
       "      <td>3.369363e-23</td>\n",
       "      <td>1.459011e-23</td>\n",
       "      <td>5.123315e-25</td>\n",
       "      <td>-5.553792e-25</td>\n",
       "      <td>-1.656932e-25</td>\n",
       "      <td>-4.579053e-26</td>\n",
       "      <td>5.280697e-26</td>\n",
       "      <td>1.550841e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.683112e-18</td>\n",
       "      <td>-1.566546e-20</td>\n",
       "      <td>6.858092e-21</td>\n",
       "      <td>1.256228e-21</td>\n",
       "      <td>-3.157088e-22</td>\n",
       "      <td>1.984213e-23</td>\n",
       "      <td>1.134711e-23</td>\n",
       "      <td>-3.192012e-24</td>\n",
       "      <td>1.801697e-25</td>\n",
       "      <td>-1.020857e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.349202e-20</td>\n",
       "      <td>-1.839305e-21</td>\n",
       "      <td>3.174579e-20</td>\n",
       "      <td>7.510705e-21</td>\n",
       "      <td>-1.584091e-21</td>\n",
       "      <td>9.770302e-23</td>\n",
       "      <td>1.247588e-22</td>\n",
       "      <td>5.449431e-24</td>\n",
       "      <td>2.336028e-24</td>\n",
       "      <td>2.577251e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.295327e-17</td>\n",
       "      <td>9.899082e-17</td>\n",
       "      <td>8.549260e-17</td>\n",
       "      <td>1.099950e-18</td>\n",
       "      <td>-8.754949e-19</td>\n",
       "      <td>1.678472e-20</td>\n",
       "      <td>-1.834816e-20</td>\n",
       "      <td>-1.115471e-20</td>\n",
       "      <td>-4.795634e-21</td>\n",
       "      <td>-1.559397e-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1568 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  Feature 6  \\\n",
       "0            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4            0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "49995        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "49996        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "49997        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "49998        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "49999        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "       Feature 7  Feature 8  Feature 9  Feature 10  ...  Feature 1559  \\\n",
       "0            0.0        0.0        0.0         0.0  ... -1.281934e-19   \n",
       "1            0.0        0.0        0.0         0.0  ... -4.714815e-19   \n",
       "2            0.0        0.0        0.0         0.0  ... -3.968480e-20   \n",
       "3            0.0        0.0        0.0         0.0  ...  4.256463e-20   \n",
       "4            0.0        0.0        0.0         0.0  ... -9.446271e-19   \n",
       "...          ...        ...        ...         ...  ...           ...   \n",
       "49995        0.0        0.0        0.0         0.0  ... -2.806037e-19   \n",
       "49996        0.0        0.0        0.0         0.0  ...  1.120559e-21   \n",
       "49997        0.0        0.0        0.0         0.0  ...  2.683112e-18   \n",
       "49998        0.0        0.0        0.0         0.0  ...  4.349202e-20   \n",
       "49999        0.0        0.0        0.0         0.0  ...  8.295327e-17   \n",
       "\n",
       "       Feature 1560  Feature 1561  Feature 1562  Feature 1563  Feature 1564  \\\n",
       "0      3.854928e-19 -1.329011e-20  4.204335e-21  4.428740e-21  4.461340e-23   \n",
       "1     -7.118652e-20  4.062297e-21 -7.743107e-21  8.638654e-22 -1.006311e-21   \n",
       "2     -4.619224e-20 -3.590984e-20 -2.717642e-20  1.923565e-20 -2.244442e-21   \n",
       "3     -5.346105e-19 -6.278001e-19 -5.786255e-19  2.573141e-19  2.385063e-19   \n",
       "4      5.494150e-20 -1.187973e-20 -1.450941e-21  8.954877e-22 -2.645088e-22   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "49995 -9.956413e-22  7.012638e-21 -1.749799e-21 -5.296019e-22  5.324962e-23   \n",
       "49996 -2.386547e-22  3.369363e-23  1.459011e-23  5.123315e-25 -5.553792e-25   \n",
       "49997 -1.566546e-20  6.858092e-21  1.256228e-21 -3.157088e-22  1.984213e-23   \n",
       "49998 -1.839305e-21  3.174579e-20  7.510705e-21 -1.584091e-21  9.770302e-23   \n",
       "49999  9.899082e-17  8.549260e-17  1.099950e-18 -8.754949e-19  1.678472e-20   \n",
       "\n",
       "       Feature 1565  Feature 1566  Feature 1567  Feature 1568  \n",
       "0      2.376798e-24 -7.807106e-24  2.379322e-24 -5.582096e-26  \n",
       "1     -2.267525e-22 -5.867730e-23  4.858047e-24 -4.595498e-25  \n",
       "2     -4.244237e-24 -3.599564e-23  7.471194e-24 -3.815300e-24  \n",
       "3      6.655487e-20  2.834975e-20  3.356577e-21  1.698628e-21  \n",
       "4      1.365356e-23  8.062470e-24 -1.235689e-24  1.890073e-25  \n",
       "...             ...           ...           ...           ...  \n",
       "49995 -7.651382e-24 -1.189074e-23 -3.929069e-24  1.550829e-24  \n",
       "49996 -1.656932e-25 -4.579053e-26  5.280697e-26  1.550841e-26  \n",
       "49997  1.134711e-23 -3.192012e-24  1.801697e-25 -1.020857e-26  \n",
       "49998  1.247588e-22  5.449431e-24  2.336028e-24  2.577251e-24  \n",
       "49999 -1.834816e-20 -1.115471e-20 -4.795634e-21 -1.559397e-22  \n",
       "\n",
       "[50000 rows x 1568 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "622f631f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.37591740e-21],\n",
       "         [ 5.30417960e-22],\n",
       "         [-3.57824900e-24]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.48994830e-21],\n",
       "         [ 6.31696440e-22],\n",
       "         [-3.58053030e-22]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.00505800e-21],\n",
       "         [ 1.07208180e-21],\n",
       "         [-2.05822040e-21]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.86626740e-23],\n",
       "         [-7.54684500e-24],\n",
       "         [-2.40440590e-23]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.71384430e-23],\n",
       "         [-2.84402220e-24],\n",
       "         [ 4.41500800e-25]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-7.80710550e-24],\n",
       "         [ 2.37932200e-24],\n",
       "         [-5.58209600e-26]]],\n",
       "\n",
       "\n",
       "       [[[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 3.27461340e-25],\n",
       "         [ 1.07634440e-25],\n",
       "         [-9.88395400e-26]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-8.87620800e-25],\n",
       "         [-2.92710000e-25],\n",
       "         [-2.16285940e-25]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.21094440e-25],\n",
       "         [-8.62574300e-25],\n",
       "         [-2.89712300e-25]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-1.01158940e-21],\n",
       "         [-3.26014200e-22],\n",
       "         [ 1.12037020e-22]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.61687560e-22],\n",
       "         [ 1.08058660e-23],\n",
       "         [ 2.33908320e-23]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-5.86773040e-23],\n",
       "         [ 4.85804650e-24],\n",
       "         [-4.59549800e-25]]],\n",
       "\n",
       "\n",
       "       [[[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.01568520e-24],\n",
       "         [-2.21912860e-25],\n",
       "         [-1.28033780e-25]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.93806880e-26],\n",
       "         [-1.16200960e-24],\n",
       "         [-6.89255140e-25]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 6.32483370e-23],\n",
       "         [-7.65216870e-25],\n",
       "         [-6.30463350e-25]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 4.40460400e-22],\n",
       "         [ 3.78048100e-22],\n",
       "         [ 1.02063820e-22]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.82695610e-22],\n",
       "         [ 8.89086300e-23],\n",
       "         [ 2.67230670e-23]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.59956400e-23],\n",
       "         [ 7.47119360e-24],\n",
       "         [-3.81529970e-24]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-2.72341040e-26],\n",
       "         [-3.49097880e-27],\n",
       "         [ 4.04444570e-28]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-2.48399260e-26],\n",
       "         [ 3.63561880e-27],\n",
       "         [ 3.83510200e-27]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.50423720e-25],\n",
       "         [ 1.25764650e-26],\n",
       "         [-3.96775370e-28]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.98952120e-23],\n",
       "         [ 1.01063370e-23],\n",
       "         [ 1.32246810e-23]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.15221730e-23],\n",
       "         [ 7.35454100e-24],\n",
       "         [ 3.31382680e-24]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.19201230e-24],\n",
       "         [ 1.80169730e-25],\n",
       "         [-1.02085740e-26]]],\n",
       "\n",
       "\n",
       "       [[[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.32780230e-24],\n",
       "         [ 1.03126220e-24],\n",
       "         [-4.22012600e-26]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.91623280e-24],\n",
       "         [-3.76451400e-24],\n",
       "         [-1.09306650e-24]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-1.13043965e-23],\n",
       "         [ 1.10209680e-24],\n",
       "         [ 2.78564240e-25]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.42552370e-23],\n",
       "         [-9.72694700e-25],\n",
       "         [-3.63002400e-23]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.11643540e-23],\n",
       "         [ 9.59594150e-24],\n",
       "         [-3.78250980e-23]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 5.44943100e-24],\n",
       "         [ 2.33602780e-24],\n",
       "         [ 2.57725080e-24]]],\n",
       "\n",
       "\n",
       "       [[[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 2.60686140e-26],\n",
       "         [-1.65943130e-26],\n",
       "         [ 1.53454600e-27]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-1.40309690e-24],\n",
       "         [-1.92335910e-25],\n",
       "         [ 2.69408330e-26]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-3.26709840e-24],\n",
       "         [-6.00235830e-25],\n",
       "         [-1.88249930e-26]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 1.59503440e-20],\n",
       "         [ 2.23094200e-20],\n",
       "         [-5.94482500e-20]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [ 5.97874640e-20],\n",
       "         [ 5.78594870e-21],\n",
       "         [ 3.81944540e-20]],\n",
       "\n",
       "        [[ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         [ 0.00000000e+00],\n",
       "         ...,\n",
       "         [-1.11547100e-20],\n",
       "         [-4.79563400e-21],\n",
       "         [-1.55939740e-22]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.values.reshape((-1,28,56,1))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f230c3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f165ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 56, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27f54066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 19)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29afcbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE MORE IMAGES VIA DATA AUGMENTATION\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,  \n",
    "        zoom_range = 0.10,  \n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64ef3cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD CONVOLUTIONAL NEURAL NETWORKS\n",
    "nets = 15\n",
    "model = [0] *nets\n",
    "for j in range(nets):\n",
    "    model[j]=Sequential()\n",
    "    model[j].add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\", input_shape=X.shape[1:]))\n",
    "    model[j].add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n",
    "    model[j].add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model[j].add(BatchNormalization())\n",
    "\n",
    "    model[j].add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
    "    model[j].add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
    "    model[j].add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model[j].add(BatchNormalization())    \n",
    "\n",
    "    model[j].add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\n",
    "    model[j].add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model[j].add(BatchNormalization())\n",
    "\n",
    "    model[j].add(Flatten())\n",
    "    model[j].add(Dense(512,activation=\"relu\"))\n",
    "\n",
    "    model[j].add(Dense(19,activation=\"softmax\"))\n",
    "\n",
    "    model[j].compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21dd6521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "391/391 [==============================] - 32s 80ms/step - loss: 1.4732 - accuracy: 0.5179\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 30s 76ms/step - loss: 0.2713 - accuracy: 0.9201\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 0.1840 - accuracy: 0.9449\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 31s 78ms/step - loss: 0.1503 - accuracy: 0.9547\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 29s 75ms/step - loss: 0.1278 - accuracy: 0.9615\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 29s 75ms/step - loss: 0.1110 - accuracy: 0.9664\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 30s 75ms/step - loss: 0.1019 - accuracy: 0.9694\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 14s 36ms/step - loss: 0.0945 - accuracy: 0.9720\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0892 - accuracy: 0.9727\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0874 - accuracy: 0.9744\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0819 - accuracy: 0.9756\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0749 - accuracy: 0.9778\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0725 - accuracy: 0.9787\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0693 - accuracy: 0.9793\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0644 - accuracy: 0.9809\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0636 - accuracy: 0.9810\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0603 - accuracy: 0.9819\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0619 - accuracy: 0.9817\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0517 - accuracy: 0.9842\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 16s 40ms/step - loss: 0.0541 - accuracy: 0.9832\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 19s 49ms/step - loss: 0.0546 - accuracy: 0.9835\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0556 - accuracy: 0.9828\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0505 - accuracy: 0.9850\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0490 - accuracy: 0.9854\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0447 - accuracy: 0.9868\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0445 - accuracy: 0.9860\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0477 - accuracy: 0.9862\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0442 - accuracy: 0.9868\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0448 - accuracy: 0.9871\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0432 - accuracy: 0.9864\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0423 - accuracy: 0.9867\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0429 - accuracy: 0.9870\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0393 - accuracy: 0.9882\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0376 - accuracy: 0.9885\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0379 - accuracy: 0.9883\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0367 - accuracy: 0.9889\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0378 - accuracy: 0.9881\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0345 - accuracy: 0.9893\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0365 - accuracy: 0.9896\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0386 - accuracy: 0.9886\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0339 - accuracy: 0.9892\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0338 - accuracy: 0.9901\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0359 - accuracy: 0.9893\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0334 - accuracy: 0.9906\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0330 - accuracy: 0.9899\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0324 - accuracy: 0.9895\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0297 - accuracy: 0.9912\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0322 - accuracy: 0.9902\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0330 - accuracy: 0.9904\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0279 - accuracy: 0.9914\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0292 - accuracy: 0.9907\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0302 - accuracy: 0.9910\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0316 - accuracy: 0.9906\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0308 - accuracy: 0.9909\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0301 - accuracy: 0.9907\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0291 - accuracy: 0.9906\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0260 - accuracy: 0.9918\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0301 - accuracy: 0.9906\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0253 - accuracy: 0.9924\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0302 - accuracy: 0.9912\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0256 - accuracy: 0.9924\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0258 - accuracy: 0.9924\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0269 - accuracy: 0.9914\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0226 - accuracy: 0.9933\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0254 - accuracy: 0.9923\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0260 - accuracy: 0.9918\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0239 - accuracy: 0.9926\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0252 - accuracy: 0.9925\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0247 - accuracy: 0.9924\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0253 - accuracy: 0.9919\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0222 - accuracy: 0.9932\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0230 - accuracy: 0.9930\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0253 - accuracy: 0.9926\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0220 - accuracy: 0.9935\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0229 - accuracy: 0.9932\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0260 - accuracy: 0.9923\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0249 - accuracy: 0.9924\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0209 - accuracy: 0.9941\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0242 - accuracy: 0.9928\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0206 - accuracy: 0.9934\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0229 - accuracy: 0.9930\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0247 - accuracy: 0.9923\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0222 - accuracy: 0.9930\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0237 - accuracy: 0.9925\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0224 - accuracy: 0.9933\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0197 - accuracy: 0.9945\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0217 - accuracy: 0.9933\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0219 - accuracy: 0.9938\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0207 - accuracy: 0.9942\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0221 - accuracy: 0.9932\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0199 - accuracy: 0.9934\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0203 - accuracy: 0.9936\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0205 - accuracy: 0.9935\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0182 - accuracy: 0.9943\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0211 - accuracy: 0.9937\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0200 - accuracy: 0.9941\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0218 - accuracy: 0.9934\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0176 - accuracy: 0.9946\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0175 - accuracy: 0.9941\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0192 - accuracy: 0.9941\n",
      "CNN 1: Epochs=100, Train accuracy=0.99458\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 1.6339 - accuracy: 0.4634\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.2905 - accuracy: 0.9141\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.1855 - accuracy: 0.9445\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.1539 - accuracy: 0.9542\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1287 - accuracy: 0.9614\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.1151 - accuracy: 0.9658\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1052 - accuracy: 0.9687\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0926 - accuracy: 0.9714\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0946 - accuracy: 0.9709\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0881 - accuracy: 0.9733\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0774 - accuracy: 0.9765\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0767 - accuracy: 0.9770\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0743 - accuracy: 0.9782\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0693 - accuracy: 0.9790\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0641 - accuracy: 0.9806\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0631 - accuracy: 0.9816\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0622 - accuracy: 0.9817\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0632 - accuracy: 0.9809\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0552 - accuracy: 0.9836\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0583 - accuracy: 0.9822\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0530 - accuracy: 0.9843\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0527 - accuracy: 0.9846\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0554 - accuracy: 0.9839\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0524 - accuracy: 0.9844\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0466 - accuracy: 0.9859\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0477 - accuracy: 0.9857\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0453 - accuracy: 0.9861\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0435 - accuracy: 0.9864\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0469 - accuracy: 0.9858\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0409 - accuracy: 0.9877\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0457 - accuracy: 0.9865\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0399 - accuracy: 0.9878\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0409 - accuracy: 0.9875\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0429 - accuracy: 0.9867\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0399 - accuracy: 0.9882\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0364 - accuracy: 0.9886\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0367 - accuracy: 0.9889\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0312 - accuracy: 0.9904\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0348 - accuracy: 0.9893\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0402 - accuracy: 0.9883\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0357 - accuracy: 0.9887\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0399 - accuracy: 0.9883\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0312 - accuracy: 0.9908\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0347 - accuracy: 0.9896\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0326 - accuracy: 0.9899\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0318 - accuracy: 0.9904\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0294 - accuracy: 0.9914\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0332 - accuracy: 0.9897\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0345 - accuracy: 0.9900\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0284 - accuracy: 0.9909\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0331 - accuracy: 0.9895\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0302 - accuracy: 0.9905\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0300 - accuracy: 0.9913\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0282 - accuracy: 0.9916\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0284 - accuracy: 0.9917\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0294 - accuracy: 0.9911\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0302 - accuracy: 0.9908\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0278 - accuracy: 0.9911\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0302 - accuracy: 0.9910\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0282 - accuracy: 0.9910\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0269 - accuracy: 0.9914\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0269 - accuracy: 0.9921\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0278 - accuracy: 0.9914\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0259 - accuracy: 0.9924\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0254 - accuracy: 0.9920\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0259 - accuracy: 0.9920\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0270 - accuracy: 0.9913\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0263 - accuracy: 0.9919\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0234 - accuracy: 0.9926\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0262 - accuracy: 0.9919\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0267 - accuracy: 0.9918\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0232 - accuracy: 0.9927\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0236 - accuracy: 0.9924\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0247 - accuracy: 0.9931\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0238 - accuracy: 0.9924\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0225 - accuracy: 0.9930\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0231 - accuracy: 0.9929\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0215 - accuracy: 0.9936\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0244 - accuracy: 0.9924\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0213 - accuracy: 0.9932\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0242 - accuracy: 0.9926\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0216 - accuracy: 0.9933\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0209 - accuracy: 0.9936\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0227 - accuracy: 0.9935\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0222 - accuracy: 0.9938\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0248 - accuracy: 0.9924\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0200 - accuracy: 0.9937\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0225 - accuracy: 0.9931\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0220 - accuracy: 0.9935\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0208 - accuracy: 0.9940\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0226 - accuracy: 0.9933\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0236 - accuracy: 0.9928\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0201 - accuracy: 0.9938\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0216 - accuracy: 0.9936\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0226 - accuracy: 0.9928\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0233 - accuracy: 0.9927\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0183 - accuracy: 0.9942\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0198 - accuracy: 0.9940\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0222 - accuracy: 0.9932\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0192 - accuracy: 0.9939\n",
      "CNN 2: Epochs=100, Train accuracy=0.99424\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 1.6078 - accuracy: 0.4739\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.2792 - accuracy: 0.9176\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.1882 - accuracy: 0.9444\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1461 - accuracy: 0.9554\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1291 - accuracy: 0.9615\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1171 - accuracy: 0.9652\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.1037 - accuracy: 0.9693\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0972 - accuracy: 0.9703\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0906 - accuracy: 0.9730\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0844 - accuracy: 0.9750\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0796 - accuracy: 0.9767\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0795 - accuracy: 0.9759\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0708 - accuracy: 0.9788\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0704 - accuracy: 0.9793\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0679 - accuracy: 0.9801\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0665 - accuracy: 0.9795\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0625 - accuracy: 0.9810\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0579 - accuracy: 0.9819\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0544 - accuracy: 0.9828\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0562 - accuracy: 0.9833\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0541 - accuracy: 0.9845\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0543 - accuracy: 0.9840\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0519 - accuracy: 0.9841\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0469 - accuracy: 0.9860\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0518 - accuracy: 0.9850\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0463 - accuracy: 0.9861\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0472 - accuracy: 0.9853\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0439 - accuracy: 0.9866\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0422 - accuracy: 0.9878\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0437 - accuracy: 0.9868\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0405 - accuracy: 0.9873\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0433 - accuracy: 0.9870\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0377 - accuracy: 0.9886\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0380 - accuracy: 0.9888\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0403 - accuracy: 0.9879\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0386 - accuracy: 0.9879\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0373 - accuracy: 0.9888\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0367 - accuracy: 0.9891\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0348 - accuracy: 0.9895\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0379 - accuracy: 0.9892\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0340 - accuracy: 0.9897\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0371 - accuracy: 0.9891\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0357 - accuracy: 0.9898\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0334 - accuracy: 0.9894\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0357 - accuracy: 0.9892\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0328 - accuracy: 0.9897\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0333 - accuracy: 0.9896\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0299 - accuracy: 0.9911\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0316 - accuracy: 0.9902\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0310 - accuracy: 0.9907\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0301 - accuracy: 0.9905\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0287 - accuracy: 0.9917\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0315 - accuracy: 0.9904\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0276 - accuracy: 0.9910\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0310 - accuracy: 0.9908\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0289 - accuracy: 0.9910\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0268 - accuracy: 0.9918\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0282 - accuracy: 0.9918\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0263 - accuracy: 0.9916\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0264 - accuracy: 0.9924\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0271 - accuracy: 0.9919\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0286 - accuracy: 0.9913\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0321 - accuracy: 0.9903\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0277 - accuracy: 0.9918\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0268 - accuracy: 0.9918\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0248 - accuracy: 0.9923\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0242 - accuracy: 0.9924\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0244 - accuracy: 0.9927\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0271 - accuracy: 0.9917\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0268 - accuracy: 0.9922\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0246 - accuracy: 0.9927\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0243 - accuracy: 0.9925\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0224 - accuracy: 0.9930\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0255 - accuracy: 0.9924\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0240 - accuracy: 0.9924\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0234 - accuracy: 0.9928\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0256 - accuracy: 0.9923\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0239 - accuracy: 0.9929\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0251 - accuracy: 0.9923\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0228 - accuracy: 0.9930\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0257 - accuracy: 0.9926\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0201 - accuracy: 0.9937\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0250 - accuracy: 0.9923\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0217 - accuracy: 0.9935\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0232 - accuracy: 0.9927\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0220 - accuracy: 0.9932\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0193 - accuracy: 0.9944\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0225 - accuracy: 0.9929\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0207 - accuracy: 0.9933\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0227 - accuracy: 0.9933\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0199 - accuracy: 0.9942\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0227 - accuracy: 0.9929\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0213 - accuracy: 0.9938\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0200 - accuracy: 0.9941\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0233 - accuracy: 0.9930\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0200 - accuracy: 0.9942\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0210 - accuracy: 0.9935\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0216 - accuracy: 0.9929\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0204 - accuracy: 0.9936\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0204 - accuracy: 0.9939\n",
      "CNN 3: Epochs=100, Train accuracy=0.99438\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 13s 31ms/step - loss: 1.5679 - accuracy: 0.4876\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.2790 - accuracy: 0.9168\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1832 - accuracy: 0.9450\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.1458 - accuracy: 0.9562\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1294 - accuracy: 0.9613\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1124 - accuracy: 0.9668\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1030 - accuracy: 0.9701\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0984 - accuracy: 0.9717\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0878 - accuracy: 0.9740\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0838 - accuracy: 0.9753\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0813 - accuracy: 0.9754\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0767 - accuracy: 0.9779\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0723 - accuracy: 0.9792\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0656 - accuracy: 0.9807\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0702 - accuracy: 0.9795\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0596 - accuracy: 0.9817\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0632 - accuracy: 0.9815\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0596 - accuracy: 0.9824\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0559 - accuracy: 0.9826\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0529 - accuracy: 0.9845\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0513 - accuracy: 0.9849\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0541 - accuracy: 0.9838\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0473 - accuracy: 0.9864\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0512 - accuracy: 0.9849\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0465 - accuracy: 0.9864\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0488 - accuracy: 0.9856\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0436 - accuracy: 0.9875\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0450 - accuracy: 0.9866\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0455 - accuracy: 0.9872\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0431 - accuracy: 0.9870\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0398 - accuracy: 0.9879\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0389 - accuracy: 0.9879\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0421 - accuracy: 0.9871\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0391 - accuracy: 0.9882\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0386 - accuracy: 0.9877\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0346 - accuracy: 0.9899\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0382 - accuracy: 0.9882\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0373 - accuracy: 0.9890\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0346 - accuracy: 0.9895\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0346 - accuracy: 0.9897\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0363 - accuracy: 0.9886\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0357 - accuracy: 0.9893\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0332 - accuracy: 0.9897\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0324 - accuracy: 0.9898\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0316 - accuracy: 0.9899\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0298 - accuracy: 0.9915\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0317 - accuracy: 0.9898\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0314 - accuracy: 0.9906\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0311 - accuracy: 0.9908\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0297 - accuracy: 0.9912\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0311 - accuracy: 0.9906\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0304 - accuracy: 0.9905\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0292 - accuracy: 0.9911\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0278 - accuracy: 0.9911\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0297 - accuracy: 0.9912\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0305 - accuracy: 0.9909\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0234 - accuracy: 0.9927\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0289 - accuracy: 0.9917\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0282 - accuracy: 0.9915\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0280 - accuracy: 0.9912\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0256 - accuracy: 0.9919\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0270 - accuracy: 0.9923\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0251 - accuracy: 0.9919\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0235 - accuracy: 0.9926\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0258 - accuracy: 0.9919\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0278 - accuracy: 0.9913\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0258 - accuracy: 0.9918\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0251 - accuracy: 0.9926\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0254 - accuracy: 0.9923\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0236 - accuracy: 0.9928\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0234 - accuracy: 0.9929\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0251 - accuracy: 0.9925\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0206 - accuracy: 0.9938\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0244 - accuracy: 0.9926\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0248 - accuracy: 0.9922\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0232 - accuracy: 0.9926\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0221 - accuracy: 0.9933\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0258 - accuracy: 0.9922\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0233 - accuracy: 0.9931\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0207 - accuracy: 0.9937\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0199 - accuracy: 0.9937\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0224 - accuracy: 0.9932\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0219 - accuracy: 0.9929\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0218 - accuracy: 0.9932\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0236 - accuracy: 0.9932\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0234 - accuracy: 0.9930\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0209 - accuracy: 0.9936\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0216 - accuracy: 0.9940\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0211 - accuracy: 0.9934\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0198 - accuracy: 0.9936\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0202 - accuracy: 0.9938\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0226 - accuracy: 0.9934\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0217 - accuracy: 0.9933\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0194 - accuracy: 0.9941\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0204 - accuracy: 0.9939\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0180 - accuracy: 0.9949\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0210 - accuracy: 0.9937\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0179 - accuracy: 0.9946\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0200 - accuracy: 0.9935\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0201 - accuracy: 0.9937\n",
      "CNN 4: Epochs=100, Train accuracy=0.99488\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 1.5942 - accuracy: 0.4772\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.2903 - accuracy: 0.9124\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1815 - accuracy: 0.9447\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1515 - accuracy: 0.9555\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1302 - accuracy: 0.9611\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1116 - accuracy: 0.9659\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1071 - accuracy: 0.9679\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0975 - accuracy: 0.9707\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0901 - accuracy: 0.9732\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0860 - accuracy: 0.9745\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0782 - accuracy: 0.9765\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0760 - accuracy: 0.9769\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0740 - accuracy: 0.9779\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0700 - accuracy: 0.9793\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0685 - accuracy: 0.9801\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0653 - accuracy: 0.9808\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0586 - accuracy: 0.9827\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0600 - accuracy: 0.9819\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0592 - accuracy: 0.9824\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0555 - accuracy: 0.9830\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0501 - accuracy: 0.9852\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0549 - accuracy: 0.9835\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0506 - accuracy: 0.9845\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0470 - accuracy: 0.9860\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0480 - accuracy: 0.9856\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0483 - accuracy: 0.9861\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0447 - accuracy: 0.9870\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0447 - accuracy: 0.9864\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0406 - accuracy: 0.9875\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0455 - accuracy: 0.9868\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0401 - accuracy: 0.9877\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0395 - accuracy: 0.9882\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0414 - accuracy: 0.9882\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0351 - accuracy: 0.9894\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0391 - accuracy: 0.9883\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0354 - accuracy: 0.9892\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0397 - accuracy: 0.9879\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.0370 - accuracy: 0.9885\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0356 - accuracy: 0.9895\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0346 - accuracy: 0.9896\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0336 - accuracy: 0.9897\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0354 - accuracy: 0.9892\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0334 - accuracy: 0.9896\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0343 - accuracy: 0.9897\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0331 - accuracy: 0.9900\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0335 - accuracy: 0.9906\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0311 - accuracy: 0.9909\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0314 - accuracy: 0.9905\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0294 - accuracy: 0.9909\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0293 - accuracy: 0.9910\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0302 - accuracy: 0.9910\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0312 - accuracy: 0.9902\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0321 - accuracy: 0.9900\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0285 - accuracy: 0.9912\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0274 - accuracy: 0.9917\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0293 - accuracy: 0.9914\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0270 - accuracy: 0.9915\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0248 - accuracy: 0.9923\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0281 - accuracy: 0.9911\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0265 - accuracy: 0.9920\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0285 - accuracy: 0.9917\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0261 - accuracy: 0.9920\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0283 - accuracy: 0.9912\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0277 - accuracy: 0.9919\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0258 - accuracy: 0.9919\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0274 - accuracy: 0.9922\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0229 - accuracy: 0.9929\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0251 - accuracy: 0.9922\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0230 - accuracy: 0.9930\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0247 - accuracy: 0.9925\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0204 - accuracy: 0.9935\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0258 - accuracy: 0.9927\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0235 - accuracy: 0.9929\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0216 - accuracy: 0.9933\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0245 - accuracy: 0.9930\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0230 - accuracy: 0.9929\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0209 - accuracy: 0.9933\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0259 - accuracy: 0.9922\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0185 - accuracy: 0.9942\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0238 - accuracy: 0.9928\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0225 - accuracy: 0.9929\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0213 - accuracy: 0.9934\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0224 - accuracy: 0.9931\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0228 - accuracy: 0.9933\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0240 - accuracy: 0.9928\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0199 - accuracy: 0.9942\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0222 - accuracy: 0.9931\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0193 - accuracy: 0.9944\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0213 - accuracy: 0.9938\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0216 - accuracy: 0.9935\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0201 - accuracy: 0.9938\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0242 - accuracy: 0.9931\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0218 - accuracy: 0.9933\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0184 - accuracy: 0.9944\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0200 - accuracy: 0.9942\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0208 - accuracy: 0.9934\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0213 - accuracy: 0.9937\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0179 - accuracy: 0.9946\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0179 - accuracy: 0.9947\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0192 - accuracy: 0.9939\n",
      "CNN 5: Epochs=100, Train accuracy=0.99472\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 1.5526 - accuracy: 0.4929\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.2829 - accuracy: 0.9137\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1819 - accuracy: 0.9461\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1525 - accuracy: 0.9547\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1225 - accuracy: 0.9641\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.1157 - accuracy: 0.9652\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.1089 - accuracy: 0.9678\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0948 - accuracy: 0.9715\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0889 - accuracy: 0.9738\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0820 - accuracy: 0.9752\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0813 - accuracy: 0.9766\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0776 - accuracy: 0.9776\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0705 - accuracy: 0.9792\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0671 - accuracy: 0.9794\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0623 - accuracy: 0.9812\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0614 - accuracy: 0.9824\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0611 - accuracy: 0.9818\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0624 - accuracy: 0.9811\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0621 - accuracy: 0.9812\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0538 - accuracy: 0.9837\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0556 - accuracy: 0.9828\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0515 - accuracy: 0.9847\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0498 - accuracy: 0.9845\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0470 - accuracy: 0.9857\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0490 - accuracy: 0.9852\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0437 - accuracy: 0.9865\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0467 - accuracy: 0.9861\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0442 - accuracy: 0.9868\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0430 - accuracy: 0.9868\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0428 - accuracy: 0.9875\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0430 - accuracy: 0.9875\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0373 - accuracy: 0.9889\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0384 - accuracy: 0.9889\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0383 - accuracy: 0.9886\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0377 - accuracy: 0.9883\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0400 - accuracy: 0.9880\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0358 - accuracy: 0.9893\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0358 - accuracy: 0.9891\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0380 - accuracy: 0.9882\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0331 - accuracy: 0.9899\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0356 - accuracy: 0.9893\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0345 - accuracy: 0.9893\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0325 - accuracy: 0.9899\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0335 - accuracy: 0.9900\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0331 - accuracy: 0.9899\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0336 - accuracy: 0.9895\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0298 - accuracy: 0.9909\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0305 - accuracy: 0.9904\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0302 - accuracy: 0.9913\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0293 - accuracy: 0.9913\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0311 - accuracy: 0.9905\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0286 - accuracy: 0.9907\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0296 - accuracy: 0.9911\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0270 - accuracy: 0.9915\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0276 - accuracy: 0.9913\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0290 - accuracy: 0.9910\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0269 - accuracy: 0.9918\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0243 - accuracy: 0.9923\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0310 - accuracy: 0.9908\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0238 - accuracy: 0.9927\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0267 - accuracy: 0.9918\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0274 - accuracy: 0.9916\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0248 - accuracy: 0.9920\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0260 - accuracy: 0.9918\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0273 - accuracy: 0.9918\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0249 - accuracy: 0.9928\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0256 - accuracy: 0.9919\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0238 - accuracy: 0.9929\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0218 - accuracy: 0.9937\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0212 - accuracy: 0.9935\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0254 - accuracy: 0.9921\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0255 - accuracy: 0.9925\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0236 - accuracy: 0.9926\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0227 - accuracy: 0.9932\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0240 - accuracy: 0.9926\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0238 - accuracy: 0.9926\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0247 - accuracy: 0.9927\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0241 - accuracy: 0.9927\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0260 - accuracy: 0.9921\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0243 - accuracy: 0.9927\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0200 - accuracy: 0.9938\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0219 - accuracy: 0.9933\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0221 - accuracy: 0.9933\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0218 - accuracy: 0.9935\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0203 - accuracy: 0.9936\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0221 - accuracy: 0.9931\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0220 - accuracy: 0.9935\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0225 - accuracy: 0.9930\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0216 - accuracy: 0.9937\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0184 - accuracy: 0.9942\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0244 - accuracy: 0.9923\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0199 - accuracy: 0.9939\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0218 - accuracy: 0.9935\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0202 - accuracy: 0.9941\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0203 - accuracy: 0.9939\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0192 - accuracy: 0.9941\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0206 - accuracy: 0.9935\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0206 - accuracy: 0.9942\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0209 - accuracy: 0.9939\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0195 - accuracy: 0.9938\n",
      "CNN 6: Epochs=100, Train accuracy=0.99418\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 13s 31ms/step - loss: 1.4934 - accuracy: 0.5133\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.2721 - accuracy: 0.9186\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.1811 - accuracy: 0.9466\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.1446 - accuracy: 0.9561\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.1234 - accuracy: 0.9634\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1178 - accuracy: 0.9645\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1082 - accuracy: 0.9687\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0986 - accuracy: 0.9704\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0904 - accuracy: 0.9725\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0813 - accuracy: 0.9759\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0818 - accuracy: 0.9754\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0748 - accuracy: 0.9779\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0715 - accuracy: 0.9781\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0720 - accuracy: 0.9782\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0676 - accuracy: 0.9800\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0659 - accuracy: 0.9805\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0625 - accuracy: 0.9813\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0544 - accuracy: 0.9828\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0592 - accuracy: 0.9823\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0566 - accuracy: 0.9833\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0510 - accuracy: 0.9842\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0521 - accuracy: 0.9838\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0522 - accuracy: 0.9849\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0503 - accuracy: 0.9850\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0490 - accuracy: 0.9853\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0485 - accuracy: 0.9853\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0467 - accuracy: 0.9855\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0476 - accuracy: 0.9856\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0421 - accuracy: 0.9871\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0416 - accuracy: 0.9871\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0413 - accuracy: 0.9874\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0392 - accuracy: 0.9883\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0425 - accuracy: 0.9868\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0373 - accuracy: 0.9886\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0389 - accuracy: 0.9882\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0395 - accuracy: 0.9881\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0364 - accuracy: 0.9887\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0377 - accuracy: 0.9884\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0352 - accuracy: 0.9891\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0366 - accuracy: 0.9890\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0359 - accuracy: 0.9892\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0347 - accuracy: 0.9893\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0339 - accuracy: 0.9898\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0341 - accuracy: 0.9891\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0321 - accuracy: 0.9901\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0334 - accuracy: 0.9900\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0299 - accuracy: 0.9906\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0316 - accuracy: 0.9904\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0301 - accuracy: 0.9909\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0311 - accuracy: 0.9907\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0297 - accuracy: 0.9910\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0324 - accuracy: 0.9899\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0305 - accuracy: 0.9909\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0288 - accuracy: 0.9912\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0289 - accuracy: 0.9914\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0293 - accuracy: 0.9912\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0295 - accuracy: 0.9909\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0294 - accuracy: 0.9911\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0275 - accuracy: 0.9915\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0269 - accuracy: 0.9917\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0249 - accuracy: 0.9925\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0276 - accuracy: 0.9919\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0273 - accuracy: 0.9917\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0262 - accuracy: 0.9923\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0236 - accuracy: 0.9926\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0269 - accuracy: 0.9920\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0259 - accuracy: 0.9919\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0237 - accuracy: 0.9925\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0269 - accuracy: 0.9915\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0279 - accuracy: 0.9919\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0259 - accuracy: 0.9918\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0231 - accuracy: 0.9932\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0238 - accuracy: 0.9927\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0242 - accuracy: 0.9926\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0262 - accuracy: 0.9922\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0221 - accuracy: 0.9932\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0226 - accuracy: 0.9931\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0248 - accuracy: 0.9919\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0222 - accuracy: 0.9935\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0218 - accuracy: 0.9932\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0232 - accuracy: 0.9928\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0216 - accuracy: 0.9935\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0239 - accuracy: 0.9928\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0198 - accuracy: 0.9940\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0229 - accuracy: 0.9931\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0204 - accuracy: 0.9936\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0216 - accuracy: 0.9935\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0228 - accuracy: 0.9935\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0212 - accuracy: 0.9936\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0203 - accuracy: 0.9938\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0218 - accuracy: 0.9930\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0199 - accuracy: 0.9941\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0213 - accuracy: 0.9938\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0232 - accuracy: 0.9935\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0204 - accuracy: 0.9937\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0222 - accuracy: 0.9934\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0195 - accuracy: 0.9942\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0190 - accuracy: 0.9941\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0200 - accuracy: 0.9938\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0186 - accuracy: 0.9941\n",
      "CNN 7: Epochs=100, Train accuracy=0.99416\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 1.5315 - accuracy: 0.5008\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.2786 - accuracy: 0.9172\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1769 - accuracy: 0.9469\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1436 - accuracy: 0.9574\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1288 - accuracy: 0.9633\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1117 - accuracy: 0.9669\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1042 - accuracy: 0.9693\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0978 - accuracy: 0.9720\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0887 - accuracy: 0.9734\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0827 - accuracy: 0.9750\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0805 - accuracy: 0.9762\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0752 - accuracy: 0.9780\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0722 - accuracy: 0.9785\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 0.0692 - accuracy: 0.9788\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0662 - accuracy: 0.9804\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0613 - accuracy: 0.9814\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0602 - accuracy: 0.9819\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0615 - accuracy: 0.9816\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0552 - accuracy: 0.9828\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0522 - accuracy: 0.9843\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0555 - accuracy: 0.9833\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0522 - accuracy: 0.9842\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0496 - accuracy: 0.9854\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0487 - accuracy: 0.9852\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0519 - accuracy: 0.9847\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.0444 - accuracy: 0.9863\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0468 - accuracy: 0.9856\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0432 - accuracy: 0.9873\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0440 - accuracy: 0.9873\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.0430 - accuracy: 0.9866\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.0426 - accuracy: 0.9877\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0400 - accuracy: 0.9879\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0435 - accuracy: 0.9867\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0412 - accuracy: 0.9873\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0392 - accuracy: 0.9886\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0362 - accuracy: 0.9887\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0405 - accuracy: 0.9880\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0339 - accuracy: 0.9900\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.0377 - accuracy: 0.9888\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0361 - accuracy: 0.9887\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0348 - accuracy: 0.9891\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 0.0318 - accuracy: 0.9905\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0371 - accuracy: 0.9887\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0324 - accuracy: 0.9902\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0322 - accuracy: 0.9906\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0328 - accuracy: 0.9899\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0332 - accuracy: 0.9899\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0278 - accuracy: 0.9914\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0314 - accuracy: 0.9903\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0302 - accuracy: 0.9913\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0302 - accuracy: 0.9909\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0265 - accuracy: 0.9920\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0304 - accuracy: 0.9907\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0328 - accuracy: 0.9897\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0283 - accuracy: 0.9915\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0255 - accuracy: 0.9922\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0315 - accuracy: 0.9904\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0268 - accuracy: 0.9916\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0296 - accuracy: 0.9917\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0281 - accuracy: 0.9920\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0257 - accuracy: 0.9919\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0293 - accuracy: 0.9914\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0297 - accuracy: 0.9915\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0241 - accuracy: 0.9924\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0268 - accuracy: 0.9920\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0249 - accuracy: 0.9924\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0236 - accuracy: 0.9923\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0242 - accuracy: 0.9927\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0238 - accuracy: 0.9930\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0236 - accuracy: 0.9928\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0260 - accuracy: 0.9925\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0253 - accuracy: 0.9925\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0248 - accuracy: 0.9926\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0204 - accuracy: 0.9937\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0237 - accuracy: 0.9925\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0228 - accuracy: 0.9931\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0234 - accuracy: 0.9930\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0225 - accuracy: 0.9930\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0237 - accuracy: 0.9932\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0223 - accuracy: 0.9933\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0236 - accuracy: 0.9929\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0220 - accuracy: 0.9937\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0210 - accuracy: 0.9940\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0224 - accuracy: 0.9929\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0234 - accuracy: 0.9928\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0224 - accuracy: 0.9932\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0219 - accuracy: 0.9932\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0205 - accuracy: 0.9934\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0236 - accuracy: 0.9929\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0197 - accuracy: 0.9941\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0201 - accuracy: 0.9942\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0209 - accuracy: 0.9938\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0188 - accuracy: 0.9948\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0206 - accuracy: 0.9936\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0211 - accuracy: 0.9938\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0215 - accuracy: 0.9937\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0223 - accuracy: 0.9929\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0225 - accuracy: 0.9933\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0180 - accuracy: 0.9948\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0192 - accuracy: 0.9941\n",
      "CNN 8: Epochs=100, Train accuracy=0.99484\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 1.6043 - accuracy: 0.4756\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.2915 - accuracy: 0.9135\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1859 - accuracy: 0.9451\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.1427 - accuracy: 0.9569\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1306 - accuracy: 0.9618\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1176 - accuracy: 0.9638\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.1038 - accuracy: 0.9690\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0942 - accuracy: 0.9718\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0885 - accuracy: 0.9734\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0836 - accuracy: 0.9757\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0823 - accuracy: 0.9752\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0763 - accuracy: 0.9768\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0718 - accuracy: 0.9787\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0663 - accuracy: 0.9806\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0668 - accuracy: 0.9801\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0615 - accuracy: 0.9819\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0634 - accuracy: 0.9817\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0572 - accuracy: 0.9827\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0557 - accuracy: 0.9828\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0538 - accuracy: 0.9838\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0541 - accuracy: 0.9836\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0509 - accuracy: 0.9848\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0487 - accuracy: 0.9851\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0488 - accuracy: 0.9852\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0491 - accuracy: 0.9851\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0500 - accuracy: 0.9856\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0419 - accuracy: 0.9871\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0430 - accuracy: 0.9864\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0428 - accuracy: 0.9872\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0418 - accuracy: 0.9873\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0405 - accuracy: 0.9886\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0397 - accuracy: 0.9880\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0401 - accuracy: 0.9875\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0407 - accuracy: 0.9887\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0350 - accuracy: 0.9888\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0383 - accuracy: 0.9884\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0356 - accuracy: 0.9899\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0359 - accuracy: 0.9893\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0354 - accuracy: 0.9888\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0342 - accuracy: 0.9894\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0340 - accuracy: 0.9893\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0367 - accuracy: 0.9892\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0297 - accuracy: 0.9907\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0353 - accuracy: 0.9892\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0321 - accuracy: 0.9903\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0314 - accuracy: 0.9904\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0357 - accuracy: 0.9899\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0331 - accuracy: 0.9898\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0306 - accuracy: 0.9906\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0275 - accuracy: 0.9916\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0283 - accuracy: 0.9917\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0287 - accuracy: 0.9914\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0281 - accuracy: 0.9915\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0301 - accuracy: 0.9909\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0289 - accuracy: 0.9909\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0308 - accuracy: 0.9907\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0302 - accuracy: 0.9906\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0274 - accuracy: 0.9917\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0278 - accuracy: 0.9916\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0300 - accuracy: 0.9913\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0251 - accuracy: 0.9921\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0288 - accuracy: 0.9913\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0246 - accuracy: 0.9925\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0270 - accuracy: 0.9919\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0249 - accuracy: 0.9927\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0249 - accuracy: 0.9927\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0244 - accuracy: 0.9924\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0268 - accuracy: 0.9919\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0251 - accuracy: 0.9923\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0252 - accuracy: 0.9925\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0245 - accuracy: 0.9923\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0232 - accuracy: 0.9929\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0226 - accuracy: 0.9931\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0242 - accuracy: 0.9931\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0233 - accuracy: 0.9931\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0226 - accuracy: 0.9929\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0256 - accuracy: 0.9920\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0218 - accuracy: 0.9933\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0223 - accuracy: 0.9932\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0215 - accuracy: 0.9932\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0221 - accuracy: 0.9933\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0220 - accuracy: 0.9933\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0242 - accuracy: 0.9929\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0213 - accuracy: 0.9935\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0208 - accuracy: 0.9936\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0199 - accuracy: 0.9938\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0217 - accuracy: 0.9933\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0227 - accuracy: 0.9929\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0190 - accuracy: 0.9942\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0210 - accuracy: 0.9936\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0204 - accuracy: 0.9936\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0216 - accuracy: 0.9936\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0207 - accuracy: 0.9936\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0191 - accuracy: 0.9942\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0202 - accuracy: 0.9940\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0195 - accuracy: 0.9937\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0201 - accuracy: 0.9938\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0178 - accuracy: 0.9946\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0198 - accuracy: 0.9937\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0193 - accuracy: 0.9940\n",
      "CNN 9: Epochs=100, Train accuracy=0.99460\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 1.4797 - accuracy: 0.5144\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.2794 - accuracy: 0.9169\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1830 - accuracy: 0.9457\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.1533 - accuracy: 0.9532\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1227 - accuracy: 0.9635\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.1149 - accuracy: 0.9655\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1047 - accuracy: 0.9683\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0972 - accuracy: 0.9714\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0847 - accuracy: 0.9746\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0828 - accuracy: 0.9757\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0825 - accuracy: 0.9754\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0774 - accuracy: 0.9764\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0713 - accuracy: 0.9786\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0722 - accuracy: 0.9788\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0684 - accuracy: 0.9799\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0658 - accuracy: 0.9810\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0623 - accuracy: 0.9812\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0620 - accuracy: 0.9814\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0599 - accuracy: 0.9817\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0548 - accuracy: 0.9837\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0567 - accuracy: 0.9833\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0509 - accuracy: 0.9845\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0514 - accuracy: 0.9840\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0493 - accuracy: 0.9853\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0464 - accuracy: 0.9856\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0469 - accuracy: 0.9858\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0472 - accuracy: 0.9863\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0469 - accuracy: 0.9856\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0420 - accuracy: 0.9873\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0444 - accuracy: 0.9866\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0390 - accuracy: 0.9883\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0399 - accuracy: 0.9879\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0382 - accuracy: 0.9888\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0412 - accuracy: 0.9877\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0382 - accuracy: 0.9879\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0367 - accuracy: 0.9890\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0373 - accuracy: 0.9887\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0384 - accuracy: 0.9888\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0331 - accuracy: 0.9900\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0345 - accuracy: 0.9902\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0365 - accuracy: 0.9890\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0336 - accuracy: 0.9901\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0340 - accuracy: 0.9899\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0331 - accuracy: 0.9898\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0318 - accuracy: 0.9901\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0324 - accuracy: 0.9901\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0336 - accuracy: 0.9902\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0307 - accuracy: 0.9905\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0313 - accuracy: 0.9907\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0279 - accuracy: 0.9915\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0310 - accuracy: 0.9906\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0288 - accuracy: 0.9912\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0261 - accuracy: 0.9922\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0284 - accuracy: 0.9913\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0318 - accuracy: 0.9906\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0311 - accuracy: 0.9910\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0273 - accuracy: 0.9921\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0248 - accuracy: 0.9924\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0277 - accuracy: 0.9914\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0260 - accuracy: 0.9920\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0293 - accuracy: 0.9915\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0260 - accuracy: 0.9924\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0250 - accuracy: 0.9926\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0286 - accuracy: 0.9919\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0260 - accuracy: 0.9925\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0272 - accuracy: 0.9920\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0268 - accuracy: 0.9921\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0275 - accuracy: 0.9914\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0229 - accuracy: 0.9930\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0227 - accuracy: 0.9929\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0243 - accuracy: 0.9927\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0258 - accuracy: 0.9922\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0229 - accuracy: 0.9929\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0253 - accuracy: 0.9924\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0239 - accuracy: 0.9925\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0217 - accuracy: 0.9936\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0215 - accuracy: 0.9936\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0221 - accuracy: 0.9932\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0226 - accuracy: 0.9932\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0255 - accuracy: 0.9926\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0211 - accuracy: 0.9936\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0243 - accuracy: 0.9924\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0229 - accuracy: 0.9928\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0213 - accuracy: 0.9937\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0238 - accuracy: 0.9925\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0199 - accuracy: 0.9938\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0176 - accuracy: 0.9944\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0236 - accuracy: 0.9926\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0183 - accuracy: 0.9941\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0222 - accuracy: 0.9935\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0187 - accuracy: 0.9942\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0212 - accuracy: 0.9936\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0213 - accuracy: 0.9935\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0240 - accuracy: 0.9929\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0211 - accuracy: 0.9936\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0194 - accuracy: 0.9943\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0220 - accuracy: 0.9931\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0196 - accuracy: 0.9942\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0184 - accuracy: 0.9945\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0202 - accuracy: 0.9936\n",
      "CNN 10: Epochs=100, Train accuracy=0.99446\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 1.4743 - accuracy: 0.5210\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.2836 - accuracy: 0.9156\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.1860 - accuracy: 0.9433\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1501 - accuracy: 0.9548\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1298 - accuracy: 0.9616\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1187 - accuracy: 0.9646\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.1017 - accuracy: 0.9700\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0980 - accuracy: 0.9708\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0915 - accuracy: 0.9732\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0850 - accuracy: 0.9746\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0797 - accuracy: 0.9763\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0774 - accuracy: 0.9768\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0734 - accuracy: 0.9778\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0686 - accuracy: 0.9793\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0689 - accuracy: 0.9789\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0654 - accuracy: 0.9800\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0610 - accuracy: 0.9816\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0576 - accuracy: 0.9830\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0567 - accuracy: 0.9828\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0552 - accuracy: 0.9832\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0543 - accuracy: 0.9835\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0521 - accuracy: 0.9846\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0485 - accuracy: 0.9851\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0513 - accuracy: 0.9844\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0537 - accuracy: 0.9839\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0453 - accuracy: 0.9861\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0455 - accuracy: 0.9861\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0428 - accuracy: 0.9874\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0431 - accuracy: 0.9876\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0424 - accuracy: 0.9875\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0451 - accuracy: 0.9869\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0415 - accuracy: 0.9872\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0423 - accuracy: 0.9874\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0360 - accuracy: 0.9890\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0402 - accuracy: 0.9876\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0396 - accuracy: 0.9880\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0398 - accuracy: 0.9882\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0385 - accuracy: 0.9886\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0355 - accuracy: 0.9888\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0365 - accuracy: 0.9887\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0358 - accuracy: 0.9892\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0338 - accuracy: 0.9898\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0319 - accuracy: 0.9903\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0318 - accuracy: 0.9905\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0344 - accuracy: 0.9894\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0320 - accuracy: 0.9901\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0329 - accuracy: 0.9899\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0313 - accuracy: 0.9903\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0300 - accuracy: 0.9906\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0298 - accuracy: 0.9907\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0331 - accuracy: 0.9904\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0291 - accuracy: 0.9912\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0298 - accuracy: 0.9910\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0290 - accuracy: 0.9912\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0284 - accuracy: 0.9916\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0285 - accuracy: 0.9915\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0287 - accuracy: 0.9911\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0263 - accuracy: 0.9919\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0280 - accuracy: 0.9919\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0261 - accuracy: 0.9917\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0259 - accuracy: 0.9921\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0253 - accuracy: 0.9925\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0275 - accuracy: 0.9919\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0265 - accuracy: 0.9916\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0257 - accuracy: 0.9927\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0279 - accuracy: 0.9915\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0240 - accuracy: 0.9929\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0255 - accuracy: 0.9924\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0236 - accuracy: 0.9929\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0248 - accuracy: 0.9928\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0255 - accuracy: 0.9923\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0250 - accuracy: 0.9926\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0246 - accuracy: 0.9927\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0260 - accuracy: 0.9917\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0237 - accuracy: 0.9928\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0225 - accuracy: 0.9928\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0217 - accuracy: 0.9935\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0228 - accuracy: 0.9929\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0226 - accuracy: 0.9934\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0244 - accuracy: 0.9929\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0212 - accuracy: 0.9938\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0227 - accuracy: 0.9931\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0241 - accuracy: 0.9927\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0240 - accuracy: 0.9927\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0221 - accuracy: 0.9933\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0209 - accuracy: 0.9937\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0208 - accuracy: 0.9934\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0210 - accuracy: 0.9933\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0205 - accuracy: 0.9941\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0227 - accuracy: 0.9927\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0212 - accuracy: 0.9937\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0222 - accuracy: 0.9931\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0232 - accuracy: 0.9929\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0196 - accuracy: 0.9939\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0212 - accuracy: 0.9936\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0197 - accuracy: 0.9940\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0187 - accuracy: 0.9938\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0219 - accuracy: 0.9930\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0197 - accuracy: 0.9938\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0210 - accuracy: 0.9939\n",
      "CNN 11: Epochs=100, Train accuracy=0.99406\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 13s 31ms/step - loss: 1.4863 - accuracy: 0.5140\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.2705 - accuracy: 0.9184\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.1794 - accuracy: 0.9480\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1435 - accuracy: 0.9566\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1238 - accuracy: 0.9632\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1119 - accuracy: 0.9664\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.1048 - accuracy: 0.9693\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0955 - accuracy: 0.9710\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0922 - accuracy: 0.9728\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0874 - accuracy: 0.9742\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0726 - accuracy: 0.9784\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0781 - accuracy: 0.9771\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0722 - accuracy: 0.9780\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0697 - accuracy: 0.9790\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0668 - accuracy: 0.9802\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0559 - accuracy: 0.9834\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0623 - accuracy: 0.9806\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0620 - accuracy: 0.9822\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0568 - accuracy: 0.9828\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0527 - accuracy: 0.9836\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0565 - accuracy: 0.9831\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0519 - accuracy: 0.9844\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0499 - accuracy: 0.9849\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0480 - accuracy: 0.9858\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0501 - accuracy: 0.9851\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0441 - accuracy: 0.9860\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0421 - accuracy: 0.9870\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0448 - accuracy: 0.9868\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0422 - accuracy: 0.9873\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0426 - accuracy: 0.9867\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0450 - accuracy: 0.9859\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0380 - accuracy: 0.9883\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0401 - accuracy: 0.9882\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0390 - accuracy: 0.9878\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0355 - accuracy: 0.9896\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0368 - accuracy: 0.9887\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0381 - accuracy: 0.9887\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0359 - accuracy: 0.9893\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0344 - accuracy: 0.9898\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0318 - accuracy: 0.9899\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0348 - accuracy: 0.9894\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0326 - accuracy: 0.9900\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0325 - accuracy: 0.9900\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0328 - accuracy: 0.9905\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0332 - accuracy: 0.9897\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0338 - accuracy: 0.9900\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0315 - accuracy: 0.9899\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0330 - accuracy: 0.9902\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0300 - accuracy: 0.9908\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0293 - accuracy: 0.9915\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0309 - accuracy: 0.9909\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0302 - accuracy: 0.9908\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0287 - accuracy: 0.9909\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0291 - accuracy: 0.9914\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0301 - accuracy: 0.9909\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0282 - accuracy: 0.9913\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0279 - accuracy: 0.9915\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0280 - accuracy: 0.9915\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0274 - accuracy: 0.9917\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0269 - accuracy: 0.9920\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0272 - accuracy: 0.9914\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0281 - accuracy: 0.9919\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0267 - accuracy: 0.9921\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0254 - accuracy: 0.9917\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0259 - accuracy: 0.9921\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0274 - accuracy: 0.9917\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0241 - accuracy: 0.9922\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0245 - accuracy: 0.9922\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0255 - accuracy: 0.9922\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0225 - accuracy: 0.9934\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0254 - accuracy: 0.9924\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0245 - accuracy: 0.9925\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0244 - accuracy: 0.9922\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0219 - accuracy: 0.9931\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0220 - accuracy: 0.9933\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0263 - accuracy: 0.9920\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0231 - accuracy: 0.9929\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0222 - accuracy: 0.9935\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0219 - accuracy: 0.9932\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0226 - accuracy: 0.9930\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0201 - accuracy: 0.9940\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0229 - accuracy: 0.9930\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0231 - accuracy: 0.9925\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0179 - accuracy: 0.9946\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0252 - accuracy: 0.9923\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0204 - accuracy: 0.9936\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0227 - accuracy: 0.9930\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0207 - accuracy: 0.9934\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0205 - accuracy: 0.9940\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0207 - accuracy: 0.9937\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0190 - accuracy: 0.9939\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0219 - accuracy: 0.9934\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0205 - accuracy: 0.9933\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0226 - accuracy: 0.9933\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0205 - accuracy: 0.9933\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0205 - accuracy: 0.9932\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0208 - accuracy: 0.9937\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0186 - accuracy: 0.9944\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0164 - accuracy: 0.9951\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0195 - accuracy: 0.9940\n",
      "CNN 12: Epochs=100, Train accuracy=0.99508\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 1.5605 - accuracy: 0.4904\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.2957 - accuracy: 0.9120\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1963 - accuracy: 0.9414\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1482 - accuracy: 0.9555\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1273 - accuracy: 0.9619\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.1154 - accuracy: 0.9648\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1083 - accuracy: 0.9673\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0947 - accuracy: 0.9715\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0877 - accuracy: 0.9738\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0898 - accuracy: 0.9728\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0778 - accuracy: 0.9767\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0756 - accuracy: 0.9771\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0707 - accuracy: 0.9786\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0711 - accuracy: 0.9788\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0642 - accuracy: 0.9814\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0653 - accuracy: 0.9814\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0621 - accuracy: 0.9814\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0560 - accuracy: 0.9839\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0571 - accuracy: 0.9827\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0591 - accuracy: 0.9818\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0540 - accuracy: 0.9837\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0501 - accuracy: 0.9852\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0525 - accuracy: 0.9842\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0479 - accuracy: 0.9859\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0475 - accuracy: 0.9865\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0494 - accuracy: 0.9852\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0479 - accuracy: 0.9855\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0451 - accuracy: 0.9864\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0445 - accuracy: 0.9861\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0409 - accuracy: 0.9870\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0405 - accuracy: 0.9879\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0394 - accuracy: 0.9887\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0384 - accuracy: 0.9883\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0414 - accuracy: 0.9871\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0389 - accuracy: 0.9885\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0375 - accuracy: 0.9881\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0353 - accuracy: 0.9889\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0389 - accuracy: 0.9884\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0374 - accuracy: 0.9890\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0339 - accuracy: 0.9899\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0350 - accuracy: 0.9891\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0331 - accuracy: 0.9902\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0353 - accuracy: 0.9893\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0316 - accuracy: 0.9907\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0310 - accuracy: 0.9905\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0325 - accuracy: 0.9904\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0328 - accuracy: 0.9900\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0295 - accuracy: 0.9910\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0319 - accuracy: 0.9900\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0310 - accuracy: 0.9909\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0297 - accuracy: 0.9912\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0285 - accuracy: 0.9913\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0298 - accuracy: 0.9907\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0322 - accuracy: 0.9899\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0274 - accuracy: 0.9914\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0298 - accuracy: 0.9910\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0293 - accuracy: 0.9910\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0267 - accuracy: 0.9918\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0278 - accuracy: 0.9917\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0252 - accuracy: 0.9919\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0264 - accuracy: 0.9918\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0260 - accuracy: 0.9920\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0263 - accuracy: 0.9921\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0259 - accuracy: 0.9920\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0243 - accuracy: 0.9929\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0249 - accuracy: 0.9925\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0266 - accuracy: 0.9918\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0278 - accuracy: 0.9916\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0226 - accuracy: 0.9932\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0234 - accuracy: 0.9930\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0236 - accuracy: 0.9927\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0240 - accuracy: 0.9926\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0248 - accuracy: 0.9928\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0224 - accuracy: 0.9931\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0231 - accuracy: 0.9928\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0230 - accuracy: 0.9933\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0254 - accuracy: 0.9925\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0240 - accuracy: 0.9923\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0220 - accuracy: 0.9933\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0230 - accuracy: 0.9931\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0237 - accuracy: 0.9925\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0233 - accuracy: 0.9931\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0234 - accuracy: 0.9930\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0207 - accuracy: 0.9931\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0229 - accuracy: 0.9932\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0207 - accuracy: 0.9936\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0234 - accuracy: 0.9926\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0216 - accuracy: 0.9935\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0186 - accuracy: 0.9946\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0230 - accuracy: 0.9934\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0205 - accuracy: 0.9936\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0189 - accuracy: 0.9944\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0213 - accuracy: 0.9934\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0217 - accuracy: 0.9932\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0193 - accuracy: 0.9938\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0176 - accuracy: 0.9942\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0189 - accuracy: 0.9940\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0193 - accuracy: 0.9939\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0183 - accuracy: 0.9941\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0213 - accuracy: 0.9935\n",
      "CNN 13: Epochs=100, Train accuracy=0.99458\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 1.5286 - accuracy: 0.4997\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.2856 - accuracy: 0.9153\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.1852 - accuracy: 0.9448\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.1478 - accuracy: 0.9556\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1349 - accuracy: 0.9596\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.1145 - accuracy: 0.9660\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1022 - accuracy: 0.9690\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0995 - accuracy: 0.9708\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0923 - accuracy: 0.9727\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0843 - accuracy: 0.9754\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0779 - accuracy: 0.9763\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0808 - accuracy: 0.9759\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0739 - accuracy: 0.9779\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0662 - accuracy: 0.9798\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0663 - accuracy: 0.9801\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0662 - accuracy: 0.9799\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0601 - accuracy: 0.9826\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0601 - accuracy: 0.9819\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0582 - accuracy: 0.9829\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0573 - accuracy: 0.9828\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0532 - accuracy: 0.9836\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0530 - accuracy: 0.9841\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0490 - accuracy: 0.9855\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0536 - accuracy: 0.9843\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0448 - accuracy: 0.9867\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0454 - accuracy: 0.9858\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0471 - accuracy: 0.9857\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0446 - accuracy: 0.9863\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0445 - accuracy: 0.9867\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0400 - accuracy: 0.9882\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0436 - accuracy: 0.9874\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0376 - accuracy: 0.9884\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0401 - accuracy: 0.9880\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0378 - accuracy: 0.9884\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0387 - accuracy: 0.9886\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0343 - accuracy: 0.9900\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0367 - accuracy: 0.9890\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0346 - accuracy: 0.9897\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0332 - accuracy: 0.9895\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0355 - accuracy: 0.9895\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0367 - accuracy: 0.9892\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0343 - accuracy: 0.9894\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0342 - accuracy: 0.9899\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0333 - accuracy: 0.9899\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0309 - accuracy: 0.9903\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0331 - accuracy: 0.9898\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0304 - accuracy: 0.9910\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0296 - accuracy: 0.9903\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0299 - accuracy: 0.9904\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0315 - accuracy: 0.9904\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0290 - accuracy: 0.9915\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0297 - accuracy: 0.9913\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0301 - accuracy: 0.9903\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0282 - accuracy: 0.9913\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0297 - accuracy: 0.9911\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0255 - accuracy: 0.9918\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0289 - accuracy: 0.9915\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0292 - accuracy: 0.9913\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0268 - accuracy: 0.9918\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0285 - accuracy: 0.9914\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0267 - accuracy: 0.9919\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0283 - accuracy: 0.9914\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0262 - accuracy: 0.9920\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0254 - accuracy: 0.9925\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0252 - accuracy: 0.9922\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0232 - accuracy: 0.9930\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0260 - accuracy: 0.9929\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0262 - accuracy: 0.9919\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0283 - accuracy: 0.9913\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0268 - accuracy: 0.9919\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0225 - accuracy: 0.9928\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0251 - accuracy: 0.9923\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0204 - accuracy: 0.9938\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0244 - accuracy: 0.9924\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0241 - accuracy: 0.9930\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0221 - accuracy: 0.9932\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0261 - accuracy: 0.9920\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0219 - accuracy: 0.9935\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0210 - accuracy: 0.9935\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0239 - accuracy: 0.9929\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0224 - accuracy: 0.9929\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0216 - accuracy: 0.9932\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0232 - accuracy: 0.9935\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0191 - accuracy: 0.9940\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0214 - accuracy: 0.9937\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0208 - accuracy: 0.9938\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0211 - accuracy: 0.9934\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0207 - accuracy: 0.9936\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0201 - accuracy: 0.9938\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0193 - accuracy: 0.9943\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0227 - accuracy: 0.9929\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0214 - accuracy: 0.9936\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0221 - accuracy: 0.9931\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0205 - accuracy: 0.9934\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0200 - accuracy: 0.9939\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0196 - accuracy: 0.9937\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0217 - accuracy: 0.9936\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0181 - accuracy: 0.9943\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0198 - accuracy: 0.9940\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0210 - accuracy: 0.9939\n",
      "CNN 14: Epochs=100, Train accuracy=0.99430\n",
      "Epoch 1/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 1.6587 - accuracy: 0.4521\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.2927 - accuracy: 0.9122\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1842 - accuracy: 0.9458\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1473 - accuracy: 0.9558\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 31ms/step - loss: 0.1259 - accuracy: 0.9627\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1138 - accuracy: 0.9660\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.1031 - accuracy: 0.9685\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0971 - accuracy: 0.9717\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0850 - accuracy: 0.9744\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0844 - accuracy: 0.9755\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0814 - accuracy: 0.9760\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0762 - accuracy: 0.9765\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 13s 32ms/step - loss: 0.0743 - accuracy: 0.9784\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0642 - accuracy: 0.9805\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0631 - accuracy: 0.9821\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0632 - accuracy: 0.9805\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0606 - accuracy: 0.9812\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0573 - accuracy: 0.9826\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0549 - accuracy: 0.9842\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0547 - accuracy: 0.9831\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0551 - accuracy: 0.9830\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0525 - accuracy: 0.9844\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0512 - accuracy: 0.9843\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0510 - accuracy: 0.9849\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0449 - accuracy: 0.9860\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0478 - accuracy: 0.9854\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0483 - accuracy: 0.9858\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0427 - accuracy: 0.9870\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0409 - accuracy: 0.9876\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0455 - accuracy: 0.9860\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0415 - accuracy: 0.9875\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0362 - accuracy: 0.9888\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0429 - accuracy: 0.9868\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0374 - accuracy: 0.9885\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 13s 33ms/step - loss: 0.0391 - accuracy: 0.9888\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0354 - accuracy: 0.9889\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0371 - accuracy: 0.9892\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0373 - accuracy: 0.9891\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0378 - accuracy: 0.9888\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0329 - accuracy: 0.9903\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0321 - accuracy: 0.9906\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0334 - accuracy: 0.9905\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0346 - accuracy: 0.9897\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0356 - accuracy: 0.9895\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0331 - accuracy: 0.9895\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0321 - accuracy: 0.9901\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0306 - accuracy: 0.9911\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0286 - accuracy: 0.9911\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0290 - accuracy: 0.9912\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0312 - accuracy: 0.9907\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0301 - accuracy: 0.9913\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0281 - accuracy: 0.9913\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0311 - accuracy: 0.9908\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0318 - accuracy: 0.9909\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0293 - accuracy: 0.9912\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0256 - accuracy: 0.9922\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0270 - accuracy: 0.9913\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0287 - accuracy: 0.9912\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 12s 29ms/step - loss: 0.0257 - accuracy: 0.9922\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0254 - accuracy: 0.9920\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0243 - accuracy: 0.9925\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0265 - accuracy: 0.9921\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0239 - accuracy: 0.9924\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0286 - accuracy: 0.9909\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0257 - accuracy: 0.9922\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0241 - accuracy: 0.9925\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0262 - accuracy: 0.9925\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0282 - accuracy: 0.9917\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0244 - accuracy: 0.9929\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0242 - accuracy: 0.9928\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0242 - accuracy: 0.9924\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0252 - accuracy: 0.9924\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0257 - accuracy: 0.9925\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0228 - accuracy: 0.9926\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0235 - accuracy: 0.9929\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0211 - accuracy: 0.9937\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0227 - accuracy: 0.9931\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0218 - accuracy: 0.9930\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0239 - accuracy: 0.9925\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0245 - accuracy: 0.9924\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0243 - accuracy: 0.9929\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0222 - accuracy: 0.9932\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0228 - accuracy: 0.9925\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0220 - accuracy: 0.9935\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0211 - accuracy: 0.9937\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0209 - accuracy: 0.9933\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0218 - accuracy: 0.9935\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0219 - accuracy: 0.9931\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0216 - accuracy: 0.9931\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0212 - accuracy: 0.9935\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0198 - accuracy: 0.9937\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0214 - accuracy: 0.9932\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 12s 32ms/step - loss: 0.0203 - accuracy: 0.9938\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0204 - accuracy: 0.9940\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0174 - accuracy: 0.9949\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0208 - accuracy: 0.9937\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 12s 31ms/step - loss: 0.0210 - accuracy: 0.9935\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0221 - accuracy: 0.9936\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0181 - accuracy: 0.9943\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 12s 30ms/step - loss: 0.0207 - accuracy: 0.9940\n",
      "CNN 15: Epochs=100, Train accuracy=0.99492\n"
     ]
    }
   ],
   "source": [
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
    "# TRAIN NETWORKS\n",
    "history = [0] * nets\n",
    "epochs = 100\n",
    "for j in range(nets):\n",
    "#     X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X, y, test_size = 0.1)\n",
    "#     history[j] = model[j].fit_generator(datagen.flow(X,y, batch_size=128),\n",
    "#         epochs = epochs, steps_per_epoch = X.shape[0]//128,  \n",
    "#         callbacks=[annealer], verbose=0)\n",
    "        history[j] = model[j].fit(datagen.flow(X,y, batch_size=128),\n",
    "                                            epochs = epochs)\n",
    "        print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}\".format(j+1,epochs,max(history[j].history['accuracy'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5542e00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>Feature 8</th>\n",
       "      <th>Feature 9</th>\n",
       "      <th>Feature 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 1559</th>\n",
       "      <th>Feature 1560</th>\n",
       "      <th>Feature 1561</th>\n",
       "      <th>Feature 1562</th>\n",
       "      <th>Feature 1563</th>\n",
       "      <th>Feature 1564</th>\n",
       "      <th>Feature 1565</th>\n",
       "      <th>Feature 1566</th>\n",
       "      <th>Feature 1567</th>\n",
       "      <th>Feature 1568</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.955389e-23</td>\n",
       "      <td>-4.232597e-23</td>\n",
       "      <td>-1.371348e-23</td>\n",
       "      <td>-4.941302e-24</td>\n",
       "      <td>4.701897e-24</td>\n",
       "      <td>9.137646e-24</td>\n",
       "      <td>-5.964309e-25</td>\n",
       "      <td>-8.037856e-27</td>\n",
       "      <td>1.607571e-26</td>\n",
       "      <td>1.896144e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.713258e-20</td>\n",
       "      <td>-3.072854e-20</td>\n",
       "      <td>1.208471e-20</td>\n",
       "      <td>8.119634e-22</td>\n",
       "      <td>-4.124326e-21</td>\n",
       "      <td>-2.351743e-22</td>\n",
       "      <td>-1.139683e-23</td>\n",
       "      <td>-1.730485e-24</td>\n",
       "      <td>-1.088523e-24</td>\n",
       "      <td>-1.192788e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.737605e-19</td>\n",
       "      <td>1.010960e-17</td>\n",
       "      <td>1.299321e-20</td>\n",
       "      <td>1.007092e-20</td>\n",
       "      <td>-1.007821e-20</td>\n",
       "      <td>2.289849e-21</td>\n",
       "      <td>-8.811264e-22</td>\n",
       "      <td>2.288049e-22</td>\n",
       "      <td>-6.056319e-23</td>\n",
       "      <td>-1.302198e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.688333e-22</td>\n",
       "      <td>1.262406e-22</td>\n",
       "      <td>-1.204514e-23</td>\n",
       "      <td>-9.310054e-24</td>\n",
       "      <td>-1.898251e-24</td>\n",
       "      <td>-1.192600e-25</td>\n",
       "      <td>-2.870280e-26</td>\n",
       "      <td>-2.612264e-27</td>\n",
       "      <td>-7.700169e-27</td>\n",
       "      <td>-3.745563e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.748979e-21</td>\n",
       "      <td>-1.613074e-21</td>\n",
       "      <td>-3.539335e-21</td>\n",
       "      <td>-6.962758e-20</td>\n",
       "      <td>1.694034e-19</td>\n",
       "      <td>-3.988890e-20</td>\n",
       "      <td>-5.779639e-22</td>\n",
       "      <td>5.424119e-21</td>\n",
       "      <td>1.102504e-22</td>\n",
       "      <td>-2.005880e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.176424e-21</td>\n",
       "      <td>2.125517e-22</td>\n",
       "      <td>-5.571208e-23</td>\n",
       "      <td>1.215935e-22</td>\n",
       "      <td>1.939962e-22</td>\n",
       "      <td>-1.638395e-22</td>\n",
       "      <td>-3.236651e-24</td>\n",
       "      <td>4.809522e-25</td>\n",
       "      <td>-1.347239e-25</td>\n",
       "      <td>5.794320e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.372621e-20</td>\n",
       "      <td>6.099703e-21</td>\n",
       "      <td>-8.780294e-22</td>\n",
       "      <td>-6.306931e-22</td>\n",
       "      <td>-1.059037e-21</td>\n",
       "      <td>6.598977e-23</td>\n",
       "      <td>5.641922e-23</td>\n",
       "      <td>1.521738e-23</td>\n",
       "      <td>5.845244e-25</td>\n",
       "      <td>2.289112e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.796364e-20</td>\n",
       "      <td>-1.969505e-20</td>\n",
       "      <td>-1.698103e-22</td>\n",
       "      <td>2.043203e-22</td>\n",
       "      <td>5.397814e-23</td>\n",
       "      <td>-3.642104e-23</td>\n",
       "      <td>-5.222338e-23</td>\n",
       "      <td>-8.629898e-24</td>\n",
       "      <td>1.129773e-24</td>\n",
       "      <td>-2.509890e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536667e-20</td>\n",
       "      <td>-5.036675e-21</td>\n",
       "      <td>2.582385e-22</td>\n",
       "      <td>1.224506e-22</td>\n",
       "      <td>3.189655e-23</td>\n",
       "      <td>-7.812957e-24</td>\n",
       "      <td>-2.556415e-24</td>\n",
       "      <td>2.959303e-25</td>\n",
       "      <td>1.060729e-25</td>\n",
       "      <td>1.069585e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.705075e-20</td>\n",
       "      <td>5.533117e-21</td>\n",
       "      <td>-7.200016e-22</td>\n",
       "      <td>1.472278e-22</td>\n",
       "      <td>-1.492252e-23</td>\n",
       "      <td>-9.910375e-24</td>\n",
       "      <td>-9.901138e-24</td>\n",
       "      <td>-2.287262e-24</td>\n",
       "      <td>-9.313975e-25</td>\n",
       "      <td>-4.494966e-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1568 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  Feature 6  \\\n",
       "0           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "9995        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9996        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9997        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9998        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "9999        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "      Feature 7  Feature 8  Feature 9  Feature 10  ...  Feature 1559  \\\n",
       "0           0.0        0.0        0.0         0.0  ...  1.955389e-23   \n",
       "1           0.0        0.0        0.0         0.0  ... -1.713258e-20   \n",
       "2           0.0        0.0        0.0         0.0  ... -7.737605e-19   \n",
       "3           0.0        0.0        0.0         0.0  ...  1.688333e-22   \n",
       "4           0.0        0.0        0.0         0.0  ... -5.748979e-21   \n",
       "...         ...        ...        ...         ...  ...           ...   \n",
       "9995        0.0        0.0        0.0         0.0  ...  2.176424e-21   \n",
       "9996        0.0        0.0        0.0         0.0  ...  8.372621e-20   \n",
       "9997        0.0        0.0        0.0         0.0  ...  1.796364e-20   \n",
       "9998        0.0        0.0        0.0         0.0  ...  1.536667e-20   \n",
       "9999        0.0        0.0        0.0         0.0  ... -3.705075e-20   \n",
       "\n",
       "      Feature 1560  Feature 1561  Feature 1562  Feature 1563  Feature 1564  \\\n",
       "0    -4.232597e-23 -1.371348e-23 -4.941302e-24  4.701897e-24  9.137646e-24   \n",
       "1    -3.072854e-20  1.208471e-20  8.119634e-22 -4.124326e-21 -2.351743e-22   \n",
       "2     1.010960e-17  1.299321e-20  1.007092e-20 -1.007821e-20  2.289849e-21   \n",
       "3     1.262406e-22 -1.204514e-23 -9.310054e-24 -1.898251e-24 -1.192600e-25   \n",
       "4    -1.613074e-21 -3.539335e-21 -6.962758e-20  1.694034e-19 -3.988890e-20   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "9995  2.125517e-22 -5.571208e-23  1.215935e-22  1.939962e-22 -1.638395e-22   \n",
       "9996  6.099703e-21 -8.780294e-22 -6.306931e-22 -1.059037e-21  6.598977e-23   \n",
       "9997 -1.969505e-20 -1.698103e-22  2.043203e-22  5.397814e-23 -3.642104e-23   \n",
       "9998 -5.036675e-21  2.582385e-22  1.224506e-22  3.189655e-23 -7.812957e-24   \n",
       "9999  5.533117e-21 -7.200016e-22  1.472278e-22 -1.492252e-23 -9.910375e-24   \n",
       "\n",
       "      Feature 1565  Feature 1566  Feature 1567  Feature 1568  \n",
       "0    -5.964309e-25 -8.037856e-27  1.607571e-26  1.896144e-27  \n",
       "1    -1.139683e-23 -1.730485e-24 -1.088523e-24 -1.192788e-25  \n",
       "2    -8.811264e-22  2.288049e-22 -6.056319e-23 -1.302198e-23  \n",
       "3    -2.870280e-26 -2.612264e-27 -7.700169e-27 -3.745563e-27  \n",
       "4    -5.779639e-22  5.424119e-21  1.102504e-22 -2.005880e-22  \n",
       "...            ...           ...           ...           ...  \n",
       "9995 -3.236651e-24  4.809522e-25 -1.347239e-25  5.794320e-26  \n",
       "9996  5.641922e-23  1.521738e-23  5.845244e-25  2.289112e-25  \n",
       "9997 -5.222338e-23 -8.629898e-24  1.129773e-24 -2.509890e-26  \n",
       "9998 -2.556415e-24  2.959303e-25  1.060729e-25  1.069585e-25  \n",
       "9999 -9.901138e-24 -2.287262e-24 -9.313975e-25 -4.494966e-25  \n",
       "\n",
       "[10000 rows x 1568 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_test = df_test.iloc[:,:-1]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f450b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.values.reshape(-1,28,56,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9650f8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5005a63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   0\n",
       "0         0  14\n",
       "1         1   7\n",
       "2         2  10\n",
       "3         3   7\n",
       "4         4   5\n",
       "...     ...  ..\n",
       "9995   9995   7\n",
       "9996   9996  12\n",
       "9997   9997  10\n",
       "9998   9998   4\n",
       "9999   9999   6\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = np.zeros( (df_test.shape[0],19) ) \n",
    "for j in range(nets):\n",
    "    results = results + model[j].predict(df_test)\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.DataFrame(results).reset_index()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52905200",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns = ['Index', 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36efae3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index  Class\n",
       "0         0     14\n",
       "1         1      7\n",
       "2         2     10\n",
       "3         3      7\n",
       "4         4      5\n",
       "...     ...    ...\n",
       "9995   9995      7\n",
       "9996   9996     12\n",
       "9997   9997     10\n",
       "9998   9998      4\n",
       "9999   9999      6\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00b79fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('pd-cnn-c-5-ensemble-submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3588fc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/0\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/1\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/2\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/3\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/4\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/5\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/6\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/7\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/8\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/9\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/10\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/11\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/11\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/12\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/12\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/13\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/13\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/14\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ensemble-c5/14\\assets\n"
     ]
    }
   ],
   "source": [
    "for j in range(nets):\n",
    "    model[j].save(f'models/ensemble-c5/{j}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a9c8da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "results = np.zeros( (df_test.shape[0],19) ) \n",
    "for j in range(nets):\n",
    "    results = results + model[j].predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f37194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = np.zeros((nets, df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c382dce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "for j in range(nets):\n",
    "    y_pred = model[j].predict(df_test)\n",
    "    final[j] = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "95ab99bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3     4     5     6     7     8     9     10    11  \\\n",
       "0     14.0  14.0  14.0  14.0  14.0  14.0  14.0  14.0  14.0  14.0  14.0  14.0   \n",
       "1      7.0   7.0   7.0   7.0   7.0   7.0   7.0   7.0   7.0   7.0   7.0   7.0   \n",
       "2     10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   \n",
       "3      7.0   7.0   7.0   7.0   7.0   7.0   7.0   7.0   7.0   7.0   7.0   7.0   \n",
       "4      5.0   5.0   5.0   5.0   5.0   5.0   5.0   5.0   5.0   5.0   5.0   5.0   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "9995   7.0   7.0   7.0   7.0   7.0   7.0   7.0   7.0   7.0   7.0   7.0   7.0   \n",
       "9996  12.0  12.0  12.0  12.0  12.0  12.0  12.0  12.0  12.0  12.0  12.0  12.0   \n",
       "9997  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0  10.0   \n",
       "9998   4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0   4.0   \n",
       "9999   6.0   6.0   6.0   6.0   6.0   6.0   6.0   6.0   6.0   6.0   6.0   6.0   \n",
       "\n",
       "        12    13    14  \n",
       "0     14.0  14.0  14.0  \n",
       "1      7.0   7.0   7.0  \n",
       "2     10.0  10.0  10.0  \n",
       "3      7.0   7.0   7.0  \n",
       "4      5.0   5.0   5.0  \n",
       "...    ...   ...   ...  \n",
       "9995   7.0   7.0   7.0  \n",
       "9996  12.0  12.0  12.0  \n",
       "9997  10.0  10.0  10.0  \n",
       "9998   4.0   4.0   4.0  \n",
       "9999   6.0   6.0   6.0  \n",
       "\n",
       "[10000 rows x 15 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(final.T)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ccac8c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = np.zeros(df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f5442d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df_test.shape[0]):\n",
    "    sub[i] = df.iloc[i].value_counts().index.values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "deec2ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sub)\n",
    "df = df.reset_index()\n",
    "df.columns =['Index', 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5627844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('voting.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a15154c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    2\n",
       "1    1\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d05c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
